{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-afe51ce7-bf2f-4535-a76c-beeeecb0f248",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "864c6ca2",
    "execution_start": 1621907198730,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\nimport numpy as np\n\n# Helper Functions\nimport wrangle as w \nimport explore as exp\nfrom explore import rfe, split, select_kbest\n\n# Visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Hypothesis tests\nfrom scipy import stats\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import ttest_1samp\nfrom scipy.stats import ttest_ind\n\n#Feature Engineering\nfrom sklearn.feature_selection import SelectKBest, f_regression, chi2\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.feature_selection import RFE\nfrom scipy import stats\n\n# Split data\nfrom sklearn.model_selection import train_test_split\n\n# Evaluate models\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_fscore_support \n\n# Create models for classification ML:\n# Decision Tree  \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# K-Nearest Neighbor(KNN)  \nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression",
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "df = w.wrangle_data(cached=False)",
   "metadata": {
    "tags": [],
    "cell_id": "00001-25082157-824e-43c1-a14e-c6627b655cef",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d93c6998",
    "execution_start": 1621902000267,
    "execution_millis": 6218,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "df.isnull().sum()",
   "metadata": {
    "tags": [],
    "cell_id": "00002-6bfd7d89-37a8-403c-9b22-989d8c76e850",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f3dd26da",
    "execution_start": 1621902006486,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 3,
     "data": {
      "text/plain": "age                                            0\ngender                                         0\nrace                                           0\ndate                                           0\ncity                                           0\nstate                                          0\nzipcode                                        0\ncounty                                         0\nagency_responsible                             0\ncause_of_death                                 0\ndescription_of_circumstances                   0\nofficial_disposition                           0\ncriminal_charges_filed                         0\nmental_illness                                 0\narmed_unarmed_status                           0\nalleged_weapon                                 0\nalleged_threat_lvl                             0\nfleeing                                        0\nbody_camera                                    0\ngeography                                      0\nencounter_type_draft                           0\ninitial_reported_reason_for_encounter_draft    0\nknown_past_shootings_of_officer_draft          0\nis_female                                      0\nis_male                                        0\nis_transgender                                 0\nwas_fleeing                                    0\nwas_not fleeing                                0\nwas_allegedly_armed                            0\nwas_unarmed                                    0\nwas_vehicle                                    0\nwas_domestic_disturbance                       0\nwas_mental_health_welfare_check                0\nwas_person_with_a_weapon                       0\nwas_traffic_stop                               0\nwas_violent_crime_part_1                       0\nis_asian/pacific islander                      0\nis_black                                       0\nis_hispanic                                    0\nis_native american                             0\nis_unknown race                                0\nis_white                                       0\nmntlill_drug or alcohol use                    0\nmntlill_no                                     0\nmntlill_unknown                                0\nmntlill_yes                                    0\nrural                                          0\nsuburban                                       0\nurban                                          0\ncod_lethal                                     0\nage_bins                                       0\nunknown                                        0\nunder 12                                       0\n12-17                                          0\n18-24                                          0\n25-34                                          0\n35-44                                          0\n45-54                                          0\n55-64                                          0\n65+                                            0\ndtype: int64"
     },
     "metadata": {}
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": "df.age.value_counts()",
   "metadata": {
    "tags": [],
    "cell_id": "00003-861c6add-03ca-4dbf-b4a3-9eead71c3e7e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2a21e0e6",
    "execution_start": 1621902006486,
    "execution_millis": 23,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "25     280\n0      279\n27     275\n28     275\n31     275\n      ... \n88       1\n93       1\n85       1\n107      1\n95       1\nName: age, Length: 88, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": "df.age_bins.value_counts()",
   "metadata": {
    "tags": [],
    "cell_id": "00007-4cfb6dc6-6394-45e7-93d9-ddea660ec5be",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "48919f60",
    "execution_start": 1621902006503,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 5,
     "data": {
      "text/plain": "25-34       2697\n35-44       2005\n18-24       1289\n45-54       1278\n55-64        652\nunknown      279\n65+          267\n12-17        155\nunder 12      12\nName: age_bins, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": "df.columns",
   "metadata": {
    "tags": [],
    "cell_id": "00006-d103c388-047e-4fd7-bd41-a3af5340dce3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "25d43fa0",
    "execution_start": 1621902006504,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 6,
     "data": {
      "text/plain": "Index(['age', 'gender', 'race', 'date', 'city', 'state', 'zipcode', 'county',\n       'agency_responsible', 'cause_of_death', 'description_of_circumstances',\n       'official_disposition', 'criminal_charges_filed', 'mental_illness',\n       'armed_unarmed_status', 'alleged_weapon', 'alleged_threat_lvl',\n       'fleeing', 'body_camera', 'geography', 'encounter_type_draft',\n       'initial_reported_reason_for_encounter_draft',\n       'known_past_shootings_of_officer_draft', 'is_female', 'is_male',\n       'is_transgender', 'was_fleeing', 'was_not fleeing ',\n       'was_allegedly_armed', 'was_unarmed', 'was_vehicle',\n       'was_domestic_disturbance', 'was_mental_health_welfare_check',\n       'was_person_with_a_weapon', 'was_traffic_stop',\n       'was_violent_crime_part_1', 'is_asian/pacific islander', 'is_black',\n       'is_hispanic', 'is_native american', 'is_unknown race', 'is_white',\n       'mntlill_drug or alcohol use', 'mntlill_no', 'mntlill_unknown',\n       'mntlill_yes', 'rural', 'suburban', 'urban', 'cod_lethal', 'age_bins',\n       'unknown', 'under 12', '12-17', '18-24', '25-34', '35-44', '45-54',\n       '55-64', '65+'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": "from explore import rfe, split, select_kbest",
   "metadata": {
    "tags": [],
    "cell_id": "00006-919db769-656a-4eab-bb10-d9c631e9331c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fb9b34ba",
    "execution_start": 1621902006542,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": "train, validate, test = split(df, stratify_by='alleged_threat_lvl')",
   "metadata": {
    "tags": [],
    "cell_id": "00007-2b4cf507-9fcb-46d5-99ad-3871b80180d8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "61bca6e2",
    "execution_start": 1621902006543,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "\ndef split_df(df, target, seed):\n    '''\n    split_df will take one argument(df) and \n    then split our data into 20/80, \n    then split the 80% into 30/70\n    performs a train, validate, test split\n    splits each of the 3 samples into a dataframe with independent variables\n    and a series with the dependent, or target variable. \n    The function returns 6 dataframes and 3 series:\n    train, validate, test split, X_train (df) & y_train (series), X_validate & y_validate, X_test & y_test. \n    '''\n    # Train, Validate, and test\n    train_and_validate, test = train_test_split(df, test_size=0.2, random_state=seed)\n    train, validate = train_test_split(train_and_validate, test_size=0.3, random_state=seed)\n    # Split with X and y\n    X_train = train.drop(columns=[target])\n    y_train = train[target]\n    X_validate = validate.drop(columns=[target])\n    y_validate = validate[target]\n    X_test = test.drop(columns=[target])\n    y_test = test[target]\n    return train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test ",
   "metadata": {
    "tags": [],
    "cell_id": "00008-dfce7d04-b461-49d8-8573-075ffde11aed",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "68e62203",
    "execution_start": 1621902006543,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "\ntrain, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test = split_df(df, 'alleged_threat_lvl', 42)",
   "metadata": {
    "tags": [],
    "cell_id": "00009-ab50d1b3-ba5d-40ca-92ea-25209c4247ce",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4ca76457",
    "execution_start": 1621902006583,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "#y_",
   "metadata": {
    "tags": [],
    "cell_id": "00010-3d397d72-f255-46c4-90ee-f665b09d8778",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "89d68b10",
    "execution_start": 1621902006583,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": "X_train.info()",
   "metadata": {
    "tags": [],
    "cell_id": "00010-a4c560cb-74e2-44a1-9b39-e5de15e68b7b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3ca3de2b",
    "execution_start": 1621902006584,
    "execution_millis": 24,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 4834 entries, 5595 to 5633\nData columns (total 59 columns):\n #   Column                                       Non-Null Count  Dtype         \n---  ------                                       --------------  -----         \n 0   age                                          4834 non-null   int64         \n 1   gender                                       4834 non-null   object        \n 2   race                                         4834 non-null   object        \n 3   date                                         4834 non-null   datetime64[ns]\n 4   city                                         4834 non-null   object        \n 5   state                                        4834 non-null   object        \n 6   zipcode                                      4834 non-null   float64       \n 7   county                                       4834 non-null   object        \n 8   agency_responsible                           4834 non-null   object        \n 9   cause_of_death                               4834 non-null   object        \n 10  description_of_circumstances                 4834 non-null   object        \n 11  official_disposition                         4834 non-null   object        \n 12  criminal_charges_filed                       4834 non-null   object        \n 13  mental_illness                               4834 non-null   object        \n 14  armed_unarmed_status                         4834 non-null   object        \n 15  alleged_weapon                               4834 non-null   object        \n 16  fleeing                                      4834 non-null   object        \n 17  body_camera                                  4834 non-null   float64       \n 18  geography                                    4834 non-null   object        \n 19  encounter_type_draft                         4834 non-null   object        \n 20  initial_reported_reason_for_encounter_draft  4834 non-null   object        \n 21  known_past_shootings_of_officer_draft        4834 non-null   object        \n 22  is_female                                    4834 non-null   uint8         \n 23  is_male                                      4834 non-null   uint8         \n 24  is_transgender                               4834 non-null   uint8         \n 25  was_fleeing                                  4834 non-null   float64       \n 26  was_not fleeing                              4834 non-null   float64       \n 27  was_allegedly_armed                          4834 non-null   float64       \n 28  was_unarmed                                  4834 non-null   float64       \n 29  was_vehicle                                  4834 non-null   float64       \n 30  was_domestic_disturbance                     4834 non-null   uint8         \n 31  was_mental_health_welfare_check              4834 non-null   uint8         \n 32  was_person_with_a_weapon                     4834 non-null   uint8         \n 33  was_traffic_stop                             4834 non-null   uint8         \n 34  was_violent_crime_part_1                     4834 non-null   uint8         \n 35  is_asian/pacific islander                    4834 non-null   uint8         \n 36  is_black                                     4834 non-null   uint8         \n 37  is_hispanic                                  4834 non-null   uint8         \n 38  is_native american                           4834 non-null   uint8         \n 39  is_unknown race                              4834 non-null   uint8         \n 40  is_white                                     4834 non-null   uint8         \n 41  mntlill_drug or alcohol use                  4834 non-null   uint8         \n 42  mntlill_no                                   4834 non-null   uint8         \n 43  mntlill_unknown                              4834 non-null   uint8         \n 44  mntlill_yes                                  4834 non-null   uint8         \n 45  rural                                        4834 non-null   float64       \n 46  suburban                                     4834 non-null   float64       \n 47  urban                                        4834 non-null   float64       \n 48  cod_lethal                                   4834 non-null   int64         \n 49  age_bins                                     4834 non-null   category      \n 50  unknown                                      4834 non-null   uint8         \n 51  under 12                                     4834 non-null   uint8         \n 52  12-17                                        4834 non-null   uint8         \n 53  18-24                                        4834 non-null   uint8         \n 54  25-34                                        4834 non-null   uint8         \n 55  35-44                                        4834 non-null   uint8         \n 56  45-54                                        4834 non-null   uint8         \n 57  55-64                                        4834 non-null   uint8         \n 58  65+                                          4834 non-null   uint8         \ndtypes: category(1), datetime64[ns](1), float64(10), int64(2), object(18), uint8(27)\nmemory usage: 1.3+ MB\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "from sklearn.feature_selection import f_regression, RFE, SelectKBest",
   "metadata": {
    "tags": [],
    "cell_id": "00010-a3624a05-3055-40b0-bd52-769edb43f3aa",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "576f2697",
    "execution_start": 1621902006600,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "list(df.columns)",
   "metadata": {
    "tags": [],
    "cell_id": "00011-d305c63a-99ca-4dd8-ba9c-c544bdd68c9b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1039a82",
    "execution_start": 1621902006605,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 14,
     "data": {
      "text/plain": "['age',\n 'gender',\n 'race',\n 'date',\n 'city',\n 'state',\n 'zipcode',\n 'county',\n 'agency_responsible',\n 'cause_of_death',\n 'description_of_circumstances',\n 'official_disposition',\n 'criminal_charges_filed',\n 'mental_illness',\n 'armed_unarmed_status',\n 'alleged_weapon',\n 'alleged_threat_lvl',\n 'fleeing',\n 'body_camera',\n 'geography',\n 'encounter_type_draft',\n 'initial_reported_reason_for_encounter_draft',\n 'known_past_shootings_of_officer_draft',\n 'is_female',\n 'is_male',\n 'is_transgender',\n 'was_fleeing',\n 'was_not fleeing ',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n 'was_domestic_disturbance',\n 'was_mental_health_welfare_check',\n 'was_person_with_a_weapon',\n 'was_traffic_stop',\n 'was_violent_crime_part_1',\n 'is_asian/pacific islander',\n 'is_black',\n 'is_hispanic',\n 'is_native american',\n 'is_unknown race',\n 'is_white',\n 'mntlill_drug or alcohol use',\n 'mntlill_no',\n 'mntlill_unknown',\n 'mntlill_yes',\n 'rural',\n 'suburban',\n 'urban',\n 'cod_lethal',\n 'age_bins',\n 'unknown',\n 'under 12',\n '12-17',\n '18-24',\n '25-34',\n '35-44',\n '45-54',\n '55-64',\n '65+']"
     },
     "metadata": {}
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "dropcols = ['date',\n 'gender',\n 'race',\n 'city',\n 'state',\n 'zipcode',\n 'county',\n 'agency_responsible',\n 'cause_of_death',\n 'description_of_circumstances',\n 'official_disposition',\n 'criminal_charges_filed',\n 'mental_illness',\n 'armed_unarmed_status',\n 'alleged_threat_lvl',\n 'alleged_weapon',\n 'fleeing',\n 'geography',\n 'encounter_type_draft',\n 'initial_reported_reason_for_encounter_draft',\n 'known_past_shootings_of_officer_draft',\n 'age_bins']\n",
   "metadata": {
    "tags": [],
    "cell_id": "00012-775bc13b-cecb-4bf7-81eb-31f4c4d288c9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "368ac104",
    "execution_start": 1621902006640,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "train2 = train.drop(columns=dropcols)\nvalidate2 = validate.drop(columns=dropcols)\ntest2 = test.drop(columns=dropcols)",
   "metadata": {
    "tags": [],
    "cell_id": "00014-06b8fccd-5774-4439-a81a-007dec60dc95",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d330f65b",
    "execution_start": 1621902006641,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "train2.info()",
   "metadata": {
    "tags": [],
    "cell_id": "00014-3c66ed67-6a30-474b-8c08-cfb4ca02b97e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "569ea54a",
    "execution_start": 1621902006641,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 4834 entries, 5595 to 5633\nData columns (total 38 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   age                              4834 non-null   int64  \n 1   body_camera                      4834 non-null   float64\n 2   is_female                        4834 non-null   uint8  \n 3   is_male                          4834 non-null   uint8  \n 4   is_transgender                   4834 non-null   uint8  \n 5   was_fleeing                      4834 non-null   float64\n 6   was_not fleeing                  4834 non-null   float64\n 7   was_allegedly_armed              4834 non-null   float64\n 8   was_unarmed                      4834 non-null   float64\n 9   was_vehicle                      4834 non-null   float64\n 10  was_domestic_disturbance         4834 non-null   uint8  \n 11  was_mental_health_welfare_check  4834 non-null   uint8  \n 12  was_person_with_a_weapon         4834 non-null   uint8  \n 13  was_traffic_stop                 4834 non-null   uint8  \n 14  was_violent_crime_part_1         4834 non-null   uint8  \n 15  is_asian/pacific islander        4834 non-null   uint8  \n 16  is_black                         4834 non-null   uint8  \n 17  is_hispanic                      4834 non-null   uint8  \n 18  is_native american               4834 non-null   uint8  \n 19  is_unknown race                  4834 non-null   uint8  \n 20  is_white                         4834 non-null   uint8  \n 21  mntlill_drug or alcohol use      4834 non-null   uint8  \n 22  mntlill_no                       4834 non-null   uint8  \n 23  mntlill_unknown                  4834 non-null   uint8  \n 24  mntlill_yes                      4834 non-null   uint8  \n 25  rural                            4834 non-null   float64\n 26  suburban                         4834 non-null   float64\n 27  urban                            4834 non-null   float64\n 28  cod_lethal                       4834 non-null   int64  \n 29  unknown                          4834 non-null   uint8  \n 30  under 12                         4834 non-null   uint8  \n 31  12-17                            4834 non-null   uint8  \n 32  18-24                            4834 non-null   uint8  \n 33  25-34                            4834 non-null   uint8  \n 34  35-44                            4834 non-null   uint8  \n 35  45-54                            4834 non-null   uint8  \n 36  55-64                            4834 non-null   uint8  \n 37  65+                              4834 non-null   uint8  \ndtypes: float64(9), int64(2), uint8(27)\nmemory usage: 580.6 KB\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": "train2.columns",
   "metadata": {
    "tags": [],
    "cell_id": "00014-73c67511-909b-4b82-ae40-277da93d8f6c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b18318e7",
    "execution_start": 1621902006646,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 18,
     "data": {
      "text/plain": "Index(['age', 'body_camera', 'is_female', 'is_male', 'is_transgender',\n       'was_fleeing', 'was_not fleeing ', 'was_allegedly_armed', 'was_unarmed',\n       'was_vehicle', 'was_domestic_disturbance',\n       'was_mental_health_welfare_check', 'was_person_with_a_weapon',\n       'was_traffic_stop', 'was_violent_crime_part_1',\n       'is_asian/pacific islander', 'is_black', 'is_hispanic',\n       'is_native american', 'is_unknown race', 'is_white',\n       'mntlill_drug or alcohol use', 'mntlill_no', 'mntlill_unknown',\n       'mntlill_yes', 'rural', 'suburban', 'urban', 'cod_lethal', 'unknown',\n       'under 12', '12-17', '18-24', '25-34', '35-44', '45-54', '55-64',\n       '65+'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "f_feature = select_kbest(train2, y_train, 15)\nf_feature",
   "metadata": {
    "tags": [],
    "cell_id": "00020-3592d1b1-6e38-4bcb-9bb8-7be199f59179",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c5522482",
    "execution_start": 1621902006701,
    "execution_millis": 13,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 19,
     "data": {
      "text/plain": "['age',\n 'body_camera',\n 'is_female',\n 'was_fleeing',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_domestic_disturbance',\n 'was_mental_health_welfare_check',\n 'was_person_with_a_weapon',\n 'was_traffic_stop',\n 'was_violent_crime_part_1',\n 'mntlill_drug or alcohol use',\n 'mntlill_no',\n 'mntlill_unknown',\n '55-64']"
     },
     "metadata": {}
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": "rfe_list = rfe(train2, y_train, 15)",
   "metadata": {
    "tags": [],
    "cell_id": "00019-4661cbe5-93ba-4a7a-bde8-3405d202bee7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ac440bf0",
    "execution_start": 1621902006702,
    "execution_millis": 10620,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=15 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": "f_feature",
   "metadata": {
    "tags": [],
    "cell_id": "00016-e2445307-8f76-4d09-babb-b3623dcc6320",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "adde19a5",
    "execution_start": 1621902017326,
    "execution_millis": 17,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 21,
     "data": {
      "text/plain": "['age',\n 'body_camera',\n 'is_female',\n 'was_fleeing',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_domestic_disturbance',\n 'was_mental_health_welfare_check',\n 'was_person_with_a_weapon',\n 'was_traffic_stop',\n 'was_violent_crime_part_1',\n 'mntlill_drug or alcohol use',\n 'mntlill_no',\n 'mntlill_unknown',\n '55-64']"
     },
     "metadata": {}
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "rfe_list",
   "metadata": {
    "tags": [],
    "cell_id": "00020-db7d45f2-f0ce-4cf3-aec3-a33672cbb6b3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9d8423df",
    "execution_start": 1621902017377,
    "execution_millis": 15,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 22,
     "data": {
      "text/plain": "['is_male',\n 'is_transgender',\n 'was_fleeing',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n 'was_traffic_stop',\n 'was_violent_crime_part_1',\n 'is_black',\n 'is_native american',\n 'is_white',\n 'mntlill_drug or alcohol use',\n 'mntlill_no',\n 'cod_lethal',\n 'under 12']"
     },
     "metadata": {}
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": "combo_feats = list(set(f_feature + rfe_list))",
   "metadata": {
    "tags": [],
    "cell_id": "00022-efcf72a8-2116-43ac-beb5-357156da745f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "75be0d0c",
    "execution_start": 1621910946601,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 112
  },
  {
   "cell_type": "code",
   "source": "len(combo_feats)",
   "metadata": {
    "tags": [],
    "cell_id": "00023-aadd07c2-a6f8-4997-a1b4-9c81e1d91266",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d038553",
    "execution_start": 1621911007642,
    "execution_millis": 18,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 116,
     "data": {
      "text/plain": "23"
     },
     "metadata": {}
    }
   ],
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "source": "combo_feats",
   "metadata": {
    "tags": [],
    "cell_id": "00024-c41b01d4-a2ee-41e7-b811-24a9d990b932",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8d90ad63",
    "execution_start": 1621911028263,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 117,
     "data": {
      "text/plain": "['is_transgender',\n 'was_unarmed',\n 'mntlill_drug or alcohol use',\n 'is_male',\n 'is_black',\n 'was_person_with_a_weapon',\n 'was_traffic_stop',\n 'is_white',\n 'body_camera',\n '55-64',\n 'cod_lethal',\n 'was_domestic_disturbance',\n 'is_native american',\n 'mntlill_no',\n 'was_fleeing',\n 'is_female',\n 'was_mental_health_welfare_check',\n 'mntlill_unknown',\n 'was_vehicle',\n 'was_violent_crime_part_1',\n 'was_allegedly_armed',\n 'under 12',\n 'age']"
     },
     "metadata": {}
    }
   ],
   "execution_count": 117
  },
  {
   "cell_type": "markdown",
   "source": "Modeling\n\nCreate a Baseline Model:",
   "metadata": {
    "tags": [],
    "cell_id": "00023-078ed2ec-d202-41f2-ae33-d35bd29d9685",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "897280cf",
    "execution_start": 1621898463294,
    "execution_millis": 13,
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": "y_train = pd.DataFrame(y_train)\n\ny_train.alleged_threat_lvl.value_counts()\n",
   "metadata": {
    "tags": [],
    "cell_id": "00023-5a407d56-0fcb-48e8-ac40-8c34a89e797f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fa46ff5a",
    "execution_start": 1621902017398,
    "execution_millis": 17,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 23,
     "data": {
      "text/plain": "0.0    2466\n1.0    2368\nName: alleged_threat_lvl, dtype: int64"
     },
     "metadata": {}
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "source": "baseline = 0\nbaseline_accuracy = round((y_train.alleged_threat_lvl == baseline).mean(),4)\nbaseline_accuracy\nprint(f'Baseline accuracy is {baseline_accuracy}')",
   "metadata": {
    "tags": [],
    "cell_id": "00023-ee3157ba-14d0-4f4c-add3-3525628778f2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "71519740",
    "execution_start": 1621902017412,
    "execution_millis": 22,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Baseline accuracy is 0.5101\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": "\n\n\nRandom Forest ",
   "metadata": {
    "tags": [],
    "cell_id": "00023-515ba470-8d61-4094-b604-b79976dbf9f0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# create the model \nrf = RandomForestClassifier(bootstrap=True, \n                            class_weight=None, \n                            criterion='gini',\n                            min_samples_leaf=3,\n                            n_estimators=100,\n                            max_depth=3, \n                            random_state=123)\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00024-d3ef19db-34d5-418f-ada7-9aad1834afac",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5fe20fb4",
    "execution_start": 1621902017431,
    "execution_millis": 44,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": "# fit the model\nrf.fit(train2, y_train)\n\n\n# Find feature importance\nprint(rf.feature_importances_)\n\n",
   "metadata": {
    "tags": [],
    "cell_id": "00025-f804edfc-1bef-44b2-bbcf-46ada16d5e0a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "35f21c7",
    "execution_start": 1621902017475,
    "execution_millis": 355,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  \n[1.96071945e-02 1.22853569e-02 4.84143166e-03 3.34139627e-03\n 2.47178718e-04 3.00992294e-01 0.00000000e+00 1.89830391e-01\n 6.81534886e-02 3.20080971e-03 4.36342151e-02 4.60627880e-03\n 3.30915386e-03 4.74121724e-02 1.56020790e-01 5.80675719e-04\n 1.10264299e-03 1.59446520e-03 1.91198224e-03 5.62825441e-03\n 6.78772459e-03 1.31126551e-02 1.26119560e-02 1.62446707e-02\n 5.37994907e-03 3.70477680e-03 1.74979101e-03 4.47276838e-03\n 5.93582050e-02 1.21445742e-03 0.00000000e+00 5.01111614e-04\n 1.63743177e-03 1.62864183e-03 8.47045404e-04 3.65413333e-04\n 1.29021195e-03 7.93018439e-04]\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": "train2.columns",
   "metadata": {
    "tags": [],
    "cell_id": "00026-ca4a9c6e-9836-498a-ae28-c6186e40a41f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b18318e7",
    "execution_start": 1621902017878,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 27,
     "data": {
      "text/plain": "Index(['age', 'body_camera', 'is_female', 'is_male', 'is_transgender',\n       'was_fleeing', 'was_not fleeing ', 'was_allegedly_armed', 'was_unarmed',\n       'was_vehicle', 'was_domestic_disturbance',\n       'was_mental_health_welfare_check', 'was_person_with_a_weapon',\n       'was_traffic_stop', 'was_violent_crime_part_1',\n       'is_asian/pacific islander', 'is_black', 'is_hispanic',\n       'is_native american', 'is_unknown race', 'is_white',\n       'mntlill_drug or alcohol use', 'mntlill_no', 'mntlill_unknown',\n       'mntlill_yes', 'rural', 'suburban', 'urban', 'cod_lethal', 'unknown',\n       'under 12', '12-17', '18-24', '25-34', '35-44', '45-54', '55-64',\n       '65+'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": "# make predictions\ny_pred = rf.predict(train2)\n\n# estimate probability\ny_pred_proba = rf.predict_proba(train2)\n\n\n#Compute accuracy\ntrain_accuracy = round(rf.score(train2, y_train),2)\nprint('Accuracy of random forest classifier on training set: {:.2f}'\n     .format(rf.score(train2, y_train)))\n",
   "metadata": {
    "tags": [],
    "cell_id": "00027-d3f95a7f-fd59-45c6-a522-728d8e97850e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9330a7f8",
    "execution_start": 1621902017879,
    "execution_millis": 134,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of random forest classifier on training set: 0.70\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": "# run classification report\nprint(classification_report(y_train, y_pred))",
   "metadata": {
    "tags": [],
    "cell_id": "00028-55ef49e9-e134-4cba-b91b-a01bb25a1347",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "571ca5f9",
    "execution_start": 1621902018011,
    "execution_millis": 20,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n         0.0       0.71      0.70      0.71      2466\n         1.0       0.70      0.70      0.70      2368\n\n    accuracy                           0.70      4834\n   macro avg       0.70      0.70      0.70      4834\nweighted avg       0.70      0.70      0.70      4834\n\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "source": "# fit the model on validate\nrf.fit(validate2, y_validate)\n\n# make predictions\ny_pred_val = rf.predict(validate2)\n\n# estimate probability\ny_pred_val_proba = rf.predict_proba(validate2)\n\n#Compute accuracy\nvalidate_accuracy = round(rf.score(validate2, y_validate),2)\nprint('Accuracy of random forest classifier on validate set: {:.2f}'\n     .format(rf.score(validate2, y_validate)))\n",
   "metadata": {
    "tags": [],
    "cell_id": "00032-8cf1818c-8672-4d06-a947-445812a92a61",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3a14f657",
    "execution_start": 1621902018033,
    "execution_millis": 284,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of random forest classifier on validate set: 0.72\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": "# run classification report on validate\nprint(classification_report(y_validate, y_pred_val))",
   "metadata": {
    "tags": [],
    "cell_id": "00032-af4eb133-581a-4f99-9bfc-ec69559453c0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bb080a19",
    "execution_start": 1621902018314,
    "execution_millis": 19,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n         0.0       0.72      0.72      0.72      1053\n         1.0       0.71      0.71      0.71      1020\n\n    accuracy                           0.72      2073\n   macro avg       0.72      0.72      0.72      2073\nweighted avg       0.72      0.72      0.72      2073\n\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": "def get_metrics_bin(clf, X, y):\n    '''\n    get_metrics_bin will take in a sklearn classifier model, an X and a y variable and utilize\n    the model to make a prediction and then gather accuracy, class report evaluations\n\n    return:  a classification report as a pandas DataFrame\n    '''\n    y_pred = clf.predict(X)\n    accuracy = clf.score(X, y)\n    conf = confusion_matrix(y, y_pred)\n    class_report = pd.DataFrame(classification_report(y, y_pred, output_dict=True)).T\n    tpr = conf[1][1] / conf[1].sum()\n    fpr = conf[0][1] / conf[0].sum()\n    tnr = conf[0][0] / conf[0].sum()\n    fnr = conf[1][0] / conf[1].sum()\n    print(f'''\n    The accuracy for our model is {accuracy:.4}\n    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n    ''')\n    return class_report",
   "metadata": {
    "tags": [],
    "cell_id": "00034-3c2f89f9-ae98-4ab6-9f40-5f87b1e4df6b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5201d0f",
    "execution_start": 1621909444833,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": "# X = validate2\n# clf = RandomForestClassifier\n# print('Model #1: min samples 3, max depth 3')\n# class_report_val = get_metrics_bin(clf, validate2, y_validate)\n# # print('-------------------------------------------\\n Model #2: min samples 3, max_depth 3\\n')\n# # class_report_val1 = get_metrics_bin(clf1, X_val, y_val)",
   "metadata": {
    "tags": [],
    "cell_id": "00034-21f54af0-6d73-4293-bb45-c42cc0a79e49",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c1f85ee1",
    "execution_start": 1621910336473,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "source": "### Takeaways on Random Forest Classifier Model (max depth 3):\n\nBaseline accuracy = 51% <br>\nAccuracy on Train = 70% <br>\nAccuracy on Validate = 72%",
   "metadata": {
    "tags": [],
    "cell_id": "00029-b74715f9-548b-430d-8ce6-cbba70590e45",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bb95de7",
    "execution_start": 1621894512751,
    "execution_millis": 11,
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": "\n#begin building a dataframe to record accuracy\nmetric_df = pd.DataFrame(data=[{\n    'model': 'random forest', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(train_accuracy, 2),\n    'validate_accuracy': round(validate_accuracy, 2)}])\nmetric_df",
   "metadata": {
    "tags": [],
    "cell_id": "00032-2b00238d-061d-4bec-ae1a-bb5677d827a1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2e7e6100",
    "execution_start": 1621902018343,
    "execution_millis": 28,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 32,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 1,
       "column_count": 4,
       "columns": [
        {
         "name": "model",
         "dtype": "object",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "categories": [
           {
            "name": "random forest",
            "count": 1
           }
          ]
         }
        },
        {
         "name": "baseline_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.51",
          "max": "0.51",
          "histogram": [
           {
            "bin_start": 0.010000000000000009,
            "bin_end": 0.11000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.11000000000000001,
            "bin_end": 0.21000000000000002,
            "count": 0
           },
           {
            "bin_start": 0.21000000000000002,
            "bin_end": 0.31000000000000005,
            "count": 0
           },
           {
            "bin_start": 0.31000000000000005,
            "bin_end": 0.41000000000000003,
            "count": 0
           },
           {
            "bin_start": 0.41000000000000003,
            "bin_end": 0.51,
            "count": 0
           },
           {
            "bin_start": 0.51,
            "bin_end": 0.6100000000000001,
            "count": 1
           },
           {
            "bin_start": 0.6100000000000001,
            "bin_end": 0.7100000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7100000000000001,
            "bin_end": 0.81,
            "count": 0
           },
           {
            "bin_start": 0.81,
            "bin_end": 0.91,
            "count": 0
           },
           {
            "bin_start": 0.91,
            "bin_end": 1.01,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "train_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.7",
          "max": "0.7",
          "histogram": [
           {
            "bin_start": 0.19999999999999996,
            "bin_end": 0.29999999999999993,
            "count": 0
           },
           {
            "bin_start": 0.29999999999999993,
            "bin_end": 0.39999999999999997,
            "count": 0
           },
           {
            "bin_start": 0.39999999999999997,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6,
            "count": 0
           },
           {
            "bin_start": 0.6,
            "bin_end": 0.7,
            "count": 0
           },
           {
            "bin_start": 0.7,
            "bin_end": 0.8,
            "count": 1
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 0
           },
           {
            "bin_start": 1,
            "bin_end": 1.1,
            "count": 0
           },
           {
            "bin_start": 1.1,
            "bin_end": 1.2,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "validate_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.72",
          "max": "0.72",
          "histogram": [
           {
            "bin_start": 0.21999999999999997,
            "bin_end": 0.31999999999999995,
            "count": 0
           },
           {
            "bin_start": 0.31999999999999995,
            "bin_end": 0.42,
            "count": 0
           },
           {
            "bin_start": 0.42,
            "bin_end": 0.52,
            "count": 0
           },
           {
            "bin_start": 0.52,
            "bin_end": 0.62,
            "count": 0
           },
           {
            "bin_start": 0.62,
            "bin_end": 0.72,
            "count": 0
           },
           {
            "bin_start": 0.72,
            "bin_end": 0.8200000000000001,
            "count": 1
           },
           {
            "bin_start": 0.8200000000000001,
            "bin_end": 0.92,
            "count": 0
           },
           {
            "bin_start": 0.92,
            "bin_end": 1.02,
            "count": 0
           },
           {
            "bin_start": 1.02,
            "bin_end": 1.12,
            "count": 0
           },
           {
            "bin_start": 1.12,
            "bin_end": 1.22,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "model": "random forest",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.72,
         "_deepnote_index_column": 0
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "           model  baseline_accuracy  train_accuracy  validate_accuracy\n0  random forest               0.51             0.7               0.72",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>baseline_accuracy</th>\n      <th>train_accuracy</th>\n      <th>validate_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random forest</td>\n      <td>0.51</td>\n      <td>0.7</td>\n      <td>0.72</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "00037-c7741957-35d0-43c9-b5e6-fff0faebc2a6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1621902018364,
    "execution_millis": 2,
    "deepnote_cell_type": "visualization"
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "source": "### Naive Bayes\nNave Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building fast machine learning models that can make quick predictions. It is a probabilistic classifier, which means it predicts on the basis of the probability of an object. It's biggest limitation is that it implicitly assumes that all the attributes are mutually independent. (In real life, it's almost impossible that we get a set of predictors that are completely independent or one another.)",
   "metadata": {
    "tags": [],
    "cell_id": "00036-bc2283cf-5389-4db5-b928-2d9743c2a13b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "99d3384f",
    "execution_start": 1621900322718,
    "execution_millis": 7,
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": 33
  },
  {
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 47,
     "data": {
      "text/plain": "CategoricalNB()"
     },
     "metadata": {}
    }
   ],
   "cell_type": "code",
   "source": "from sklearn.naive_bayes import CategoricalNB\n\n# make the model\nclassifier = CategoricalNB()\n\n# fit the model\nclassifier.fit(train2, y_train)",
   "metadata": {
    "tags": [],
    "cell_id": "00038-bf577518-5ce8-4a7c-b12c-ad63c5c4e317",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fe51bc76",
    "execution_start": 1621902759010,
    "execution_millis": 27,
    "deepnote_cell_type": "code"
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": "# make predictions on train\nnb_y_pred  =  classifier.predict(train2)\n\n# make predictions on validate\nnb_y_val_pred  =  classifier.predict(validate2)",
   "metadata": {
    "tags": [],
    "cell_id": "00039-f8de9f52-1243-4ab5-99f1-55dad9c3156b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dad90cf1",
    "execution_start": 1621902761764,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": "# evaluate model on train\nfrom sklearn.metrics import confusion_matrix,accuracy_score\ncm_train = confusion_matrix(y_train, nb_y_pred)\nac_train = accuracy_score(y_train,nb_y_pred)",
   "metadata": {
    "tags": [],
    "cell_id": "00040-8012050f-8a4d-4414-b974-95543fe6cd30",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "20ca0f84",
    "execution_start": 1621902763848,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": "# evaluate model on validate\ncm_validate = confusion_matrix(y_validate, nb_y_val_pred)\nac_validate = accuracy_score(y_validate,nb_y_val_pred)",
   "metadata": {
    "tags": [],
    "cell_id": "00041-00cf078f-1b1f-486a-84f1-724cb86ded7a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "85adb028",
    "execution_start": 1621902765314,
    "execution_millis": 5,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": "print('Accuracy of Naive Bayes Gaussian Classifier on train set: {:.2f}'.format(ac_train))\nprint('Accuracy of Naive Bayes Gaussian Classifier on validate set: {:.2f}'.format(ac_validate))",
   "metadata": {
    "tags": [],
    "cell_id": "00042-307e743c-b4e2-46dd-9a4e-be45fb381299",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "98109a86",
    "execution_start": 1621902767780,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of Naive Bayes Gaussian Classifier on train set: 0.70\nAccuracy of Naive Bayes Gaussian Classifier on validate set: 0.68\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": "### Takeaways on Naive Bayes Model:\nBaseline accuracy = 51% <br>\nAccuracy on Train = 70% <br>\nAccuracy on Validate = 68%",
   "metadata": {
    "tags": [],
    "cell_id": "00045-9732d597-06db-4357-a678-493f3cbeec4c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "94e0f3ab",
    "execution_start": 1621902072354,
    "execution_millis": 7,
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": "### Dataframe Summarizing Models",
   "metadata": {
    "tags": [],
    "cell_id": "00035-1f82fffe-df47-4cc4-a31c-a9432e509979",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# append dataframe to record accuracy on Naive Bayes\nmetric_df = metric_df.append({\n    'model': 'naive bayes', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(ac_train, 2),\n    'validate_accuracy':round(ac_validate,2)}, ignore_index=True)\n  \n\n\nmetric_df",
   "metadata": {
    "tags": [],
    "cell_id": "00043-c8dcda21-b9ad-414d-b940-a027a05dced4",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bce38aaf",
    "execution_start": 1621902857559,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 52,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 3,
       "column_count": 4,
       "columns": [
        {
         "name": "model",
         "dtype": "object",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "categories": [
           {
            "name": "naive bayes",
            "count": 2
           },
           {
            "name": "random forest",
            "count": 1
           }
          ]
         }
        },
        {
         "name": "baseline_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.51",
          "max": "0.51",
          "histogram": [
           {
            "bin_start": 0.010000000000000009,
            "bin_end": 0.11000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.11000000000000001,
            "bin_end": 0.21000000000000002,
            "count": 0
           },
           {
            "bin_start": 0.21000000000000002,
            "bin_end": 0.31000000000000005,
            "count": 0
           },
           {
            "bin_start": 0.31000000000000005,
            "bin_end": 0.41000000000000003,
            "count": 0
           },
           {
            "bin_start": 0.41000000000000003,
            "bin_end": 0.51,
            "count": 0
           },
           {
            "bin_start": 0.51,
            "bin_end": 0.6100000000000001,
            "count": 3
           },
           {
            "bin_start": 0.6100000000000001,
            "bin_end": 0.7100000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7100000000000001,
            "bin_end": 0.81,
            "count": 0
           },
           {
            "bin_start": 0.81,
            "bin_end": 0.91,
            "count": 0
           },
           {
            "bin_start": 0.91,
            "bin_end": 1.01,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "train_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0.61",
          "max": "0.7",
          "histogram": [
           {
            "bin_start": 0.61,
            "bin_end": 0.619,
            "count": 1
           },
           {
            "bin_start": 0.619,
            "bin_end": 0.628,
            "count": 0
           },
           {
            "bin_start": 0.628,
            "bin_end": 0.637,
            "count": 0
           },
           {
            "bin_start": 0.637,
            "bin_end": 0.646,
            "count": 0
           },
           {
            "bin_start": 0.646,
            "bin_end": 0.655,
            "count": 0
           },
           {
            "bin_start": 0.655,
            "bin_end": 0.6639999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6639999999999999,
            "bin_end": 0.6729999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6729999999999999,
            "bin_end": 0.6819999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6819999999999999,
            "bin_end": 0.691,
            "count": 0
           },
           {
            "bin_start": 0.691,
            "bin_end": 0.7,
            "count": 2
           }
          ]
         }
        },
        {
         "name": "validate_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 3,
          "nan_count": 0,
          "min": "0.6",
          "max": "0.72",
          "histogram": [
           {
            "bin_start": 0.6,
            "bin_end": 0.612,
            "count": 1
           },
           {
            "bin_start": 0.612,
            "bin_end": 0.624,
            "count": 0
           },
           {
            "bin_start": 0.624,
            "bin_end": 0.636,
            "count": 0
           },
           {
            "bin_start": 0.636,
            "bin_end": 0.648,
            "count": 0
           },
           {
            "bin_start": 0.648,
            "bin_end": 0.6599999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6599999999999999,
            "bin_end": 0.6719999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6719999999999999,
            "bin_end": 0.6839999999999999,
            "count": 1
           },
           {
            "bin_start": 0.6839999999999999,
            "bin_end": 0.696,
            "count": 0
           },
           {
            "bin_start": 0.696,
            "bin_end": 0.708,
            "count": 0
           },
           {
            "bin_start": 0.708,
            "bin_end": 0.72,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "model": "random forest",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.72,
         "_deepnote_index_column": 0
        },
        {
         "model": "naive bayes",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.61,
         "validate_accuracy": 0.6,
         "_deepnote_index_column": 1
        },
        {
         "model": "naive bayes",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.68,
         "_deepnote_index_column": 2
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "           model  baseline_accuracy  train_accuracy  validate_accuracy\n0  random forest               0.51            0.70               0.72\n1    naive bayes               0.51            0.61               0.60\n2    naive bayes               0.51            0.70               0.68",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>baseline_accuracy</th>\n      <th>train_accuracy</th>\n      <th>validate_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random forest</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>naive bayes</td>\n      <td>0.51</td>\n      <td>0.61</td>\n      <td>0.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>naive bayes</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.68</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00046-8a5b83a8-30e3-483a-b5ca-c5cc36802154",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### GridSearchCV",
   "metadata": {
    "tags": [],
    "cell_id": "00046-217bb1dc-a743-42a8-ab02-21847598bdbc",
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom scipy.stats import uniform",
   "metadata": {
    "tags": [],
    "cell_id": "00047-35748be9-71e7-4d9e-bddb-b1cf454b54f1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2264946b",
    "execution_start": 1621907209059,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": "# Create a parameter dictionary for the model, {'parameter': [list of settings]}\nparameters = [\n    {\n    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n    'shuffle': [True, False],\n    'verbose': [0, 1, 5, 10],\n    'class_weight': [None, 'balanced'],\n    },\n]\n# Created variable model which holds the KNN model\nmodel = SGDClassifier()\n# Create grid_search model, looking at recall\ngrid_search = GridSearchCV(model,\n                           param_grid=parameters,\n                           scoring='accuracy',\n                           )\n# Create variable r that hold the FIT grid_search\nr = grid_search.fit(X_train[f_feature], y_train)\nscores = r.cv_results_\nlm = r.best_estimator_",
   "metadata": {
    "tags": [],
    "cell_id": "00048-22ef8f8c-abdc-423c-83c9-d63f8767c7d9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cd3ac985",
    "execution_start": 1621909059997,
    "execution_millis": 55235,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.207421, T: 30936, Avg. loss: 0.970514\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.205892, T: 34803, Avg. loss: 0.960938\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.204843, T: 38670, Avg. loss: 0.971095\nTotal training time: 0.03 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.203705, T: 42537, Avg. loss: 0.960194\nTotal training time: 0.03 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.202595, T: 46404, Avg. loss: 0.962556\nTotal training time: 0.03 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 15, Bias: 0.201685, T: 50271, Avg. loss: 0.957067\nTotal training time: 0.03 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 15, Bias: 0.200439, T: 54138, Avg. loss: 0.956782\nTotal training time: 0.03 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 15, Bias: 0.200114, T: 58005, Avg. loss: 0.948819\nTotal training time: 0.03 seconds.\n-- Epoch 16\nNorm: 0.21, NNZs: 15, Bias: 0.199221, T: 61872, Avg. loss: 0.961388\nTotal training time: 0.04 seconds.\n-- Epoch 17\nNorm: 0.22, NNZs: 15, Bias: 0.198629, T: 65739, Avg. loss: 0.960282\nTotal training time: 0.04 seconds.\n-- Epoch 18\nNorm: 0.22, NNZs: 15, Bias: 0.197912, T: 69606, Avg. loss: 0.961355\nTotal training time: 0.04 seconds.\n-- Epoch 19\nNorm: 0.22, NNZs: 15, Bias: 0.197390, T: 73473, Avg. loss: 0.950290\nTotal training time: 0.04 seconds.\n-- Epoch 20\nNorm: 0.22, NNZs: 15, Bias: 0.196824, T: 77340, Avg. loss: 0.959424\nTotal training time: 0.05 seconds.\nConvergence after 20 epochs took 0.05 seconds\n-- Epoch 1\nNorm: 0.16, NNZs: 15, Bias: -0.689736, T: 3867, Avg. loss: 1.765550\nTotal training time: 0.01 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: -0.688167, T: 7734, Avg. loss: 0.982249\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: -0.691255, T: 11601, Avg. loss: 0.969090\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: -0.692251, T: 15468, Avg. loss: 0.959697\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: -0.693327, T: 19335, Avg. loss: 0.949190\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.694977, T: 23202, Avg. loss: 0.961607\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: -0.696378, T: 27069, Avg. loss: 0.950165\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: -0.697301, T: 30936, Avg. loss: 0.953887\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: -0.697960, T: 34803, Avg. loss: 0.943122\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: -0.698960, T: 38670, Avg. loss: 0.953353\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: -0.700092, T: 42537, Avg. loss: 0.946991\nTotal training time: 0.03 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: -0.700370, T: 46404, Avg. loss: 0.943480\nTotal training time: 0.03 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: -0.700810, T: 50271, Avg. loss: 0.932476\nTotal training time: 0.03 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 15, Bias: -0.701906, T: 54138, Avg. loss: 0.942518\nTotal training time: 0.03 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 15, Bias: -0.702321, T: 58005, Avg. loss: 0.942859\nTotal training time: 0.04 seconds.\n-- Epoch 16\nNorm: 0.22, NNZs: 15, Bias: -0.702764, T: 61872, Avg. loss: 0.942246\nTotal training time: 0.04 seconds.\n-- Epoch 17\nNorm: 0.22, NNZs: 15, Bias: -0.703312, T: 65739, Avg. loss: 0.943223\nTotal training time: 0.04 seconds.\n-- Epoch 18\nNorm: 0.22, NNZs: 15, Bias: -0.703796, T: 69606, Avg. loss: 0.945142\nTotal training time: 0.04 seconds.\nConvergence after 18 epochs took 0.04 seconds\n-- Epoch 1\nNorm: 0.16, NNZs: 15, Bias: -0.680037, T: 3867, Avg. loss: 1.560291\nTotal training time: 0.01 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.679877, T: 7734, Avg. loss: 0.993630\nTotal training time: 0.03 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.681835, T: 11601, Avg. loss: 0.971168\nTotal training time: 0.03 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: -0.683170, T: 15468, Avg. loss: 0.957358\nTotal training time: 0.03 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.684260, T: 19335, Avg. loss: 0.955194\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.686030, T: 23202, Avg. loss: 0.948934\nTotal training time: 0.04 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.686728, T: 27069, Avg. loss: 0.948611\nTotal training time: 0.04 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 15, Bias: -0.687583, T: 30936, Avg. loss: 0.951777\nTotal training time: 0.04 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.688199, T: 34803, Avg. loss: 0.943616\nTotal training time: 0.04 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 15, Bias: -0.688899, T: 38670, Avg. loss: 0.943061\nTotal training time: 0.04 seconds.\n-- Epoch 11\nNorm: 0.20, NNZs: 15, Bias: -0.689361, T: 42537, Avg. loss: 0.929192\nTotal training time: 0.04 seconds.\n-- Epoch 12\nNorm: 0.20, NNZs: 15, Bias: -0.690271, T: 46404, Avg. loss: 0.950181\nTotal training time: 0.04 seconds.\n-- Epoch 13\nNorm: 0.20, NNZs: 15, Bias: -0.691010, T: 50271, Avg. loss: 0.952434\nTotal training time: 0.05 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 15, Bias: -0.691419, T: 54138, Avg. loss: 0.945460\nTotal training time: 0.05 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 15, Bias: -0.692409, T: 58005, Avg. loss: 0.942226\nTotal training time: 0.05 seconds.\n-- Epoch 16\nNorm: 0.21, NNZs: 15, Bias: -0.692564, T: 61872, Avg. loss: 0.948196\nTotal training time: 0.05 seconds.\nConvergence after 16 epochs took 0.05 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: -0.530331, T: 3867, Avg. loss: 2.241020\nTotal training time: 0.01 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: -0.530124, T: 7734, Avg. loss: 0.983895\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: -0.531830, T: 11601, Avg. loss: 0.972480\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: -0.533319, T: 15468, Avg. loss: 0.960002\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: -0.534857, T: 19335, Avg. loss: 0.962982\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.535528, T: 23202, Avg. loss: 0.942459\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: -0.536193, T: 27069, Avg. loss: 0.939646\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 15, Bias: -0.536707, T: 30936, Avg. loss: 0.943688\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: -0.537245, T: 34803, Avg. loss: 0.944024\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: -0.538170, T: 38670, Avg. loss: 0.948916\nTotal training time: 0.03 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: -0.538721, T: 42537, Avg. loss: 0.948113\nTotal training time: 0.03 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: -0.539908, T: 46404, Avg. loss: 0.948352\nTotal training time: 0.03 seconds.\nConvergence after 12 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.16, NNZs: 15, Bias: -0.774841, T: 3868, Avg. loss: 1.840222\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: -0.773426, T: 7736, Avg. loss: 0.983272\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.772568, T: 11604, Avg. loss: 0.957771\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: -0.773011, T: 15472, Avg. loss: 0.957803\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: -0.773691, T: 19340, Avg. loss: 0.951833\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.774661, T: 23208, Avg. loss: 0.952374\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: -0.774895, T: 27076, Avg. loss: 0.940523\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 15, Bias: -0.775618, T: 30944, Avg. loss: 0.942716\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.776505, T: 34812, Avg. loss: 0.949554\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: -0.777187, T: 38680, Avg. loss: 0.947007\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: -0.777871, T: 42548, Avg. loss: 0.950578\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: -0.778586, T: 46416, Avg. loss: 0.947290\nTotal training time: 0.02 seconds.\nConvergence after 12 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 15, Bias: -0.905223, T: 3867, Avg. loss: 1.311422\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.899070, T: 7734, Avg. loss: 0.969841\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.896748, T: 11601, Avg. loss: 0.955577\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 15, Bias: -0.895927, T: 15468, Avg. loss: 0.951618\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.895591, T: 19335, Avg. loss: 0.951667\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.895173, T: 23202, Avg. loss: 0.953631\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.894876, T: 27069, Avg. loss: 0.952417\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 15, Bias: -0.894745, T: 30936, Avg. loss: 0.951819\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.894743, T: 34803, Avg. loss: 0.951205\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 15, Bias: 0.815444, T: 3867, Avg. loss: 1.914033\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.798935, T: 7734, Avg. loss: 0.988788\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.790798, T: 11601, Avg. loss: 0.981051\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.785476, T: 15468, Avg. loss: 0.979066\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.781827, T: 19335, Avg. loss: 0.979000\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.779156, T: 23202, Avg. loss: 0.977237\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.776993, T: 27069, Avg. loss: 0.975920\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.775123, T: 30936, Avg. loss: 0.974840\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.773477, T: 34803, Avg. loss: 0.974083\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.772039, T: 38670, Avg. loss: 0.973455\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.770766, T: 42537, Avg. loss: 0.972627\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.769606, T: 46404, Avg. loss: 0.972288\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.768561, T: 50271, Avg. loss: 0.971908\nTotal training time: 0.02 seconds.\nConvergence after 13 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.819444, T: 3867, Avg. loss: 1.904986\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: 0.802018, T: 7734, Avg. loss: 0.988963\nTotal training time: 0.03 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.793577, T: 11601, Avg. loss: 0.982172\nTotal training time: 0.03 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: 0.788233, T: 15468, Avg. loss: 0.980840\nTotal training time: 0.03 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.784628, T: 19335, Avg. loss: 0.978594\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.781852, T: 23202, Avg. loss: 0.977853\nTotal training time: 0.03 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: 0.779564, T: 27069, Avg. loss: 0.978034\nTotal training time: 0.03 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.777692, T: 30936, Avg. loss: 0.977911\nTotal training time: 0.04 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.776139, T: 34803, Avg. loss: 0.977588\nTotal training time: 0.04 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.774755, T: 38670, Avg. loss: 0.976957\nTotal training time: 0.04 seconds.\nConvergence after 10 epochs took 0.04 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.825833, T: 3867, Avg. loss: 1.906355\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.811119, T: 7734, Avg. loss: 0.987736\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.804096, T: 11601, Avg. loss: 0.979527\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.799536, T: 15468, Avg. loss: 0.977853\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.796495, T: 19335, Avg. loss: 0.976248\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.794229, T: 23202, Avg. loss: 0.976284\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.792378, T: 27069, Avg. loss: 0.976439\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.790919, T: 30936, Avg. loss: 0.976025\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.789638, T: 34803, Avg. loss: 0.974615\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.788497, T: 38670, Avg. loss: 0.974499\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.787519, T: 42537, Avg. loss: 0.973500\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.786606, T: 46404, Avg. loss: 0.972892\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.785811, T: 50271, Avg. loss: 0.972570\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.785076, T: 54138, Avg. loss: 0.971945\nTotal training time: 0.02 seconds.\nConvergence after 14 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.818384, T: 3868, Avg. loss: 1.920305\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: 0.801938, T: 7736, Avg. loss: 0.988807\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.794142, T: 11604, Avg. loss: 0.981883\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.21, NNZs: 15, Bias: 0.789297, T: 15472, Avg. loss: 0.980771\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.21, NNZs: 15, Bias: 0.785937, T: 19340, Avg. loss: 0.978860\nTotal training time: 0.02 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.783290, T: 23208, Avg. loss: 0.977811\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.781096, T: 27076, Avg. loss: 0.976609\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.779229, T: 30944, Avg. loss: 0.974711\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.22, NNZs: 15, Bias: 0.777613, T: 34812, Avg. loss: 0.973673\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.22, NNZs: 15, Bias: 0.776112, T: 38680, Avg. loss: 0.972546\nTotal training time: 0.03 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.774780, T: 42548, Avg. loss: 0.971769\nTotal training time: 0.03 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.773587, T: 46416, Avg. loss: 0.971313\nTotal training time: 0.03 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.772512, T: 50284, Avg. loss: 0.970911\nTotal training time: 0.04 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.771554, T: 54152, Avg. loss: 0.970199\nTotal training time: 0.04 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: 0.770644, T: 58020, Avg. loss: 0.969567\nTotal training time: 0.04 seconds.\nConvergence after 15 epochs took 0.04 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 15, Bias: -0.905223, T: 3867, Avg. loss: 1.311422\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.899070, T: 7734, Avg. loss: 0.969841\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.896748, T: 11601, Avg. loss: 0.955577\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 15, Bias: -0.895927, T: 15468, Avg. loss: 0.951618\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.895591, T: 19335, Avg. loss: 0.951667\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.895173, T: 23202, Avg. loss: 0.953631\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.894876, T: 27069, Avg. loss: 0.952417\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 15, Bias: -0.894745, T: 30936, Avg. loss: 0.951819\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.894743, T: 34803, Avg. loss: 0.951205\nTotal training time: 0.02 seconds.\nConvergence after 9 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 15, Bias: 0.815444, T: 3867, Avg. loss: 1.914033\nTotal training time: 0.02 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.798935, T: 7734, Avg. loss: 0.988788\nTotal training time: 0.02 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.790798, T: 11601, Avg. loss: 0.981051\nTotal training time: 0.02 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.785476, T: 15468, Avg. loss: 0.979066\nTotal training time: 0.02 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.781827, T: 19335, Avg. loss: 0.979000\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.779156, T: 23202, Avg. loss: 0.977237\nTotal training time: 0.03 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.776993, T: 27069, Avg. loss: 0.975920\nTotal training time: 0.03 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.775123, T: 30936, Avg. loss: 0.974840\nTotal training time: 0.03 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.773477, T: 34803, Avg. loss: 0.974083\nTotal training time: 0.03 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.772039, T: 38670, Avg. loss: 0.973455\nTotal training time: 0.03 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.770766, T: 42537, Avg. loss: 0.972627\nTotal training time: 0.04 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.769606, T: 46404, Avg. loss: 0.972288\nTotal training time: 0.04 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.768561, T: 50271, Avg. loss: 0.971908\nTotal training time: 0.04 seconds.\nConvergence after 13 epochs took 0.04 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.819444, T: 3867, Avg. loss: 1.904986\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: 0.802018, T: 7734, Avg. loss: 0.988963\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.793577, T: 11601, Avg. loss: 0.982172\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: 0.788233, T: 15468, Avg. loss: 0.980840\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.784628, T: 19335, Avg. loss: 0.978594\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.781852, T: 23202, Avg. loss: 0.977853\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: 0.779564, T: 27069, Avg. loss: 0.978034\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.777692, T: 30936, Avg. loss: 0.977911\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.776139, T: 34803, Avg. loss: 0.977588\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.774755, T: 38670, Avg. loss: 0.976957\nTotal training time: 0.02 seconds.\nConvergence after 10 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.825833, T: 3867, Avg. loss: 1.906355\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.811119, T: 7734, Avg. loss: 0.987736\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.804096, T: 11601, Avg. loss: 0.979527\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.799536, T: 15468, Avg. loss: 0.977853\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.796495, T: 19335, Avg. loss: 0.976248\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.794229, T: 23202, Avg. loss: 0.976284\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.792378, T: 27069, Avg. loss: 0.976439\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.790919, T: 30936, Avg. loss: 0.976025\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.789638, T: 34803, Avg. loss: 0.974615\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.788497, T: 38670, Avg. loss: 0.974499\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.787519, T: 42537, Avg. loss: 0.973500\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.786606, T: 46404, Avg. loss: 0.972892\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.785811, T: 50271, Avg. loss: 0.972570\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.785076, T: 54138, Avg. loss: 0.971945\nTotal training time: 0.02 seconds.\nConvergence after 14 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.818384, T: 3868, Avg. loss: 1.920305\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: 0.801938, T: 7736, Avg. loss: 0.988807\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.794142, T: 11604, Avg. loss: 0.981883\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.21, NNZs: 15, Bias: 0.789297, T: 15472, Avg. loss: 0.980771\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.21, NNZs: 15, Bias: 0.785937, T: 19340, Avg. loss: 0.978860\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.783290, T: 23208, Avg. loss: 0.977811\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.781096, T: 27076, Avg. loss: 0.976609\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.779229, T: 30944, Avg. loss: 0.974711\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.22, NNZs: 15, Bias: 0.777613, T: 34812, Avg. loss: 0.973673\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.22, NNZs: 15, Bias: 0.776112, T: 38680, Avg. loss: 0.972546\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.774780, T: 42548, Avg. loss: 0.971769\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.773587, T: 46416, Avg. loss: 0.971313\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.772512, T: 50284, Avg. loss: 0.970911\nTotal training time: 0.03 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.771554, T: 54152, Avg. loss: 0.970199\nTotal training time: 0.03 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: 0.770644, T: 58020, Avg. loss: 0.969567\nTotal training time: 0.03 seconds.\nConvergence after 15 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 15, Bias: -0.905223, T: 3867, Avg. loss: 1.311422\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.899070, T: 7734, Avg. loss: 0.969841\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.896748, T: 11601, Avg. loss: 0.955577\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 15, Bias: -0.895927, T: 15468, Avg. loss: 0.951618\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.895591, T: 19335, Avg. loss: 0.951667\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.895173, T: 23202, Avg. loss: 0.953631\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.894876, T: 27069, Avg. loss: 0.952417\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 15, Bias: -0.894745, T: 30936, Avg. loss: 0.951819\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.894743, T: 34803, Avg. loss: 0.951205\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 15, Bias: 0.815444, T: 3867, Avg. loss: 1.914033\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.798935, T: 7734, Avg. loss: 0.988788\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.790798, T: 11601, Avg. loss: 0.981051\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.785476, T: 15468, Avg. loss: 0.979066\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.781827, T: 19335, Avg. loss: 0.979000\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.779156, T: 23202, Avg. loss: 0.977237\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.776993, T: 27069, Avg. loss: 0.975920\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.775123, T: 30936, Avg. loss: 0.974840\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.773477, T: 34803, Avg. loss: 0.974083\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.772039, T: 38670, Avg. loss: 0.973455\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.770766, T: 42537, Avg. loss: 0.972627\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.769606, T: 46404, Avg. loss: 0.972288\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.768561, T: 50271, Avg. loss: 0.971908\nTotal training time: 0.02 seconds.\nConvergence after 13 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.819444, T: 3867, Avg. loss: 1.904986\nTotal training time: 0.02 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: 0.802018, T: 7734, Avg. loss: 0.988963\nTotal training time: 0.02 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.793577, T: 11601, Avg. loss: 0.982172\nTotal training time: 0.02 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: 0.788233, T: 15468, Avg. loss: 0.980840\nTotal training time: 0.02 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.784628, T: 19335, Avg. loss: 0.978594\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.781852, T: 23202, Avg. loss: 0.977853\nTotal training time: 0.03 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: 0.779564, T: 27069, Avg. loss: 0.978034\nTotal training time: 0.03 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.777692, T: 30936, Avg. loss: 0.977911\nTotal training time: 0.03 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.776139, T: 34803, Avg. loss: 0.977588\nTotal training time: 0.03 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.774755, T: 38670, Avg. loss: 0.976957\nTotal training time: 0.03 seconds.\nConvergence after 10 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.825833, T: 3867, Avg. loss: 1.906355\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.811119, T: 7734, Avg. loss: 0.987736\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.804096, T: 11601, Avg. loss: 0.979527\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.799536, T: 15468, Avg. loss: 0.977853\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.796495, T: 19335, Avg. loss: 0.976248\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.794229, T: 23202, Avg. loss: 0.976284\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.792378, T: 27069, Avg. loss: 0.976439\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.790919, T: 30936, Avg. loss: 0.976025\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.789638, T: 34803, Avg. loss: 0.974615\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.788497, T: 38670, Avg. loss: 0.974499\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.787519, T: 42537, Avg. loss: 0.973500\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.786606, T: 46404, Avg. loss: 0.972892\nTotal training time: 0.03 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.785811, T: 50271, Avg. loss: 0.972570\nTotal training time: 0.03 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.785076, T: 54138, Avg. loss: 0.971945\nTotal training time: 0.03 seconds.\nConvergence after 14 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.818384, T: 3868, Avg. loss: 1.920305\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: 0.801938, T: 7736, Avg. loss: 0.988807\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.794142, T: 11604, Avg. loss: 0.981883\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.21, NNZs: 15, Bias: 0.789297, T: 15472, Avg. loss: 0.980771\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.21, NNZs: 15, Bias: 0.785937, T: 19340, Avg. loss: 0.978860\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.783290, T: 23208, Avg. loss: 0.977811\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.781096, T: 27076, Avg. loss: 0.976609\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.779229, T: 30944, Avg. loss: 0.974711\nTotal training time: 0.00 seconds.\n-- Epoch 9\nNorm: 0.22, NNZs: 15, Bias: 0.777613, T: 34812, Avg. loss: 0.973673\nTotal training time: 0.00 seconds.\n-- Epoch 10\nNorm: 0.22, NNZs: 15, Bias: 0.776112, T: 38680, Avg. loss: 0.972546\nTotal training time: 0.00 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.774780, T: 42548, Avg. loss: 0.971769\nTotal training time: 0.00 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.773587, T: 46416, Avg. loss: 0.971313\nTotal training time: 0.00 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.772512, T: 50284, Avg. loss: 0.970911\nTotal training time: 0.03 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.771554, T: 54152, Avg. loss: 0.970199\nTotal training time: 0.03 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: 0.770644, T: 58020, Avg. loss: 0.969567\nTotal training time: 0.03 seconds.\nConvergence after 15 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 7.76, NNZs: 15, Bias: -1.484206, T: 4834, Avg. loss: 38.194082\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 6.36, NNZs: 15, Bias: -0.988164, T: 9668, Avg. loss: 5.213828\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 5.31, NNZs: 15, Bias: -0.543765, T: 14502, Avg. loss: 3.211437\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 4.64, NNZs: 15, Bias: -0.246664, T: 19336, Avg. loss: 2.473782\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 4.12, NNZs: 15, Bias: -0.099296, T: 24170, Avg. loss: 2.071971\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 3.81, NNZs: 15, Bias: 0.031447, T: 29004, Avg. loss: 1.858293\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 3.57, NNZs: 15, Bias: 0.133252, T: 33838, Avg. loss: 1.658053\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 3.39, NNZs: 15, Bias: 0.157422, T: 38672, Avg. loss: 1.512977\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 3.19, NNZs: 15, Bias: 0.159096, T: 43506, Avg. loss: 1.417458\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 3.00, NNZs: 15, Bias: 0.185938, T: 48340, Avg. loss: 1.338357\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 2.89, NNZs: 15, Bias: 0.212993, T: 53174, Avg. loss: 1.277801\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 2.80, NNZs: 15, Bias: 0.241367, T: 58008, Avg. loss: 1.241149\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 2.75, NNZs: 15, Bias: 0.262507, T: 62842, Avg. loss: 1.202404\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 2.71, NNZs: 15, Bias: 0.274651, T: 67676, Avg. loss: 1.155428\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 2.63, NNZs: 15, Bias: 0.294748, T: 72510, Avg. loss: 1.104692\nTotal training time: 0.03 seconds.\n-- Epoch 16\nNorm: 2.58, NNZs: 15, Bias: 0.293179, T: 77344, Avg. loss: 1.088115\nTotal training time: 0.03 seconds.\n-- Epoch 17\nNorm: 2.49, NNZs: 15, Bias: 0.319893, T: 82178, Avg. loss: 1.083899\nTotal training time: 0.03 seconds.\n-- Epoch 18\nNorm: 2.47, NNZs: 15, Bias: 0.336708, T: 87012, Avg. loss: 1.034421\nTotal training time: 0.03 seconds.\n-- Epoch 19\nNorm: 2.42, NNZs: 15, Bias: 0.343792, T: 91846, Avg. loss: 1.025808\nTotal training time: 0.04 seconds.\n-- Epoch 20\nNorm: 2.40, NNZs: 15, Bias: 0.345130, T: 96680, Avg. loss: 1.018647\nTotal training time: 0.04 seconds.\n-- Epoch 21\nNorm: 2.35, NNZs: 15, Bias: 0.341841, T: 101514, Avg. loss: 0.997472\nTotal training time: 0.04 seconds.\n-- Epoch 22\nNorm: 2.31, NNZs: 15, Bias: 0.346815, T: 106348, Avg. loss: 0.979985\nTotal training time: 0.04 seconds.\n-- Epoch 23\nNorm: 2.29, NNZs: 15, Bias: 0.363954, T: 111182, Avg. loss: 0.941413\nTotal training time: 0.04 seconds.\n-- Epoch 24\nNorm: 2.30, NNZs: 15, Bias: 0.353497, T: 116016, Avg. loss: 0.948897\nTotal training time: 0.04 seconds.\n-- Epoch 25\nNorm: 2.27, NNZs: 15, Bias: 0.360883, T: 120850, Avg. loss: 0.928147\nTotal training time: 0.04 seconds.\n-- Epoch 26\nNorm: 2.25, NNZs: 15, Bias: 0.364985, T: 125684, Avg. loss: 0.936033\nTotal training time: 0.05 seconds.\n-- Epoch 27\nNorm: 2.22, NNZs: 15, Bias: 0.361882, T: 130518, Avg. loss: 0.928974\nTotal training time: 0.05 seconds.\n-- Epoch 28\nNorm: 2.21, NNZs: 15, Bias: 0.355873, T: 135352, Avg. loss: 0.923005\nTotal training time: 0.05 seconds.\n-- Epoch 29\nNorm: 2.20, NNZs: 15, Bias: 0.360949, T: 140186, Avg. loss: 0.918711\nTotal training time: 0.05 seconds.\n-- Epoch 30\nNorm: 2.19, NNZs: 15, Bias: 0.359530, T: 145020, Avg. loss: 0.896317\nTotal training time: 0.05 seconds.\n-- Epoch 31\nNorm: 2.17, NNZs: 15, Bias: 0.377117, T: 149854, Avg. loss: 0.899352\nTotal training time: 0.05 seconds.\n-- Epoch 32\nNorm: 2.16, NNZs: 15, Bias: 0.378088, T: 154688, Avg. loss: 0.897375\nTotal training time: 0.06 seconds.\n-- Epoch 33\nNorm: 2.15, NNZs: 15, Bias: 0.384410, T: 159522, Avg. loss: 0.881939\nTotal training time: 0.06 seconds.\n-- Epoch 34\nNorm: 2.16, NNZs: 15, Bias: 0.378265, T: 164356, Avg. loss: 0.875771\nTotal training time: 0.06 seconds.\n-- Epoch 35\nNorm: 2.15, NNZs: 15, Bias: 0.375666, T: 169190, Avg. loss: 0.867884\nTotal training time: 0.06 seconds.\n-- Epoch 36\nNorm: 2.14, NNZs: 15, Bias: 0.376144, T: 174024, Avg. loss: 0.861593\nTotal training time: 0.06 seconds.\n-- Epoch 37\nNorm: 2.12, NNZs: 15, Bias: 0.377800, T: 178858, Avg. loss: 0.865575\nTotal training time: 0.06 seconds.\n-- Epoch 38\nNorm: 2.11, NNZs: 15, Bias: 0.384437, T: 183692, Avg. loss: 0.853236\nTotal training time: 0.07 seconds.\n-- Epoch 39\nNorm: 2.10, NNZs: 15, Bias: 0.381429, T: 188526, Avg. loss: 0.857174\nTotal training time: 0.07 seconds.\n-- Epoch 40\nNorm: 2.09, NNZs: 15, Bias: 0.389254, T: 193360, Avg. loss: 0.854853\nTotal training time: 0.07 seconds.\n-- Epoch 41\nNorm: 2.08, NNZs: 15, Bias: 0.396873, T: 198194, Avg. loss: 0.847469\nTotal training time: 0.08 seconds.\n-- Epoch 42\nNorm: 2.07, NNZs: 15, Bias: 0.398270, T: 203028, Avg. loss: 0.839240\nTotal training time: 0.08 seconds.\n-- Epoch 43\nNorm: 2.06, NNZs: 15, Bias: 0.401218, T: 207862, Avg. loss: 0.840239\nTotal training time: 0.08 seconds.\n-- Epoch 44\nNorm: 2.05, NNZs: 15, Bias: 0.405107, T: 212696, Avg. loss: 0.837145\nTotal training time: 0.08 seconds.\n-- Epoch 45\nNorm: 2.04, NNZs: 15, Bias: 0.408831, T: 217530, Avg. loss: 0.832921\nTotal training time: 0.08 seconds.\n-- Epoch 46\nNorm: 2.03, NNZs: 15, Bias: 0.409735, T: 222364, Avg. loss: 0.830841\nTotal training time: 0.09 seconds.\n-- Epoch 47\nNorm: 2.04, NNZs: 15, Bias: 0.406589, T: 227198, Avg. loss: 0.827492\nTotal training time: 0.09 seconds.\n-- Epoch 48\nNorm: 2.04, NNZs: 15, Bias: 0.408732, T: 232032, Avg. loss: 0.827889\nTotal training time: 0.09 seconds.\n-- Epoch 49\nNorm: 2.04, NNZs: 15, Bias: 0.409178, T: 236866, Avg. loss: 0.814791\nTotal training time: 0.09 seconds.\n-- Epoch 50\nNorm: 2.03, NNZs: 15, Bias: 0.409048, T: 241700, Avg. loss: 0.815170\nTotal training time: 0.09 seconds.\n-- Epoch 51\nNorm: 2.02, NNZs: 15, Bias: 0.406188, T: 246534, Avg. loss: 0.815502\nTotal training time: 0.10 seconds.\n-- Epoch 52\nNorm: 2.02, NNZs: 15, Bias: 0.410626, T: 251368, Avg. loss: 0.814420\nTotal training time: 0.10 seconds.\n-- Epoch 53\nNorm: 2.01, NNZs: 15, Bias: 0.417316, T: 256202, Avg. loss: 0.806459\nTotal training time: 0.10 seconds.\n-- Epoch 54\nNorm: 2.01, NNZs: 15, Bias: 0.425435, T: 261036, Avg. loss: 0.801904\nTotal training time: 0.10 seconds.\n-- Epoch 55\nNorm: 2.01, NNZs: 15, Bias: 0.426553, T: 265870, Avg. loss: 0.809705\nTotal training time: 0.10 seconds.\n-- Epoch 56\nNorm: 2.01, NNZs: 15, Bias: 0.424308, T: 270704, Avg. loss: 0.804182\nTotal training time: 0.11 seconds.\n-- Epoch 57\nNorm: 2.01, NNZs: 15, Bias: 0.423255, T: 275538, Avg. loss: 0.801258\nTotal training time: 0.11 seconds.\n-- Epoch 58\nNorm: 2.00, NNZs: 15, Bias: 0.429339, T: 280372, Avg. loss: 0.800834\nTotal training time: 0.11 seconds.\n-- Epoch 59\nNorm: 2.00, NNZs: 15, Bias: 0.436415, T: 285206, Avg. loss: 0.795910\nTotal training time: 0.11 seconds.\n-- Epoch 60\nNorm: 2.00, NNZs: 15, Bias: 0.433690, T: 290040, Avg. loss: 0.804779\nTotal training time: 0.11 seconds.\n-- Epoch 61\nNorm: 2.00, NNZs: 15, Bias: 0.440147, T: 294874, Avg. loss: 0.801540\nTotal training time: 0.11 seconds.\n-- Epoch 62\nNorm: 1.99, NNZs: 15, Bias: 0.440812, T: 299708, Avg. loss: 0.784128\nTotal training time: 0.11 seconds.\n-- Epoch 63\nNorm: 1.99, NNZs: 15, Bias: 0.444431, T: 304542, Avg. loss: 0.793314\nTotal training time: 0.11 seconds.\n-- Epoch 64\nNorm: 2.00, NNZs: 15, Bias: 0.442535, T: 309376, Avg. loss: 0.792470\nTotal training time: 0.11 seconds.\n-- Epoch 65\nNorm: 1.98, NNZs: 15, Bias: 0.444762, T: 314210, Avg. loss: 0.785490\nTotal training time: 0.11 seconds.\n-- Epoch 66\nNorm: 1.98, NNZs: 15, Bias: 0.446318, T: 319044, Avg. loss: 0.784130\nTotal training time: 0.11 seconds.\n-- Epoch 67\nNorm: 1.98, NNZs: 15, Bias: 0.442956, T: 323878, Avg. loss: 0.778814\nTotal training time: 0.11 seconds.\n-- Epoch 68\nNorm: 1.98, NNZs: 15, Bias: 0.445143, T: 328712, Avg. loss: 0.786940\nTotal training time: 0.12 seconds.\n-- Epoch 69\nNorm: 1.98, NNZs: 15, Bias: 0.445450, T: 333546, Avg. loss: 0.786098\nTotal training time: 0.12 seconds.\n-- Epoch 70\nNorm: 1.98, NNZs: 15, Bias: 0.448123, T: 338380, Avg. loss: 0.779103\nTotal training time: 0.12 seconds.\n-- Epoch 71\nNorm: 1.97, NNZs: 15, Bias: 0.449631, T: 343214, Avg. loss: 0.778796\nTotal training time: 0.12 seconds.\n-- Epoch 72\nNorm: 1.97, NNZs: 15, Bias: 0.454033, T: 348048, Avg. loss: 0.779160\nTotal training time: 0.12 seconds.\nConvergence after 72 epochs took 0.12 seconds\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "source": "# Returns max value of the mean test score \nmax(scores['mean_test_score'])",
   "metadata": {
    "tags": [],
    "cell_id": "00049-17ec2782-a3dc-4b89-a678-94576b39c441",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "32c9439c",
    "execution_start": 1621909115239,
    "execution_millis": 19,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 87,
     "data": {
      "text/plain": "0.6892799869824284"
     },
     "metadata": {}
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "code",
   "source": "# loop that runs all of the possible parameter configurations from the parameter dictionary above\nfor mean_score, params in sorted(list(zip(scores[\"mean_test_score\"], scores[\"params\"])),key = lambda x: x[0]):\n     print(f'Best parameters for SGD Classifier are {params} with a score of {mean_score}')",
   "metadata": {
    "tags": [],
    "cell_id": "00050-9c7659bd-9c73-4b11-8197-2001238ca999",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "46f0d3fb",
    "execution_start": 1621909115255,
    "execution_millis": 20,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Best parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5161302271009569\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5219448851434823\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5248211689693638\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5252346053299248\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.5252348194347205\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5289533915270168\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5343428374452159\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5380704019389331\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5397125857222076\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5502679521518602\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5537762733347465\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5603938243612718\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5670265768282944\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5994981383588011\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5998991566412096\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6011576646305301\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6115158405433123\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6144088245432608\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6185427599392799\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6212250648202269\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6259625616354181\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6301296832747756\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.637365568951379\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6398508974202514\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6443991255960142\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.644608734191037\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.646049231256731\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6598868242049754\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.660947713467834\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6615662622227075\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.666928088622257\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6673488045458731\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6679787008549204\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6685993906577513\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6750028368885435\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6772847658014692\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6824526132560844\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6824571094567947\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6828666919310326\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6892799869824284\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 88
  },
  {
   "cell_type": "markdown",
   "source": "Best parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} using f_feature from Select K Best\n",
   "metadata": {
    "tags": [],
    "cell_id": "00051-c3636cb1-861e-4d20-ac55-4f50c27ad9cc",
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "# Create a parameter dictionary for the model, {'parameter': [list of settings]}\nparameters = [\n    {\n    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n    'shuffle': [True, False],\n    'verbose': [0, 1, 5, 10],\n    'class_weight': [None, 'balanced'],\n    },\n]\n# Created variable model which holds the KNN model\nmodel = SGDClassifier()\n# Create grid_search model, looking at recall\ngrid_search = GridSearchCV(model,\n                           param_grid=parameters,\n                           scoring='accuracy',\n                           )\n# Create variable r that hold the FIT grid_search\nr = grid_search.fit(X_train[rfe_list], y_train)\nscores = r.cv_results_\nlm = r.best_estimator_",
   "metadata": {
    "tags": [],
    "cell_id": "00049-3e3bd1e4-f867-4c2a-aa7d-34e78b11a543",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6f44e136",
    "is_output_hidden": true,
    "allow_embed": false,
    "execution_start": 1621909141548,
    "execution_millis": 26365,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Total training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.012585, T: 27069, Avg. loss: 0.945377\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.24, NNZs: 15, Bias: 0.028819, T: 3868, Avg. loss: 0.948445\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.24, NNZs: 15, Bias: 0.013260, T: 7736, Avg. loss: 0.944546\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.24, NNZs: 15, Bias: 0.004584, T: 11604, Avg. loss: 0.944139\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.24, NNZs: 15, Bias: -0.001461, T: 15472, Avg. loss: 0.943921\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.24, NNZs: 15, Bias: -0.006104, T: 19340, Avg. loss: 0.943775\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.24, NNZs: 15, Bias: -0.009876, T: 23208, Avg. loss: 0.943666\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.24, NNZs: 15, Bias: -0.013052, T: 27076, Avg. loss: 0.943579\nTotal training time: 0.02 seconds.\nConvergence after 7 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.20, NNZs: 15, Bias: -0.759855, T: 3867, Avg. loss: 0.939707\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: -0.760235, T: 7734, Avg. loss: 0.939062\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: -0.760101, T: 11601, Avg. loss: 0.939003\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: -0.760030, T: 15468, Avg. loss: 0.938976\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: -0.759891, T: 19335, Avg. loss: 0.938968\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.759812, T: 23202, Avg. loss: 0.938962\nTotal training time: 0.02 seconds.\nConvergence after 6 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.027397, T: 3867, Avg. loss: 0.947323\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.24, NNZs: 15, Bias: 0.011667, T: 7734, Avg. loss: 0.944687\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.24, NNZs: 15, Bias: 0.002891, T: 11601, Avg. loss: 0.944488\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.24, NNZs: 15, Bias: -0.003225, T: 15468, Avg. loss: 0.944357\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.24, NNZs: 15, Bias: -0.007925, T: 19335, Avg. loss: 0.944257\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.24, NNZs: 15, Bias: -0.011743, T: 23202, Avg. loss: 0.944177\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.24, NNZs: 15, Bias: -0.014958, T: 27069, Avg. loss: 0.944110\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.029448, T: 3867, Avg. loss: 0.951113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.013861, T: 7734, Avg. loss: 0.948007\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.005133, T: 11601, Avg. loss: 0.947681\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.000960, T: 15468, Avg. loss: 0.947495\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.005646, T: 19335, Avg. loss: 0.947366\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.009455, T: 23202, Avg. loss: 0.947266\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.012663, T: 27069, Avg. loss: 0.947186\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.028962, T: 3867, Avg. loss: 0.949495\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.013492, T: 7734, Avg. loss: 0.946165\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.004883, T: 11601, Avg. loss: 0.945848\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.001108, T: 15468, Avg. loss: 0.945670\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.005708, T: 19335, Avg. loss: 0.945547\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.009442, T: 23202, Avg. loss: 0.945453\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.012585, T: 27069, Avg. loss: 0.945377\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.24, NNZs: 15, Bias: 0.028819, T: 3868, Avg. loss: 0.948445\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.24, NNZs: 15, Bias: 0.013260, T: 7736, Avg. loss: 0.944546\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.24, NNZs: 15, Bias: 0.004584, T: 11604, Avg. loss: 0.944139\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.24, NNZs: 15, Bias: -0.001461, T: 15472, Avg. loss: 0.943921\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.24, NNZs: 15, Bias: -0.006104, T: 19340, Avg. loss: 0.943775\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.24, NNZs: 15, Bias: -0.009876, T: 23208, Avg. loss: 0.943666\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.24, NNZs: 15, Bias: -0.013052, T: 27076, Avg. loss: 0.943579\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.636835, T: 3867, Avg. loss: 0.964332\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.638614, T: 7734, Avg. loss: 0.963472\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.638740, T: 11601, Avg. loss: 0.962514\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.638532, T: 15468, Avg. loss: 0.961997\nTotal training time: 0.03 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.638775, T: 19335, Avg. loss: 0.962302\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.638911, T: 23202, Avg. loss: 0.962358\nTotal training time: 0.03 seconds.\nConvergence after 6 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.059704, T: 3867, Avg. loss: 0.952497\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.061529, T: 7734, Avg. loss: 0.949640\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.061660, T: 11601, Avg. loss: 0.948496\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.061359, T: 15468, Avg. loss: 0.948018\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.061104, T: 19335, Avg. loss: 0.948180\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.060975, T: 23202, Avg. loss: 0.948016\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.060757, T: 27069, Avg. loss: 0.947894\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.23, NNZs: 15, Bias: 0.060857, T: 30936, Avg. loss: 0.948239\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.737084, T: 3867, Avg. loss: 0.969545\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.739135, T: 7734, Avg. loss: 0.965427\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.739268, T: 11601, Avg. loss: 0.964859\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.738717, T: 15468, Avg. loss: 0.964495\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.738909, T: 19335, Avg. loss: 0.964934\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.738935, T: 23202, Avg. loss: 0.964700\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.738797, T: 27069, Avg. loss: 0.964561\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.455414, T: 3867, Avg. loss: 0.943528\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.455830, T: 7734, Avg. loss: 0.938878\nTotal training time: 0.02 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.455926, T: 11601, Avg. loss: 0.938436\nTotal training time: 0.03 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.455782, T: 15468, Avg. loss: 0.938810\nTotal training time: 0.03 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.455717, T: 19335, Avg. loss: 0.938656\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.455772, T: 23202, Avg. loss: 0.938544\nTotal training time: 0.03 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.455720, T: 27069, Avg. loss: 0.938445\nTotal training time: 0.03 seconds.\nConvergence after 7 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.315999, T: 3868, Avg. loss: 0.956235\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.319792, T: 7736, Avg. loss: 0.953913\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.320995, T: 11604, Avg. loss: 0.952845\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.320593, T: 15472, Avg. loss: 0.952315\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.320673, T: 19340, Avg. loss: 0.952605\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.320734, T: 23208, Avg. loss: 0.952407\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.320813, T: 27076, Avg. loss: 0.952414\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.23, NNZs: 15, Bias: 0.320896, T: 30944, Avg. loss: 0.952426\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.499618, T: 3867, Avg. loss: 0.967524\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.497841, T: 7734, Avg. loss: 0.958994\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.497710, T: 11601, Avg. loss: 0.958871\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.497887, T: 15468, Avg. loss: 0.959150\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.497759, T: 19335, Avg. loss: 0.959045\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.497685, T: 23202, Avg. loss: 0.959271\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.497633, T: 27069, Avg. loss: 0.959248\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.470896, T: 3867, Avg. loss: 0.959935\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.471962, T: 7734, Avg. loss: 0.956446\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.471358, T: 11601, Avg. loss: 0.956138\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.471178, T: 15468, Avg. loss: 0.956415\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.471438, T: 19335, Avg. loss: 0.956769\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.471562, T: 23202, Avg. loss: 0.956556\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.471382, T: 27069, Avg. loss: 0.956259\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.382343, T: 3867, Avg. loss: 0.966728\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.381844, T: 7734, Avg. loss: 0.957523\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.380999, T: 11601, Avg. loss: 0.957804\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.380646, T: 15468, Avg. loss: 0.957303\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.380892, T: 19335, Avg. loss: 0.957789\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.380994, T: 23202, Avg. loss: 0.957535\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.381226, T: 27069, Avg. loss: 0.957671\nTotal training time: 0.02 seconds.\nConvergence after 7 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.496964, T: 3867, Avg. loss: 0.962861\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.494818, T: 7734, Avg. loss: 0.957562\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.494653, T: 11601, Avg. loss: 0.958050\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.494985, T: 15468, Avg. loss: 0.957509\nTotal training time: 0.02 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.495207, T: 19335, Avg. loss: 0.957436\nTotal training time: 0.02 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.495271, T: 23202, Avg. loss: 0.957477\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.495088, T: 27069, Avg. loss: 0.957366\nTotal training time: 0.02 seconds.\nConvergence after 7 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.179270, T: 3868, Avg. loss: 0.946252\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.177405, T: 7736, Avg. loss: 0.942485\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.176609, T: 11604, Avg. loss: 0.942973\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.177046, T: 15472, Avg. loss: 0.942424\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.176860, T: 19340, Avg. loss: 0.942560\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.176776, T: 23208, Avg. loss: 0.942304\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.176682, T: 27076, Avg. loss: 0.942484\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.197497, T: 3867, Avg. loss: 0.959922\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.197390, T: 7734, Avg. loss: 0.953638\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.196564, T: 11601, Avg. loss: 0.953455\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.197106, T: 15468, Avg. loss: 0.953474\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.196869, T: 19335, Avg. loss: 0.952971\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.196945, T: 23202, Avg. loss: 0.953258\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.196835, T: 27069, Avg. loss: 0.953066\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.437443, T: 3867, Avg. loss: 0.944034\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.435416, T: 7734, Avg. loss: 0.938310\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.434628, T: 11601, Avg. loss: 0.938458\nTotal training time: 0.03 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.434123, T: 15468, Avg. loss: 0.938351\nTotal training time: 0.03 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.433994, T: 19335, Avg. loss: 0.938103\nTotal training time: 0.03 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.433878, T: 23202, Avg. loss: 0.938282\nTotal training time: 0.03 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.433968, T: 27069, Avg. loss: 0.937883\nTotal training time: 0.03 seconds.\nConvergence after 7 epochs took 0.03 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.012653, T: 3867, Avg. loss: 0.955441\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.012253, T: 7734, Avg. loss: 0.950351\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.012151, T: 11601, Avg. loss: 0.950199\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.012218, T: 15468, Avg. loss: 0.950005\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.012076, T: 19335, Avg. loss: 0.949911\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.012282, T: 23202, Avg. loss: 0.950181\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.012277, T: 27069, Avg. loss: 0.949999\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.633363, T: 3867, Avg. loss: 0.958975\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.634165, T: 7734, Avg. loss: 0.961207\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.633937, T: 11601, Avg. loss: 0.960525\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.634113, T: 15468, Avg. loss: 0.960552\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.634135, T: 19335, Avg. loss: 0.960319\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.634185, T: 23202, Avg. loss: 0.960405\nTotal training time: 0.01 seconds.\nConvergence after 6 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.060119, T: 3868, Avg. loss: 0.943906\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066677, T: 7736, Avg. loss: 0.948665\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.067272, T: 11604, Avg. loss: 0.947426\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.067058, T: 15472, Avg. loss: 0.947127\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.067487, T: 19340, Avg. loss: 0.947560\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.067560, T: 23208, Avg. loss: 0.947245\nTotal training time: 0.00 seconds.\nConvergence after 6 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.686357, T: 3867, Avg. loss: 0.938113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.687095, T: 7734, Avg. loss: 0.935787\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.687238, T: 11601, Avg. loss: 0.935483\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.687264, T: 15468, Avg. loss: 0.935366\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.687202, T: 19335, Avg. loss: 0.935303\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.687182, T: 23202, Avg. loss: 0.935273\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.687155, T: 27069, Avg. loss: 0.935245\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.068531, T: 3867, Avg. loss: 0.948325\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066960, T: 7734, Avg. loss: 0.947785\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.066467, T: 11601, Avg. loss: 0.947867\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.066228, T: 15468, Avg. loss: 0.947903\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.066086, T: 19335, Avg. loss: 0.947923\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065993, T: 23202, Avg. loss: 0.947935\nTotal training time: 0.00 seconds.\nConvergence after 6 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.070583, T: 3867, Avg. loss: 0.952059\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.069155, T: 7734, Avg. loss: 0.951020\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.068710, T: 11601, Avg. loss: 0.950973\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.068494, T: 15468, Avg. loss: 0.950953\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.068366, T: 19335, Avg. loss: 0.950942\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.068282, T: 23202, Avg. loss: 0.950935\nTotal training time: 0.02 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.068222, T: 27069, Avg. loss: 0.950930\nTotal training time: 0.02 seconds.\nConvergence after 7 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.065962, T: 3867, Avg. loss: 0.950180\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.064292, T: 7734, Avg. loss: 0.948885\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.063756, T: 11601, Avg. loss: 0.948837\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.063493, T: 15468, Avg. loss: 0.948819\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.063336, T: 19335, Avg. loss: 0.948810\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.063233, T: 23202, Avg. loss: 0.948805\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.063159, T: 27069, Avg. loss: 0.948801\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.067849, T: 3868, Avg. loss: 0.949250\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066266, T: 7736, Avg. loss: 0.947401\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.065766, T: 11604, Avg. loss: 0.947267\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.065523, T: 15472, Avg. loss: 0.947213\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.065379, T: 19340, Avg. loss: 0.947183\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065283, T: 23208, Avg. loss: 0.947164\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.065216, T: 27076, Avg. loss: 0.947151\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.686357, T: 3867, Avg. loss: 0.938113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.687095, T: 7734, Avg. loss: 0.935787\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.687238, T: 11601, Avg. loss: 0.935483\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.687264, T: 15468, Avg. loss: 0.935366\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.687202, T: 19335, Avg. loss: 0.935303\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.687182, T: 23202, Avg. loss: 0.935273\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.687155, T: 27069, Avg. loss: 0.935245\nTotal training time: 0.02 seconds.\nConvergence after 7 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.068531, T: 3867, Avg. loss: 0.948325\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066960, T: 7734, Avg. loss: 0.947785\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.066467, T: 11601, Avg. loss: 0.947867\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.066228, T: 15468, Avg. loss: 0.947903\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.066086, T: 19335, Avg. loss: 0.947923\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065993, T: 23202, Avg. loss: 0.947935\nTotal training time: 0.01 seconds.\nConvergence after 6 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.070583, T: 3867, Avg. loss: 0.952059\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.069155, T: 7734, Avg. loss: 0.951020\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.068710, T: 11601, Avg. loss: 0.950973\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.068494, T: 15468, Avg. loss: 0.950953\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.068366, T: 19335, Avg. loss: 0.950942\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.068282, T: 23202, Avg. loss: 0.950935\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.068222, T: 27069, Avg. loss: 0.950930\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.065962, T: 3867, Avg. loss: 0.950180\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.064292, T: 7734, Avg. loss: 0.948885\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.063756, T: 11601, Avg. loss: 0.948837\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.063493, T: 15468, Avg. loss: 0.948819\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.063336, T: 19335, Avg. loss: 0.948810\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.063233, T: 23202, Avg. loss: 0.948805\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.063159, T: 27069, Avg. loss: 0.948801\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.067849, T: 3868, Avg. loss: 0.949250\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066266, T: 7736, Avg. loss: 0.947401\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.065766, T: 11604, Avg. loss: 0.947267\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.065523, T: 15472, Avg. loss: 0.947213\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.065379, T: 19340, Avg. loss: 0.947183\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065283, T: 23208, Avg. loss: 0.947164\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.065216, T: 27076, Avg. loss: 0.947151\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.686357, T: 3867, Avg. loss: 0.938113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.687095, T: 7734, Avg. loss: 0.935787\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.687238, T: 11601, Avg. loss: 0.935483\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.687264, T: 15468, Avg. loss: 0.935366\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.687202, T: 19335, Avg. loss: 0.935303\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.687182, T: 23202, Avg. loss: 0.935273\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.687155, T: 27069, Avg. loss: 0.935245\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.068531, T: 3867, Avg. loss: 0.948325\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066960, T: 7734, Avg. loss: 0.947785\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.066467, T: 11601, Avg. loss: 0.947867\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.066228, T: 15468, Avg. loss: 0.947903\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.066086, T: 19335, Avg. loss: 0.947923\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065993, T: 23202, Avg. loss: 0.947935\nTotal training time: 0.00 seconds.\nConvergence after 6 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.070583, T: 3867, Avg. loss: 0.952059\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.069155, T: 7734, Avg. loss: 0.951020\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.068710, T: 11601, Avg. loss: 0.950973\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.068494, T: 15468, Avg. loss: 0.950953\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.068366, T: 19335, Avg. loss: 0.950942\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.068282, T: 23202, Avg. loss: 0.950935\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.068222, T: 27069, Avg. loss: 0.950930\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.065962, T: 3867, Avg. loss: 0.950180\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.064292, T: 7734, Avg. loss: 0.948885\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.063756, T: 11601, Avg. loss: 0.948837\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.063493, T: 15468, Avg. loss: 0.948819\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.063336, T: 19335, Avg. loss: 0.948810\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.063233, T: 23202, Avg. loss: 0.948805\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.063159, T: 27069, Avg. loss: 0.948801\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.067849, T: 3868, Avg. loss: 0.949250\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066266, T: 7736, Avg. loss: 0.947401\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.065766, T: 11604, Avg. loss: 0.947267\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.065523, T: 15472, Avg. loss: 0.947213\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.065379, T: 19340, Avg. loss: 0.947183\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065283, T: 23208, Avg. loss: 0.947164\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.065216, T: 27076, Avg. loss: 0.947151\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 22.41, NNZs: 15, Bias: -12.322759, T: 4834, Avg. loss: 5.428138\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 11.54, NNZs: 15, Bias: -6.809244, T: 9668, Avg. loss: 2.249223\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 8.50, NNZs: 15, Bias: -2.411777, T: 14502, Avg. loss: 1.669622\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 7.60, NNZs: 15, Bias: -3.653883, T: 19336, Avg. loss: 1.410815\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 5.92, NNZs: 15, Bias: -3.557178, T: 24170, Avg. loss: 1.245135\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 5.13, NNZs: 15, Bias: -3.624255, T: 29004, Avg. loss: 1.125119\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 5.17, NNZs: 15, Bias: -3.302463, T: 33838, Avg. loss: 1.070980\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 5.48, NNZs: 15, Bias: -2.883837, T: 38672, Avg. loss: 1.016585\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 5.37, NNZs: 15, Bias: -2.518356, T: 43506, Avg. loss: 0.980750\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 4.66, NNZs: 15, Bias: -2.977559, T: 48340, Avg. loss: 0.944404\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 4.69, NNZs: 15, Bias: -1.725383, T: 53174, Avg. loss: 0.907599\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 4.90, NNZs: 15, Bias: -2.186481, T: 58008, Avg. loss: 0.901472\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 4.64, NNZs: 15, Bias: -1.879070, T: 62842, Avg. loss: 0.887243\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 4.41, NNZs: 15, Bias: -2.004472, T: 67676, Avg. loss: 0.868756\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 4.08, NNZs: 15, Bias: -1.738849, T: 72510, Avg. loss: 0.862628\nTotal training time: 0.02 seconds.\n-- Epoch 16\nNorm: 3.87, NNZs: 15, Bias: -2.127357, T: 77344, Avg. loss: 0.845252\nTotal training time: 0.02 seconds.\n-- Epoch 17\nNorm: 4.07, NNZs: 15, Bias: -1.907798, T: 82178, Avg. loss: 0.838834\nTotal training time: 0.02 seconds.\n-- Epoch 18\nNorm: 4.41, NNZs: 15, Bias: -1.683212, T: 87012, Avg. loss: 0.827170\nTotal training time: 0.02 seconds.\n-- Epoch 19\nNorm: 3.99, NNZs: 15, Bias: -1.816716, T: 91846, Avg. loss: 0.816539\nTotal training time: 0.02 seconds.\n-- Epoch 20\nNorm: 4.15, NNZs: 15, Bias: -1.752213, T: 96680, Avg. loss: 0.812192\nTotal training time: 0.02 seconds.\n-- Epoch 21\nNorm: 4.04, NNZs: 15, Bias: -2.052219, T: 101514, Avg. loss: 0.795656\nTotal training time: 0.03 seconds.\n-- Epoch 22\nNorm: 3.85, NNZs: 15, Bias: -1.758133, T: 106348, Avg. loss: 0.804647\nTotal training time: 0.03 seconds.\n-- Epoch 23\nNorm: 3.88, NNZs: 15, Bias: -1.318502, T: 111182, Avg. loss: 0.792654\nTotal training time: 0.03 seconds.\n-- Epoch 24\nNorm: 4.21, NNZs: 15, Bias: -2.009863, T: 116016, Avg. loss: 0.780648\nTotal training time: 0.03 seconds.\n-- Epoch 25\nNorm: 3.86, NNZs: 15, Bias: -1.691004, T: 120850, Avg. loss: 0.781813\nTotal training time: 0.03 seconds.\n-- Epoch 26\nNorm: 3.77, NNZs: 15, Bias: -1.726731, T: 125684, Avg. loss: 0.780190\nTotal training time: 0.04 seconds.\n-- Epoch 27\nNorm: 4.13, NNZs: 15, Bias: -1.324923, T: 130518, Avg. loss: 0.766968\nTotal training time: 0.04 seconds.\n-- Epoch 28\nNorm: 4.30, NNZs: 15, Bias: -1.226470, T: 135352, Avg. loss: 0.777066\nTotal training time: 0.04 seconds.\n-- Epoch 29\nNorm: 3.88, NNZs: 15, Bias: -1.623913, T: 140186, Avg. loss: 0.765220\nTotal training time: 0.04 seconds.\n-- Epoch 30\nNorm: 4.07, NNZs: 15, Bias: -1.530964, T: 145020, Avg. loss: 0.765523\nTotal training time: 0.04 seconds.\n-- Epoch 31\nNorm: 3.99, NNZs: 15, Bias: -1.455402, T: 149854, Avg. loss: 0.761807\nTotal training time: 0.04 seconds.\n-- Epoch 32\nNorm: 3.85, NNZs: 15, Bias: -1.448455, T: 154688, Avg. loss: 0.757325\nTotal training time: 0.04 seconds.\n-- Epoch 33\nNorm: 3.56, NNZs: 15, Bias: -1.700552, T: 159522, Avg. loss: 0.753127\nTotal training time: 0.05 seconds.\n-- Epoch 34\nNorm: 3.75, NNZs: 15, Bias: -1.648220, T: 164356, Avg. loss: 0.753574\nTotal training time: 0.05 seconds.\n-- Epoch 35\nNorm: 3.95, NNZs: 15, Bias: -1.478790, T: 169190, Avg. loss: 0.750656\nTotal training time: 0.06 seconds.\n-- Epoch 36\nNorm: 3.86, NNZs: 15, Bias: -1.286705, T: 174024, Avg. loss: 0.745604\nTotal training time: 0.06 seconds.\n-- Epoch 37\nNorm: 3.74, NNZs: 15, Bias: -1.321265, T: 178858, Avg. loss: 0.743622\nTotal training time: 0.06 seconds.\n-- Epoch 38\nNorm: 3.75, NNZs: 15, Bias: -1.351143, T: 183692, Avg. loss: 0.739678\nTotal training time: 0.06 seconds.\n-- Epoch 39\nNorm: 3.68, NNZs: 15, Bias: -1.471451, T: 188526, Avg. loss: 0.739704\nTotal training time: 0.06 seconds.\n-- Epoch 40\nNorm: 3.84, NNZs: 15, Bias: -1.508697, T: 193360, Avg. loss: 0.740054\nTotal training time: 0.06 seconds.\n-- Epoch 41\nNorm: 3.83, NNZs: 15, Bias: -1.420734, T: 198194, Avg. loss: 0.734670\nTotal training time: 0.06 seconds.\n-- Epoch 42\nNorm: 3.79, NNZs: 15, Bias: -1.354832, T: 203028, Avg. loss: 0.738827\nTotal training time: 0.06 seconds.\n-- Epoch 43\nNorm: 3.87, NNZs: 15, Bias: -1.163521, T: 207862, Avg. loss: 0.731614\nTotal training time: 0.06 seconds.\n-- Epoch 44\nNorm: 3.53, NNZs: 15, Bias: -1.631045, T: 212696, Avg. loss: 0.733656\nTotal training time: 0.09 seconds.\n-- Epoch 45\nNorm: 3.65, NNZs: 15, Bias: -1.510963, T: 217530, Avg. loss: 0.732784\nTotal training time: 0.09 seconds.\n-- Epoch 46\nNorm: 3.79, NNZs: 15, Bias: -1.394455, T: 222364, Avg. loss: 0.729818\nTotal training time: 0.09 seconds.\n-- Epoch 47\nNorm: 3.84, NNZs: 15, Bias: -1.122797, T: 227198, Avg. loss: 0.726595\nTotal training time: 0.10 seconds.\n-- Epoch 48\nNorm: 3.66, NNZs: 15, Bias: -1.462246, T: 232032, Avg. loss: 0.725415\nTotal training time: 0.10 seconds.\n-- Epoch 49\nNorm: 3.71, NNZs: 15, Bias: -1.527017, T: 236866, Avg. loss: 0.723491\nTotal training time: 0.10 seconds.\n-- Epoch 50\nNorm: 3.82, NNZs: 15, Bias: -1.668077, T: 241700, Avg. loss: 0.720537\nTotal training time: 0.10 seconds.\n-- Epoch 51\nNorm: 3.88, NNZs: 15, Bias: -1.324231, T: 246534, Avg. loss: 0.722854\nTotal training time: 0.10 seconds.\n-- Epoch 52\nNorm: 3.81, NNZs: 15, Bias: -1.439941, T: 251368, Avg. loss: 0.716561\nTotal training time: 0.10 seconds.\n-- Epoch 53\nNorm: 3.89, NNZs: 15, Bias: -1.306387, T: 256202, Avg. loss: 0.717043\nTotal training time: 0.10 seconds.\n-- Epoch 54\nNorm: 3.69, NNZs: 15, Bias: -1.362634, T: 261036, Avg. loss: 0.721160\nTotal training time: 0.11 seconds.\n-- Epoch 55\nNorm: 3.89, NNZs: 15, Bias: -1.180991, T: 265870, Avg. loss: 0.716983\nTotal training time: 0.11 seconds.\n-- Epoch 56\nNorm: 3.82, NNZs: 15, Bias: -1.240532, T: 270704, Avg. loss: 0.714387\nTotal training time: 0.11 seconds.\n-- Epoch 57\nNorm: 3.76, NNZs: 15, Bias: -1.396504, T: 275538, Avg. loss: 0.715265\nTotal training time: 0.11 seconds.\n-- Epoch 58\nNorm: 3.84, NNZs: 15, Bias: -1.233014, T: 280372, Avg. loss: 0.711991\nTotal training time: 0.11 seconds.\n-- Epoch 59\nNorm: 3.71, NNZs: 15, Bias: -1.255905, T: 285206, Avg. loss: 0.711300\nTotal training time: 0.11 seconds.\n-- Epoch 60\nNorm: 3.64, NNZs: 15, Bias: -1.341905, T: 290040, Avg. loss: 0.710023\nTotal training time: 0.11 seconds.\n-- Epoch 61\nNorm: 3.55, NNZs: 15, Bias: -1.392838, T: 294874, Avg. loss: 0.709435\nTotal training time: 0.11 seconds.\n-- Epoch 62\nNorm: 3.87, NNZs: 15, Bias: -1.241526, T: 299708, Avg. loss: 0.711661\nTotal training time: 0.11 seconds.\n-- Epoch 63\nNorm: 3.77, NNZs: 15, Bias: -1.191083, T: 304542, Avg. loss: 0.708443\nTotal training time: 0.12 seconds.\n-- Epoch 64\nNorm: 3.77, NNZs: 15, Bias: -1.265370, T: 309376, Avg. loss: 0.706281\nTotal training time: 0.12 seconds.\n-- Epoch 65\nNorm: 3.76, NNZs: 15, Bias: -1.232794, T: 314210, Avg. loss: 0.709724\nTotal training time: 0.12 seconds.\n-- Epoch 66\nNorm: 3.97, NNZs: 15, Bias: -1.133670, T: 319044, Avg. loss: 0.705398\nTotal training time: 0.12 seconds.\n-- Epoch 67\nNorm: 3.87, NNZs: 15, Bias: -1.118651, T: 323878, Avg. loss: 0.704393\nTotal training time: 0.12 seconds.\n-- Epoch 68\nNorm: 3.85, NNZs: 15, Bias: -1.274542, T: 328712, Avg. loss: 0.704503\nTotal training time: 0.12 seconds.\n-- Epoch 69\nNorm: 3.69, NNZs: 15, Bias: -1.200718, T: 333546, Avg. loss: 0.703432\nTotal training time: 0.12 seconds.\n-- Epoch 70\nNorm: 3.63, NNZs: 15, Bias: -1.296268, T: 338380, Avg. loss: 0.702455\nTotal training time: 0.12 seconds.\n-- Epoch 71\nNorm: 3.87, NNZs: 15, Bias: -1.109471, T: 343214, Avg. loss: 0.702919\nTotal training time: 0.12 seconds.\n-- Epoch 72\nNorm: 3.81, NNZs: 15, Bias: -1.197464, T: 348048, Avg. loss: 0.703017\nTotal training time: 0.12 seconds.\nConvergence after 72 epochs took 0.12 seconds\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "source": "# Returns max value of the mean test score \nmax(scores['mean_test_score'])",
   "metadata": {
    "tags": [],
    "cell_id": "00050-a8e1d628-6041-48d2-b19f-cd87e24f5871",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "32c9439c",
    "allow_embed": false,
    "execution_start": 1621909167920,
    "execution_millis": 17,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 90,
     "data": {
      "text/plain": "0.6998340687833068"
     },
     "metadata": {}
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "source": "# loop that runs all of the possible parameter configurations from the parameter dictionary above\nfor mean_score, params in sorted(list(zip(scores[\"mean_test_score\"], scores[\"params\"])),key = lambda x: x[0]):\n     print(f'Best parameters for SGD Classifier are {params} with a score of {mean_score}')",
   "metadata": {
    "tags": [],
    "cell_id": "00051-fb51c8a0-61ba-4267-9fae-aad236819c5c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "46f0d3fb",
    "allow_embed": false,
    "execution_start": 1621909167940,
    "execution_millis": 31,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Best parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.49669572068744766\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5275098969941828\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5351585767169599\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5442584587452174\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5484067391625504\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.5694954192278953\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5866888907444638\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5904213796484828\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6677714474126506\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6708569116239634\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6710767972491816\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6737685227411409\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6737685227411409\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6745981788246075\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6748002937517799\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6762489267997114\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.676250853742873\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6766632195794553\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6766645042082298\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6781103538938169\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6791446941620045\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6803854314532791\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6805920425811618\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6822472867569761\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6836963480144992\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6836963480144992\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6874213432506675\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6880401061103367\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6888678352506419\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6994206324227457\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6998340687833068\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "source": "Best parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} using rfe_list froms RFE\n",
   "metadata": {
    "tags": [],
    "cell_id": "00052-6260c188-07db-413d-b166-cdb4d0a8303e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "# Build 2 models using Select K Best features for one and RFE Features for the other\nsgd_skb = SGDClassifier(alpha=0.01, shuffle=True, verbose=5, class_weight=None)\nsgd_rfe = SGDClassifier(alpha=0.0001, class_weight='balanced', shuffle=True, verbose=1)\n\n# fitting the SGD Classifiers with the X_train with the corresponding features\nsgd_skb.fit(X_train[f_feature], y_train)\nsgd_rfe.fit(X_train[rfe_list], y_train)\n\n# Model SKB predictions\ny_pred_sgd_skb = sgd_skb.predict(X_train[f_feature])\ny_pred_val_sgd_skb = sgd_skb.predict(X_validate[f_feature])\n\n# Model RFE predictions\ny_pred_sgd_rfe = sgd_rfe.predict(X_train[rfe_list])\ny_pred_val_sgd_rfe = sgd_rfe.predict(X_validate[rfe_list])\n\n# Measure accuracy of the select k best feature model\naccuracy_train_sgd_skb = sgd_skb.score(X_train[f_feature], y_train)\naccuracy_val_sgd_skb = sgd_skb.score(X_validate[f_feature], y_validate)\n\n# Measure accuracy of the RFE feature model\naccuracy_train_sgd_rfe = sgd_rfe.score(X_train[rfe_list], y_train)\naccuracy_val_sgd_rfe = sgd_rfe.score(X_validate[rfe_list], y_validate)",
   "metadata": {
    "tags": [],
    "cell_id": "00056-645ac43a-0c8d-47b9-9421-f62d19b649ad",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "99ef0b23",
    "execution_start": 1621911332346,
    "execution_millis": 442,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "-- Epoch 1\nNorm: 8.28, NNZs: 15, Bias: -2.358298, T: 4834, Avg. loss: 37.365591\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 6.03, NNZs: 15, Bias: -1.461340, T: 9668, Avg. loss: 5.087795\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 5.44, NNZs: 15, Bias: -1.065081, T: 14502, Avg. loss: 3.369127\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 4.68, NNZs: 15, Bias: -0.736281, T: 19336, Avg. loss: 2.580900\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 4.32, NNZs: 15, Bias: -0.497432, T: 24170, Avg. loss: 2.085193\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 3.89, NNZs: 15, Bias: -0.315186, T: 29004, Avg. loss: 1.869400\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 3.55, NNZs: 15, Bias: -0.242906, T: 33838, Avg. loss: 1.622763\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 3.32, NNZs: 15, Bias: -0.150791, T: 38672, Avg. loss: 1.542882\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 3.14, NNZs: 15, Bias: -0.099004, T: 43506, Avg. loss: 1.423115\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 2.99, NNZs: 15, Bias: -0.056139, T: 48340, Avg. loss: 1.341298\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 2.89, NNZs: 15, Bias: 0.016698, T: 53174, Avg. loss: 1.277088\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 2.76, NNZs: 15, Bias: 0.062470, T: 58008, Avg. loss: 1.224715\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 2.71, NNZs: 15, Bias: 0.088368, T: 62842, Avg. loss: 1.167284\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 2.67, NNZs: 15, Bias: 0.103474, T: 67676, Avg. loss: 1.150357\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 2.61, NNZs: 15, Bias: 0.115039, T: 72510, Avg. loss: 1.112482\nTotal training time: 0.02 seconds.\n-- Epoch 16\nNorm: 2.56, NNZs: 15, Bias: 0.145788, T: 77344, Avg. loss: 1.100065\nTotal training time: 0.03 seconds.\n-- Epoch 17\nNorm: 2.50, NNZs: 15, Bias: 0.158247, T: 82178, Avg. loss: 1.055317\nTotal training time: 0.03 seconds.\n-- Epoch 18\nNorm: 2.46, NNZs: 15, Bias: 0.190404, T: 87012, Avg. loss: 1.043480\nTotal training time: 0.03 seconds.\n-- Epoch 19\nNorm: 2.41, NNZs: 15, Bias: 0.186912, T: 91846, Avg. loss: 1.026246\nTotal training time: 0.04 seconds.\n-- Epoch 20\nNorm: 2.37, NNZs: 15, Bias: 0.202652, T: 96680, Avg. loss: 1.016625\nTotal training time: 0.04 seconds.\n-- Epoch 21\nNorm: 2.36, NNZs: 15, Bias: 0.221305, T: 101514, Avg. loss: 0.988938\nTotal training time: 0.05 seconds.\n-- Epoch 22\nNorm: 2.35, NNZs: 15, Bias: 0.238666, T: 106348, Avg. loss: 0.986588\nTotal training time: 0.05 seconds.\n-- Epoch 23\nNorm: 2.32, NNZs: 15, Bias: 0.247696, T: 111182, Avg. loss: 0.966365\nTotal training time: 0.05 seconds.\n-- Epoch 24\nNorm: 2.30, NNZs: 15, Bias: 0.252404, T: 116016, Avg. loss: 0.951495\nTotal training time: 0.05 seconds.\n-- Epoch 25\nNorm: 2.29, NNZs: 15, Bias: 0.250954, T: 120850, Avg. loss: 0.937534\nTotal training time: 0.05 seconds.\n-- Epoch 26\nNorm: 2.27, NNZs: 15, Bias: 0.264916, T: 125684, Avg. loss: 0.945384\nTotal training time: 0.06 seconds.\n-- Epoch 27\nNorm: 2.25, NNZs: 15, Bias: 0.268324, T: 130518, Avg. loss: 0.922859\nTotal training time: 0.06 seconds.\n-- Epoch 28\nNorm: 2.22, NNZs: 15, Bias: 0.278707, T: 135352, Avg. loss: 0.914228\nTotal training time: 0.06 seconds.\n-- Epoch 29\nNorm: 2.22, NNZs: 15, Bias: 0.287467, T: 140186, Avg. loss: 0.902184\nTotal training time: 0.06 seconds.\n-- Epoch 30\nNorm: 2.21, NNZs: 15, Bias: 0.293677, T: 145020, Avg. loss: 0.904454\nTotal training time: 0.06 seconds.\n-- Epoch 31\nNorm: 2.18, NNZs: 15, Bias: 0.304041, T: 149854, Avg. loss: 0.888929\nTotal training time: 0.06 seconds.\n-- Epoch 32\nNorm: 2.17, NNZs: 15, Bias: 0.307412, T: 154688, Avg. loss: 0.891228\nTotal training time: 0.06 seconds.\n-- Epoch 33\nNorm: 2.15, NNZs: 15, Bias: 0.310622, T: 159522, Avg. loss: 0.901067\nTotal training time: 0.07 seconds.\n-- Epoch 34\nNorm: 2.14, NNZs: 15, Bias: 0.325991, T: 164356, Avg. loss: 0.878442\nTotal training time: 0.07 seconds.\n-- Epoch 35\nNorm: 2.12, NNZs: 15, Bias: 0.326243, T: 169190, Avg. loss: 0.869876\nTotal training time: 0.07 seconds.\n-- Epoch 36\nNorm: 2.12, NNZs: 15, Bias: 0.340303, T: 174024, Avg. loss: 0.867053\nTotal training time: 0.07 seconds.\n-- Epoch 37\nNorm: 2.12, NNZs: 15, Bias: 0.343077, T: 178858, Avg. loss: 0.864754\nTotal training time: 0.07 seconds.\n-- Epoch 38\nNorm: 2.11, NNZs: 15, Bias: 0.345851, T: 183692, Avg. loss: 0.858040\nTotal training time: 0.07 seconds.\n-- Epoch 39\nNorm: 2.11, NNZs: 15, Bias: 0.342185, T: 188526, Avg. loss: 0.850898\nTotal training time: 0.07 seconds.\n-- Epoch 40\nNorm: 2.10, NNZs: 15, Bias: 0.348005, T: 193360, Avg. loss: 0.853175\nTotal training time: 0.07 seconds.\n-- Epoch 41\nNorm: 2.09, NNZs: 15, Bias: 0.351093, T: 198194, Avg. loss: 0.853115\nTotal training time: 0.07 seconds.\n-- Epoch 42\nNorm: 2.08, NNZs: 15, Bias: 0.362018, T: 203028, Avg. loss: 0.843930\nTotal training time: 0.08 seconds.\n-- Epoch 43\nNorm: 2.07, NNZs: 15, Bias: 0.368839, T: 207862, Avg. loss: 0.831487\nTotal training time: 0.08 seconds.\n-- Epoch 44\nNorm: 2.07, NNZs: 15, Bias: 0.370398, T: 212696, Avg. loss: 0.835556\nTotal training time: 0.08 seconds.\n-- Epoch 45\nNorm: 2.06, NNZs: 15, Bias: 0.367607, T: 217530, Avg. loss: 0.836835\nTotal training time: 0.08 seconds.\n-- Epoch 46\nNorm: 2.06, NNZs: 15, Bias: 0.369407, T: 222364, Avg. loss: 0.836051\nTotal training time: 0.08 seconds.\n-- Epoch 47\nNorm: 2.05, NNZs: 15, Bias: 0.376589, T: 227198, Avg. loss: 0.821546\nTotal training time: 0.08 seconds.\n-- Epoch 48\nNorm: 2.04, NNZs: 15, Bias: 0.380078, T: 232032, Avg. loss: 0.819308\nTotal training time: 0.09 seconds.\n-- Epoch 49\nNorm: 2.04, NNZs: 15, Bias: 0.382178, T: 236866, Avg. loss: 0.821788\nTotal training time: 0.09 seconds.\n-- Epoch 50\nNorm: 2.02, NNZs: 15, Bias: 0.391370, T: 241700, Avg. loss: 0.818931\nTotal training time: 0.09 seconds.\n-- Epoch 51\nNorm: 2.02, NNZs: 15, Bias: 0.395819, T: 246534, Avg. loss: 0.813867\nTotal training time: 0.09 seconds.\n-- Epoch 52\nNorm: 2.02, NNZs: 15, Bias: 0.395868, T: 251368, Avg. loss: 0.818338\nTotal training time: 0.09 seconds.\n-- Epoch 53\nNorm: 2.02, NNZs: 15, Bias: 0.395462, T: 256202, Avg. loss: 0.804605\nTotal training time: 0.09 seconds.\n-- Epoch 54\nNorm: 2.01, NNZs: 15, Bias: 0.398205, T: 261036, Avg. loss: 0.804541\nTotal training time: 0.09 seconds.\n-- Epoch 55\nNorm: 2.01, NNZs: 15, Bias: 0.397856, T: 265870, Avg. loss: 0.801689\nTotal training time: 0.09 seconds.\n-- Epoch 56\nNorm: 2.01, NNZs: 15, Bias: 0.396022, T: 270704, Avg. loss: 0.802736\nTotal training time: 0.10 seconds.\n-- Epoch 57\nNorm: 2.01, NNZs: 15, Bias: 0.396020, T: 275538, Avg. loss: 0.794877\nTotal training time: 0.10 seconds.\n-- Epoch 58\nNorm: 2.00, NNZs: 15, Bias: 0.401053, T: 280372, Avg. loss: 0.792110\nTotal training time: 0.10 seconds.\n-- Epoch 59\nNorm: 2.00, NNZs: 15, Bias: 0.403517, T: 285206, Avg. loss: 0.793581\nTotal training time: 0.10 seconds.\n-- Epoch 60\nNorm: 2.00, NNZs: 15, Bias: 0.406980, T: 290040, Avg. loss: 0.802158\nTotal training time: 0.10 seconds.\n-- Epoch 61\nNorm: 2.00, NNZs: 15, Bias: 0.409022, T: 294874, Avg. loss: 0.794172\nTotal training time: 0.10 seconds.\n-- Epoch 62\nNorm: 1.99, NNZs: 15, Bias: 0.412733, T: 299708, Avg. loss: 0.794577\nTotal training time: 0.10 seconds.\n-- Epoch 63\nNorm: 2.00, NNZs: 15, Bias: 0.413095, T: 304542, Avg. loss: 0.796418\nTotal training time: 0.10 seconds.\nConvergence after 63 epochs took 0.10 seconds\n-- Epoch 1\nNorm: 16.75, NNZs: 15, Bias: -12.966224, T: 4834, Avg. loss: 5.305105\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 11.05, NNZs: 15, Bias: -3.167106, T: 9668, Avg. loss: 2.324710\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 8.85, NNZs: 15, Bias: -2.942432, T: 14502, Avg. loss: 1.625766\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 6.60, NNZs: 15, Bias: -3.721862, T: 19336, Avg. loss: 1.387350\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 7.34, NNZs: 15, Bias: -1.568709, T: 24170, Avg. loss: 1.235955\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 5.75, NNZs: 15, Bias: -2.717080, T: 29004, Avg. loss: 1.144443\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 5.61, NNZs: 15, Bias: -2.663869, T: 33838, Avg. loss: 1.060822\nTotal training time: 0.02 seconds.\n-- Epoch 8\nNorm: 5.31, NNZs: 15, Bias: -2.312652, T: 38672, Avg. loss: 1.017411\nTotal training time: 0.02 seconds.\n-- Epoch 9\nNorm: 4.59, NNZs: 15, Bias: -1.714153, T: 43506, Avg. loss: 0.972657\nTotal training time: 0.02 seconds.\n-- Epoch 10\nNorm: 5.14, NNZs: 15, Bias: -1.332526, T: 48340, Avg. loss: 0.945446\nTotal training time: 0.02 seconds.\n-- Epoch 11\nNorm: 4.62, NNZs: 15, Bias: -1.722258, T: 53174, Avg. loss: 0.932039\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 4.17, NNZs: 15, Bias: -2.330905, T: 58008, Avg. loss: 0.888865\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 3.90, NNZs: 15, Bias: -2.237946, T: 62842, Avg. loss: 0.879998\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 4.42, NNZs: 15, Bias: -2.074354, T: 67676, Avg. loss: 0.877598\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 4.06, NNZs: 15, Bias: -1.825696, T: 72510, Avg. loss: 0.861438\nTotal training time: 0.03 seconds.\n-- Epoch 16\nNorm: 4.42, NNZs: 15, Bias: -1.785831, T: 77344, Avg. loss: 0.844309\nTotal training time: 0.03 seconds.\n-- Epoch 17\nNorm: 4.55, NNZs: 15, Bias: -1.613939, T: 82178, Avg. loss: 0.834769\nTotal training time: 0.03 seconds.\n-- Epoch 18\nNorm: 4.16, NNZs: 15, Bias: -1.740715, T: 87012, Avg. loss: 0.832236\nTotal training time: 0.03 seconds.\n-- Epoch 19\nNorm: 3.95, NNZs: 15, Bias: -2.203216, T: 91846, Avg. loss: 0.813945\nTotal training time: 0.03 seconds.\n-- Epoch 20\nNorm: 4.28, NNZs: 15, Bias: -1.969743, T: 96680, Avg. loss: 0.806268\nTotal training time: 0.03 seconds.\n-- Epoch 21\nNorm: 4.46, NNZs: 15, Bias: -1.478118, T: 101514, Avg. loss: 0.811143\nTotal training time: 0.03 seconds.\n-- Epoch 22\nNorm: 4.09, NNZs: 15, Bias: -1.707476, T: 106348, Avg. loss: 0.785879\nTotal training time: 0.03 seconds.\n-- Epoch 23\nNorm: 4.13, NNZs: 15, Bias: -1.482069, T: 111182, Avg. loss: 0.787725\nTotal training time: 0.04 seconds.\n-- Epoch 24\nNorm: 4.19, NNZs: 15, Bias: -1.589293, T: 116016, Avg. loss: 0.781884\nTotal training time: 0.04 seconds.\n-- Epoch 25\nNorm: 4.28, NNZs: 15, Bias: -1.030456, T: 120850, Avg. loss: 0.777363\nTotal training time: 0.04 seconds.\n-- Epoch 26\nNorm: 4.00, NNZs: 15, Bias: -1.305972, T: 125684, Avg. loss: 0.783567\nTotal training time: 0.04 seconds.\n-- Epoch 27\nNorm: 3.87, NNZs: 15, Bias: -1.682617, T: 130518, Avg. loss: 0.780471\nTotal training time: 0.04 seconds.\n-- Epoch 28\nNorm: 3.73, NNZs: 15, Bias: -1.482173, T: 135352, Avg. loss: 0.770307\nTotal training time: 0.04 seconds.\n-- Epoch 29\nNorm: 4.04, NNZs: 15, Bias: -1.758329, T: 140186, Avg. loss: 0.765473\nTotal training time: 0.04 seconds.\n-- Epoch 30\nNorm: 4.08, NNZs: 15, Bias: -1.278100, T: 145020, Avg. loss: 0.764084\nTotal training time: 0.04 seconds.\n-- Epoch 31\nNorm: 3.80, NNZs: 15, Bias: -1.548160, T: 149854, Avg. loss: 0.760590\nTotal training time: 0.04 seconds.\n-- Epoch 32\nNorm: 3.94, NNZs: 15, Bias: -1.469945, T: 154688, Avg. loss: 0.754740\nTotal training time: 0.05 seconds.\n-- Epoch 33\nNorm: 3.58, NNZs: 15, Bias: -1.627223, T: 159522, Avg. loss: 0.747720\nTotal training time: 0.05 seconds.\n-- Epoch 34\nNorm: 4.02, NNZs: 15, Bias: -1.395485, T: 164356, Avg. loss: 0.751340\nTotal training time: 0.05 seconds.\n-- Epoch 35\nNorm: 3.75, NNZs: 15, Bias: -1.455651, T: 169190, Avg. loss: 0.746777\nTotal training time: 0.05 seconds.\n-- Epoch 36\nNorm: 3.72, NNZs: 15, Bias: -1.523595, T: 174024, Avg. loss: 0.749843\nTotal training time: 0.05 seconds.\n-- Epoch 37\nNorm: 4.02, NNZs: 15, Bias: -1.302058, T: 178858, Avg. loss: 0.744429\nTotal training time: 0.05 seconds.\n-- Epoch 38\nNorm: 3.88, NNZs: 15, Bias: -1.487820, T: 183692, Avg. loss: 0.741891\nTotal training time: 0.05 seconds.\n-- Epoch 39\nNorm: 3.99, NNZs: 15, Bias: -1.655784, T: 188526, Avg. loss: 0.737269\nTotal training time: 0.05 seconds.\n-- Epoch 40\nNorm: 4.02, NNZs: 15, Bias: -1.372959, T: 193360, Avg. loss: 0.734390\nTotal training time: 0.06 seconds.\n-- Epoch 41\nNorm: 3.71, NNZs: 15, Bias: -1.725609, T: 198194, Avg. loss: 0.740174\nTotal training time: 0.06 seconds.\n-- Epoch 42\nNorm: 3.82, NNZs: 15, Bias: -1.479794, T: 203028, Avg. loss: 0.733561\nTotal training time: 0.06 seconds.\n-- Epoch 43\nNorm: 3.77, NNZs: 15, Bias: -1.576546, T: 207862, Avg. loss: 0.733102\nTotal training time: 0.06 seconds.\n-- Epoch 44\nNorm: 3.82, NNZs: 15, Bias: -1.429793, T: 212696, Avg. loss: 0.731417\nTotal training time: 0.06 seconds.\n-- Epoch 45\nNorm: 3.56, NNZs: 15, Bias: -1.528998, T: 217530, Avg. loss: 0.729386\nTotal training time: 0.06 seconds.\n-- Epoch 46\nNorm: 3.82, NNZs: 15, Bias: -1.491497, T: 222364, Avg. loss: 0.730889\nTotal training time: 0.06 seconds.\n-- Epoch 47\nNorm: 3.58, NNZs: 15, Bias: -1.447356, T: 227198, Avg. loss: 0.727314\nTotal training time: 0.06 seconds.\n-- Epoch 48\nNorm: 3.51, NNZs: 15, Bias: -1.443933, T: 232032, Avg. loss: 0.723670\nTotal training time: 0.07 seconds.\n-- Epoch 49\nNorm: 3.69, NNZs: 15, Bias: -1.565672, T: 236866, Avg. loss: 0.728181\nTotal training time: 0.07 seconds.\n-- Epoch 50\nNorm: 3.77, NNZs: 15, Bias: -1.329225, T: 241700, Avg. loss: 0.725624\nTotal training time: 0.07 seconds.\n-- Epoch 51\nNorm: 3.68, NNZs: 15, Bias: -1.390075, T: 246534, Avg. loss: 0.723600\nTotal training time: 0.07 seconds.\n-- Epoch 52\nNorm: 3.82, NNZs: 15, Bias: -1.282398, T: 251368, Avg. loss: 0.720716\nTotal training time: 0.07 seconds.\n-- Epoch 53\nNorm: 3.87, NNZs: 15, Bias: -1.134645, T: 256202, Avg. loss: 0.721390\nTotal training time: 0.07 seconds.\n-- Epoch 54\nNorm: 3.98, NNZs: 15, Bias: -1.115636, T: 261036, Avg. loss: 0.715359\nTotal training time: 0.07 seconds.\n-- Epoch 55\nNorm: 3.69, NNZs: 15, Bias: -1.148455, T: 265870, Avg. loss: 0.717927\nTotal training time: 0.08 seconds.\n-- Epoch 56\nNorm: 3.99, NNZs: 15, Bias: -1.101617, T: 270704, Avg. loss: 0.716960\nTotal training time: 0.08 seconds.\n-- Epoch 57\nNorm: 3.97, NNZs: 15, Bias: -1.191608, T: 275538, Avg. loss: 0.714028\nTotal training time: 0.08 seconds.\n-- Epoch 58\nNorm: 3.89, NNZs: 15, Bias: -1.073193, T: 280372, Avg. loss: 0.712565\nTotal training time: 0.08 seconds.\n-- Epoch 59\nNorm: 3.77, NNZs: 15, Bias: -1.237434, T: 285206, Avg. loss: 0.710703\nTotal training time: 0.08 seconds.\n-- Epoch 60\nNorm: 3.72, NNZs: 15, Bias: -1.250205, T: 290040, Avg. loss: 0.711964\nTotal training time: 0.09 seconds.\n-- Epoch 61\nNorm: 3.65, NNZs: 15, Bias: -1.361191, T: 294874, Avg. loss: 0.710894\nTotal training time: 0.12 seconds.\n-- Epoch 62\nNorm: 3.83, NNZs: 15, Bias: -1.222968, T: 299708, Avg. loss: 0.710375\nTotal training time: 0.12 seconds.\n-- Epoch 63\nNorm: 3.77, NNZs: 15, Bias: -1.291597, T: 304542, Avg. loss: 0.711302\nTotal training time: 0.12 seconds.\n-- Epoch 64\nNorm: 3.66, NNZs: 15, Bias: -1.336981, T: 309376, Avg. loss: 0.707193\nTotal training time: 0.13 seconds.\n-- Epoch 65\nNorm: 3.52, NNZs: 15, Bias: -1.382470, T: 314210, Avg. loss: 0.706594\nTotal training time: 0.13 seconds.\n-- Epoch 66\nNorm: 3.69, NNZs: 15, Bias: -1.220870, T: 319044, Avg. loss: 0.706077\nTotal training time: 0.13 seconds.\n-- Epoch 67\nNorm: 3.74, NNZs: 15, Bias: -1.226884, T: 323878, Avg. loss: 0.703031\nTotal training time: 0.13 seconds.\n-- Epoch 68\nNorm: 3.75, NNZs: 15, Bias: -1.163988, T: 328712, Avg. loss: 0.707523\nTotal training time: 0.13 seconds.\n-- Epoch 69\nNorm: 3.94, NNZs: 15, Bias: -1.244243, T: 333546, Avg. loss: 0.703404\nTotal training time: 0.13 seconds.\n-- Epoch 70\nNorm: 3.54, NNZs: 15, Bias: -1.340780, T: 338380, Avg. loss: 0.699010\nTotal training time: 0.13 seconds.\n-- Epoch 71\nNorm: 3.77, NNZs: 15, Bias: -1.123516, T: 343214, Avg. loss: 0.704042\nTotal training time: 0.14 seconds.\n-- Epoch 72\nNorm: 3.73, NNZs: 15, Bias: -1.129991, T: 348048, Avg. loss: 0.701137\nTotal training time: 0.14 seconds.\n-- Epoch 73\nNorm: 3.78, NNZs: 15, Bias: -1.155791, T: 352882, Avg. loss: 0.700987\nTotal training time: 0.14 seconds.\n-- Epoch 74\nNorm: 3.72, NNZs: 15, Bias: -1.077366, T: 357716, Avg. loss: 0.700386\nTotal training time: 0.14 seconds.\n-- Epoch 75\nNorm: 3.70, NNZs: 15, Bias: -1.133011, T: 362550, Avg. loss: 0.700021\nTotal training time: 0.14 seconds.\nConvergence after 75 epochs took 0.14 seconds\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "source": "# Add accuracy of the SKB model to the metric_df\nmetric_df = metric_df.append({\n    'model': 'SGD Classifier SKB Features', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(accuracy_train_sgd_skb, 2),\n    'validate_accuracy':round(accuracy_val_sgd_skb,2)}, ignore_index=True)\n",
   "metadata": {
    "tags": [],
    "cell_id": "00060-7e5fbb44-a8a8-4de8-bc0f-d384b3ab3b75",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e2809fff",
    "execution_start": 1621909837581,
    "execution_millis": 93,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "source": "# Add accuracy of the RFE model to the metric_df\nmetric_df = metric_df.append({\n    'model': 'SGD Classifier RFE Features', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(accuracy_train_sgd_rfe, 2),\n    'validate_accuracy':round(accuracy_val_sgd_rfe,2)}, ignore_index=True)",
   "metadata": {
    "tags": [],
    "cell_id": "00061-60b11f13-4225-4299-9769-853a128cda69",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4890a958",
    "execution_start": 1621909971706,
    "execution_millis": 21,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "source": "metric_df",
   "metadata": {
    "tags": [],
    "cell_id": "00063-738a4a78-840c-49b6-9eea-091156bab26a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "400c35cf",
    "execution_start": 1621910507280,
    "execution_millis": 25,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 110,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 5,
       "column_count": 4,
       "columns": [
        {
         "name": "model",
         "dtype": "object",
         "stats": {
          "unique_count": 4,
          "nan_count": 0,
          "categories": [
           {
            "name": "naive bayes",
            "count": 2
           },
           {
            "name": "random forest",
            "count": 1
           },
           {
            "name": "2 others",
            "count": 2
           }
          ]
         }
        },
        {
         "name": "baseline_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.51",
          "max": "0.51",
          "histogram": [
           {
            "bin_start": 0.010000000000000009,
            "bin_end": 0.11000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.11000000000000001,
            "bin_end": 0.21000000000000002,
            "count": 0
           },
           {
            "bin_start": 0.21000000000000002,
            "bin_end": 0.31000000000000005,
            "count": 0
           },
           {
            "bin_start": 0.31000000000000005,
            "bin_end": 0.41000000000000003,
            "count": 0
           },
           {
            "bin_start": 0.41000000000000003,
            "bin_end": 0.51,
            "count": 0
           },
           {
            "bin_start": 0.51,
            "bin_end": 0.6100000000000001,
            "count": 5
           },
           {
            "bin_start": 0.6100000000000001,
            "bin_end": 0.7100000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7100000000000001,
            "bin_end": 0.81,
            "count": 0
           },
           {
            "bin_start": 0.81,
            "bin_end": 0.91,
            "count": 0
           },
           {
            "bin_start": 0.91,
            "bin_end": 1.01,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "train_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 4,
          "nan_count": 0,
          "min": "0.53",
          "max": "0.7",
          "histogram": [
           {
            "bin_start": 0.53,
            "bin_end": 0.547,
            "count": 1
           },
           {
            "bin_start": 0.547,
            "bin_end": 0.5640000000000001,
            "count": 0
           },
           {
            "bin_start": 0.5640000000000001,
            "bin_end": 0.581,
            "count": 0
           },
           {
            "bin_start": 0.581,
            "bin_end": 0.598,
            "count": 0
           },
           {
            "bin_start": 0.598,
            "bin_end": 0.615,
            "count": 1
           },
           {
            "bin_start": 0.615,
            "bin_end": 0.632,
            "count": 0
           },
           {
            "bin_start": 0.632,
            "bin_end": 0.649,
            "count": 0
           },
           {
            "bin_start": 0.649,
            "bin_end": 0.6659999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6659999999999999,
            "bin_end": 0.6829999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6829999999999999,
            "bin_end": 0.7,
            "count": 3
           }
          ]
         }
        },
        {
         "name": "validate_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "0.53",
          "max": "0.72",
          "histogram": [
           {
            "bin_start": 0.53,
            "bin_end": 0.549,
            "count": 1
           },
           {
            "bin_start": 0.549,
            "bin_end": 0.5680000000000001,
            "count": 0
           },
           {
            "bin_start": 0.5680000000000001,
            "bin_end": 0.587,
            "count": 0
           },
           {
            "bin_start": 0.587,
            "bin_end": 0.606,
            "count": 1
           },
           {
            "bin_start": 0.606,
            "bin_end": 0.625,
            "count": 0
           },
           {
            "bin_start": 0.625,
            "bin_end": 0.644,
            "count": 0
           },
           {
            "bin_start": 0.644,
            "bin_end": 0.663,
            "count": 0
           },
           {
            "bin_start": 0.663,
            "bin_end": 0.6819999999999999,
            "count": 1
           },
           {
            "bin_start": 0.6819999999999999,
            "bin_end": 0.701,
            "count": 1
           },
           {
            "bin_start": 0.701,
            "bin_end": 0.72,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "model": "random forest",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.72,
         "_deepnote_index_column": 0
        },
        {
         "model": "naive bayes",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.61,
         "validate_accuracy": 0.6,
         "_deepnote_index_column": 1
        },
        {
         "model": "naive bayes",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.68,
         "_deepnote_index_column": 2
        },
        {
         "model": "SGD Classifier SKB Features",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.53,
         "validate_accuracy": 0.53,
         "_deepnote_index_column": 3
        },
        {
         "model": "SGD Classifier RFE Features",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.69,
         "validate_accuracy": 0.69,
         "_deepnote_index_column": 5
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "                         model  baseline_accuracy  train_accuracy  \\\n0                random forest               0.51            0.70   \n1                  naive bayes               0.51            0.61   \n2                  naive bayes               0.51            0.70   \n3  SGD Classifier SKB Features               0.51            0.53   \n5  SGD Classifier RFE Features               0.51            0.69   \n\n   validate_accuracy  \n0               0.72  \n1               0.60  \n2               0.68  \n3               0.53  \n5               0.69  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>baseline_accuracy</th>\n      <th>train_accuracy</th>\n      <th>validate_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random forest</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>naive bayes</td>\n      <td>0.51</td>\n      <td>0.61</td>\n      <td>0.60</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>naive bayes</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.68</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SGD Classifier SKB Features</td>\n      <td>0.51</td>\n      <td>0.53</td>\n      <td>0.53</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>SGD Classifier RFE Features</td>\n      <td>0.51</td>\n      <td>0.69</td>\n      <td>0.69</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00064-5363d995-0e1b-4579-8ed8-353e65a6d486",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=258e71fc-cf2b-48c3-8461-70ecd9787aa1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "898de622-f47c-4fb6-afc3-512715d2b613",
  "deepnote_execution_queue": []
 }
}