{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00000-afe51ce7-bf2f-4535-a76c-beeeecb0f248",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "864c6ca2",
    "execution_start": 1622126498259,
    "execution_millis": 3372,
    "deepnote_cell_type": "code"
   },
   "source": "import pandas as pd\nimport numpy as np\n\n# Helper Functions\nimport wrangle as w \nimport explore as exp\nfrom explore import rfe, split, select_kbest\n\n# Visualizations\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Hypothesis tests\nfrom scipy import stats\nfrom scipy.stats import chi2_contingency\nfrom scipy.stats import ttest_1samp\nfrom scipy.stats import ttest_ind\n\n#Feature Engineering\nfrom sklearn.feature_selection import SelectKBest, f_regression, chi2\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.feature_selection import RFE\nfrom scipy import stats\n\n# Split data\nfrom sklearn.model_selection import train_test_split\n\n# Evaluate models\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import precision_recall_fscore_support \n\n# Create models for classification ML:\n# Decision Tree  \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import export_graphviz\n\n# Random Forest\nfrom sklearn.ensemble import RandomForestClassifier\n\n# K-Nearest Neighbor(KNN)  \nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Logistic Regression\nfrom sklearn.linear_model import LogisticRegression",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00001-25082157-824e-43c1-a14e-c6627b655cef",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "82eeda13",
    "execution_start": 1622126501639,
    "execution_millis": 114,
    "deepnote_cell_type": "code"
   },
   "source": "df = w.wrangle_data(cached=True)",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-4a3d20f1-7c99-4fbb-a6e9-f87319d0cb48",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8fb9d845",
    "execution_start": 1622126501760,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "df.drop(columns=['Unnamed: 0'], inplace=True)",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00002-6bfd7d89-37a8-403c-9b22-989d8c76e850",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f3dd26da",
    "execution_start": 1622126501777,
    "execution_millis": 38,
    "deepnote_cell_type": "code"
   },
   "source": "df.isnull().sum()",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 4,
     "data": {
      "text/plain": "age                                            0\ngender                                         0\nrace                                           0\ndate                                           0\ncity                                           0\nstate                                          0\nzipcode                                        0\ncounty                                         0\nagency_responsible                             0\ncause_of_death                                 0\ndescription_of_circumstances                   0\nofficial_disposition                           0\ncriminal_charges_filed                         0\nmental_illness                                 0\narmed_unarmed_status                           0\nalleged_weapon                                 0\nalleged_threat_lvl                             0\nfleeing                                        0\nbody_camera                                    0\ngeography                                      0\nencounter_type_draft                           0\ninitial_reported_reason_for_encounter_draft    0\nknown_past_shootings_of_officer_draft          0\nis_female                                      0\nis_male                                        0\nis_transgender                                 0\nwas_fleeing                                    0\nwas_not fleeing                                0\nwas_allegedly_armed                            0\nwas_unarmed                                    0\nwas_vehicle                                    0\nwas_domestic_disturbance                       0\nwas_mental_health_welfare_check                0\nwas_person_with_a_weapon                       0\nwas_traffic_stop                               0\nwas_violent_crime_part_1                       0\nis_asian/pacific islander                      0\nis_black                                       0\nis_hispanic                                    0\nis_native american                             0\nis_unknown race                                0\nis_white                                       0\nmntlill_drug or alcohol use                    0\nmntlill_no                                     0\nmntlill_unknown                                0\nmntlill_yes                                    0\nrural                                          0\nsuburban                                       0\nurban                                          0\ncod_lethal                                     0\nage_bins                                       0\nunknown                                        0\nunder 12                                       0\n12-17                                          0\n18-24                                          0\n25-34                                          0\n35-44                                          0\n45-54                                          0\n55-64                                          0\n65+                                            0\ndtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00004-45aa526f-7457-4dbb-8324-cab2c290082e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "14f60b8f",
    "execution_start": 1622126501832,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "df.shape",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 5,
     "data": {
      "text/plain": "(6265, 60)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00005-a34d6831-3c52-4d2d-88b3-27be177478ea",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bb2235ce",
    "execution_start": 1622126501832,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "df.alleged_threat_lvl.value_counts()",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 6,
     "data": {
      "text/plain": "1.0    4242\n0.0    2023\nName: alleged_threat_lvl, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00003-861c6add-03ca-4dbf-b4a3-9eead71c3e7e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2a21e0e6",
    "execution_start": 1622126501833,
    "execution_millis": 13,
    "deepnote_cell_type": "code"
   },
   "source": "df.age.value_counts()",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 7,
     "data": {
      "text/plain": "0     233\n31    211\n25    210\n32    200\n30    198\n     ... \n10      1\n12      1\n1       1\n88      1\n85      1\nName: age, Length: 81, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-4cfb6dc6-6394-45e7-93d9-ddea660ec5be",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "48919f60",
    "execution_start": 1622126501863,
    "execution_millis": 17,
    "deepnote_cell_type": "code"
   },
   "source": "df.age_bins.value_counts()",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 8,
     "data": {
      "text/plain": "25-34       1957\n35-44       1476\n45-54        919\n18-24        870\n55-64        501\nunknown      233\n65+          189\n12-17        115\nunder 12       5\nName: age_bins, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-d103c388-047e-4fd7-bd41-a3af5340dce3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "25d43fa0",
    "execution_start": 1622126501864,
    "execution_millis": 16,
    "deepnote_cell_type": "code"
   },
   "source": "df.columns",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 9,
     "data": {
      "text/plain": "Index(['age', 'gender', 'race', 'date', 'city', 'state', 'zipcode', 'county',\n       'agency_responsible', 'cause_of_death', 'description_of_circumstances',\n       'official_disposition', 'criminal_charges_filed', 'mental_illness',\n       'armed_unarmed_status', 'alleged_weapon', 'alleged_threat_lvl',\n       'fleeing', 'body_camera', 'geography', 'encounter_type_draft',\n       'initial_reported_reason_for_encounter_draft',\n       'known_past_shootings_of_officer_draft', 'is_female', 'is_male',\n       'is_transgender', 'was_fleeing', 'was_not fleeing ',\n       'was_allegedly_armed', 'was_unarmed', 'was_vehicle',\n       'was_domestic_disturbance', 'was_mental_health_welfare_check',\n       'was_person_with_a_weapon', 'was_traffic_stop',\n       'was_violent_crime_part_1', 'is_asian/pacific islander', 'is_black',\n       'is_hispanic', 'is_native american', 'is_unknown race', 'is_white',\n       'mntlill_drug or alcohol use', 'mntlill_no', 'mntlill_unknown',\n       'mntlill_yes', 'rural', 'suburban', 'urban', 'cod_lethal', 'age_bins',\n       'unknown', 'under 12', '12-17', '18-24', '25-34', '35-44', '45-54',\n       '55-64', '65+'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-919db769-656a-4eab-bb10-d9c631e9331c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fb9b34ba",
    "execution_start": 1622126501865,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "source": "from explore import rfe, split, select_kbest",
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-2b4cf507-9fcb-46d5-99ad-3871b80180d8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "61bca6e2",
    "execution_start": 1622126501870,
    "execution_millis": 31,
    "deepnote_cell_type": "code"
   },
   "source": "train, validate, test = split(df, stratify_by='alleged_threat_lvl')",
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00008-dfce7d04-b461-49d8-8573-075ffde11aed",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "68e62203",
    "execution_start": 1622126501907,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "\ndef split_df(df, target, seed):\n    '''\n    split_df will take one argument(df) and \n    then split our data into 20/80, \n    then split the 80% into 30/70\n    performs a train, validate, test split\n    splits each of the 3 samples into a dataframe with independent variables\n    and a series with the dependent, or target variable. \n    The function returns 6 dataframes and 3 series:\n    train, validate, test split, X_train (df) & y_train (series), X_validate & y_validate, X_test & y_test. \n    '''\n    # Train, Validate, and test\n    train_and_validate, test = train_test_split(df, test_size=0.2, random_state=seed)\n    train, validate = train_test_split(train_and_validate, test_size=0.3, random_state=seed)\n    # Split with X and y\n    X_train = train.drop(columns=[target])\n    y_train = train[target]\n    X_validate = validate.drop(columns=[target])\n    y_validate = validate[target]\n    X_test = test.drop(columns=[target])\n    y_test = test[target]\n    return train, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test ",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-ab50d1b3-ba5d-40ca-92ea-25209c4247ce",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4ca76457",
    "execution_start": 1622126501954,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "\ntrain, validate, test, X_train, y_train, X_validate, y_validate, X_test, y_test = split_df(df, 'alleged_threat_lvl', 42)",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-3d397d72-f255-46c4-90ee-f665b09d8778",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "89d68b10",
    "execution_start": 1622126501955,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "#y_",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-a4c560cb-74e2-44a1-9b39-e5de15e68b7b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3ca3de2b",
    "execution_start": 1622126501991,
    "execution_millis": 25,
    "deepnote_cell_type": "code"
   },
   "source": "X_train.info()",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3508 entries, 4142 to 5708\nData columns (total 59 columns):\n #   Column                                       Non-Null Count  Dtype  \n---  ------                                       --------------  -----  \n 0   age                                          3508 non-null   int64  \n 1   gender                                       3508 non-null   object \n 2   race                                         3508 non-null   object \n 3   date                                         3508 non-null   object \n 4   city                                         3508 non-null   object \n 5   state                                        3508 non-null   object \n 6   zipcode                                      3508 non-null   float64\n 7   county                                       3508 non-null   object \n 8   agency_responsible                           3508 non-null   object \n 9   cause_of_death                               3508 non-null   object \n 10  description_of_circumstances                 3508 non-null   object \n 11  official_disposition                         3508 non-null   object \n 12  criminal_charges_filed                       3508 non-null   object \n 13  mental_illness                               3508 non-null   object \n 14  armed_unarmed_status                         3508 non-null   object \n 15  alleged_weapon                               3508 non-null   object \n 16  fleeing                                      3508 non-null   object \n 17  body_camera                                  3508 non-null   float64\n 18  geography                                    3508 non-null   object \n 19  encounter_type_draft                         3508 non-null   object \n 20  initial_reported_reason_for_encounter_draft  3508 non-null   object \n 21  known_past_shootings_of_officer_draft        3508 non-null   int64  \n 22  is_female                                    3508 non-null   int64  \n 23  is_male                                      3508 non-null   int64  \n 24  is_transgender                               3508 non-null   int64  \n 25  was_fleeing                                  3508 non-null   float64\n 26  was_not fleeing                              3508 non-null   float64\n 27  was_allegedly_armed                          3508 non-null   float64\n 28  was_unarmed                                  3508 non-null   float64\n 29  was_vehicle                                  3508 non-null   float64\n 30  was_domestic_disturbance                     3508 non-null   int64  \n 31  was_mental_health_welfare_check              3508 non-null   int64  \n 32  was_person_with_a_weapon                     3508 non-null   int64  \n 33  was_traffic_stop                             3508 non-null   int64  \n 34  was_violent_crime_part_1                     3508 non-null   int64  \n 35  is_asian/pacific islander                    3508 non-null   int64  \n 36  is_black                                     3508 non-null   int64  \n 37  is_hispanic                                  3508 non-null   int64  \n 38  is_native american                           3508 non-null   int64  \n 39  is_unknown race                              3508 non-null   int64  \n 40  is_white                                     3508 non-null   int64  \n 41  mntlill_drug or alcohol use                  3508 non-null   int64  \n 42  mntlill_no                                   3508 non-null   int64  \n 43  mntlill_unknown                              3508 non-null   int64  \n 44  mntlill_yes                                  3508 non-null   int64  \n 45  rural                                        3508 non-null   float64\n 46  suburban                                     3508 non-null   float64\n 47  urban                                        3508 non-null   float64\n 48  cod_lethal                                   3508 non-null   int64  \n 49  age_bins                                     3508 non-null   object \n 50  unknown                                      3508 non-null   int64  \n 51  under 12                                     3508 non-null   int64  \n 52  12-17                                        3508 non-null   int64  \n 53  18-24                                        3508 non-null   int64  \n 54  25-34                                        3508 non-null   int64  \n 55  35-44                                        3508 non-null   int64  \n 56  45-54                                        3508 non-null   int64  \n 57  55-64                                        3508 non-null   int64  \n 58  65+                                          3508 non-null   int64  \ndtypes: float64(10), int64(30), object(19)\nmemory usage: 1.6+ MB\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-a3624a05-3055-40b0-bd52-769edb43f3aa",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "576f2697",
    "execution_start": 1622126501992,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.feature_selection import f_regression, RFE, SelectKBest",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-d305c63a-99ca-4dd8-ba9c-c544bdd68c9b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1039a82",
    "execution_start": 1622126502001,
    "execution_millis": 15,
    "deepnote_cell_type": "code"
   },
   "source": "list(df.columns)",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 17,
     "data": {
      "text/plain": "['age',\n 'gender',\n 'race',\n 'date',\n 'city',\n 'state',\n 'zipcode',\n 'county',\n 'agency_responsible',\n 'cause_of_death',\n 'description_of_circumstances',\n 'official_disposition',\n 'criminal_charges_filed',\n 'mental_illness',\n 'armed_unarmed_status',\n 'alleged_weapon',\n 'alleged_threat_lvl',\n 'fleeing',\n 'body_camera',\n 'geography',\n 'encounter_type_draft',\n 'initial_reported_reason_for_encounter_draft',\n 'known_past_shootings_of_officer_draft',\n 'is_female',\n 'is_male',\n 'is_transgender',\n 'was_fleeing',\n 'was_not fleeing ',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n 'was_domestic_disturbance',\n 'was_mental_health_welfare_check',\n 'was_person_with_a_weapon',\n 'was_traffic_stop',\n 'was_violent_crime_part_1',\n 'is_asian/pacific islander',\n 'is_black',\n 'is_hispanic',\n 'is_native american',\n 'is_unknown race',\n 'is_white',\n 'mntlill_drug or alcohol use',\n 'mntlill_no',\n 'mntlill_unknown',\n 'mntlill_yes',\n 'rural',\n 'suburban',\n 'urban',\n 'cod_lethal',\n 'age_bins',\n 'unknown',\n 'under 12',\n '12-17',\n '18-24',\n '25-34',\n '35-44',\n '45-54',\n '55-64',\n '65+']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00012-775bc13b-cecb-4bf7-81eb-31f4c4d288c9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "368ac104",
    "execution_start": 1622126502006,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "dropcols = ['date',\n 'gender',\n 'race',\n 'city',\n 'state',\n 'zipcode',\n 'county',\n 'agency_responsible',\n 'cause_of_death',\n 'description_of_circumstances',\n 'official_disposition',\n 'criminal_charges_filed',\n 'mental_illness',\n 'armed_unarmed_status',\n 'alleged_threat_lvl',\n 'alleged_weapon',\n 'fleeing',\n 'geography',\n 'encounter_type_draft',\n 'initial_reported_reason_for_encounter_draft',\n 'known_past_shootings_of_officer_draft',\n 'age_bins']\n",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-06b8fccd-5774-4439-a81a-007dec60dc95",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d330f65b",
    "execution_start": 1622126502050,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "train2 = train.drop(columns=dropcols)\nvalidate2 = validate.drop(columns=dropcols)\ntest2 = test.drop(columns=dropcols)",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-3c66ed67-6a30-474b-8c08-cfb4ca02b97e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "569ea54a",
    "execution_start": 1622126502051,
    "execution_millis": 10,
    "deepnote_cell_type": "code"
   },
   "source": "train2.info()",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3508 entries, 4142 to 5708\nData columns (total 38 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   age                              3508 non-null   int64  \n 1   body_camera                      3508 non-null   float64\n 2   is_female                        3508 non-null   int64  \n 3   is_male                          3508 non-null   int64  \n 4   is_transgender                   3508 non-null   int64  \n 5   was_fleeing                      3508 non-null   float64\n 6   was_not fleeing                  3508 non-null   float64\n 7   was_allegedly_armed              3508 non-null   float64\n 8   was_unarmed                      3508 non-null   float64\n 9   was_vehicle                      3508 non-null   float64\n 10  was_domestic_disturbance         3508 non-null   int64  \n 11  was_mental_health_welfare_check  3508 non-null   int64  \n 12  was_person_with_a_weapon         3508 non-null   int64  \n 13  was_traffic_stop                 3508 non-null   int64  \n 14  was_violent_crime_part_1         3508 non-null   int64  \n 15  is_asian/pacific islander        3508 non-null   int64  \n 16  is_black                         3508 non-null   int64  \n 17  is_hispanic                      3508 non-null   int64  \n 18  is_native american               3508 non-null   int64  \n 19  is_unknown race                  3508 non-null   int64  \n 20  is_white                         3508 non-null   int64  \n 21  mntlill_drug or alcohol use      3508 non-null   int64  \n 22  mntlill_no                       3508 non-null   int64  \n 23  mntlill_unknown                  3508 non-null   int64  \n 24  mntlill_yes                      3508 non-null   int64  \n 25  rural                            3508 non-null   float64\n 26  suburban                         3508 non-null   float64\n 27  urban                            3508 non-null   float64\n 28  cod_lethal                       3508 non-null   int64  \n 29  unknown                          3508 non-null   int64  \n 30  under 12                         3508 non-null   int64  \n 31  12-17                            3508 non-null   int64  \n 32  18-24                            3508 non-null   int64  \n 33  25-34                            3508 non-null   int64  \n 34  35-44                            3508 non-null   int64  \n 35  45-54                            3508 non-null   int64  \n 36  55-64                            3508 non-null   int64  \n 37  65+                              3508 non-null   int64  \ndtypes: float64(9), int64(29)\nmemory usage: 1.0 MB\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00014-73c67511-909b-4b82-ae40-277da93d8f6c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b18318e7",
    "execution_start": 1622126502094,
    "execution_millis": 13,
    "deepnote_cell_type": "code"
   },
   "source": "train2.columns",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 21,
     "data": {
      "text/plain": "Index(['age', 'body_camera', 'is_female', 'is_male', 'is_transgender',\n       'was_fleeing', 'was_not fleeing ', 'was_allegedly_armed', 'was_unarmed',\n       'was_vehicle', 'was_domestic_disturbance',\n       'was_mental_health_welfare_check', 'was_person_with_a_weapon',\n       'was_traffic_stop', 'was_violent_crime_part_1',\n       'is_asian/pacific islander', 'is_black', 'is_hispanic',\n       'is_native american', 'is_unknown race', 'is_white',\n       'mntlill_drug or alcohol use', 'mntlill_no', 'mntlill_unknown',\n       'mntlill_yes', 'rural', 'suburban', 'urban', 'cod_lethal', 'unknown',\n       'under 12', '12-17', '18-24', '25-34', '35-44', '45-54', '55-64',\n       '65+'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-3592d1b1-6e38-4bcb-9bb8-7be199f59179",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c5522482",
    "execution_start": 1622126502095,
    "execution_millis": 12,
    "deepnote_cell_type": "code"
   },
   "source": "f_feature = select_kbest(train2, y_train, 15)\nf_feature",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 22,
     "data": {
      "text/plain": "['age',\n 'body_camera',\n 'is_transgender',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n 'was_mental_health_welfare_check',\n 'was_violent_crime_part_1',\n 'is_hispanic',\n 'is_white',\n 'mntlill_no',\n 'mntlill_yes',\n 'rural',\n '55-64',\n '65+']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00019-4661cbe5-93ba-4a7a-bde8-3405d202bee7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ac440bf0",
    "execution_start": 1622126502101,
    "execution_millis": 3744,
    "deepnote_cell_type": "code"
   },
   "source": "rfe_list = rfe(train2, y_train, 15)",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py:72: FutureWarning: Pass n_features_to_select=15 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n  \"will result in an error\", FutureWarning)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00016-e2445307-8f76-4d09-babb-b3623dcc6320",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "adde19a5",
    "execution_start": 1622126505846,
    "execution_millis": 56,
    "deepnote_cell_type": "code"
   },
   "source": "f_feature",
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 24,
     "data": {
      "text/plain": "['age',\n 'body_camera',\n 'is_transgender',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n 'was_mental_health_welfare_check',\n 'was_violent_crime_part_1',\n 'is_hispanic',\n 'is_white',\n 'mntlill_no',\n 'mntlill_yes',\n 'rural',\n '55-64',\n '65+']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-db7d45f2-f0ce-4cf3-aec3-a33672cbb6b3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9d8423df",
    "execution_start": 1622126505939,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "rfe_list",
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 25,
     "data": {
      "text/plain": "['is_female',\n 'is_male',\n 'is_transgender',\n 'was_not fleeing ',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n 'was_person_with_a_weapon',\n 'is_black',\n 'is_unknown race',\n 'is_white',\n 'mntlill_drug or alcohol use',\n 'mntlill_yes',\n 'cod_lethal',\n '65+']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00022-efcf72a8-2116-43ac-beb5-357156da745f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "75be0d0c",
    "execution_start": 1622126505939,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "combo_feats = list(set(f_feature + rfe_list))",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00023-aadd07c2-a6f8-4997-a1b4-9c81e1d91266",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d038553",
    "execution_start": 1622126505940,
    "execution_millis": 106,
    "deepnote_cell_type": "code"
   },
   "source": "len(combo_feats)",
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 27,
     "data": {
      "text/plain": "23"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00024-c41b01d4-a2ee-41e7-b811-24a9d990b932",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8d90ad63",
    "execution_start": 1622126505984,
    "execution_millis": 62,
    "deepnote_cell_type": "code"
   },
   "source": "combo_feats",
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 28,
     "data": {
      "text/plain": "['body_camera',\n 'is_unknown race',\n 'is_transgender',\n 'rural',\n 'mntlill_yes',\n 'age',\n 'is_white',\n 'was_not fleeing ',\n 'was_person_with_a_weapon',\n 'is_hispanic',\n 'was_allegedly_armed',\n 'was_unarmed',\n 'was_vehicle',\n '65+',\n 'is_male',\n 'cod_lethal',\n 'is_black',\n 'mntlill_drug or alcohol use',\n 'was_violent_crime_part_1',\n 'is_female',\n 'mntlill_no',\n 'was_mental_health_welfare_check',\n '55-64']"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-0fa812ed-ef21-43eb-bf19-19d49558c1fd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "32e4eb35",
    "execution_start": 1622126506008,
    "execution_millis": 19,
    "deepnote_cell_type": "code"
   },
   "source": "combo_feats = ['55-64',\n 'is_native american',\n 'mntlill_no',\n 'under 12',\n 'was_traffic_stop',\n 'body_camera',\n 'age',\n 'was_allegedly_armed',\n 'is_black',\n 'was_domestic_disturbance',\n 'was_fleeing',\n 'cod_lethal',\n 'was_mental_health_welfare_check',\n 'is_white',\n 'was_violent_crime_part_1',\n 'was_vehicle',\n 'mntlill_drug or alcohol use',\n 'is_transgender',\n 'is_female']",
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Modeling\n\nCreate a Baseline Model:",
   "metadata": {
    "tags": [],
    "cell_id": "00023-078ed2ec-d202-41f2-ae33-d35bd29d9685",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "897280cf",
    "execution_start": 1621898463294,
    "execution_millis": 13,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00023-5a407d56-0fcb-48e8-ac40-8c34a89e797f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fa46ff5a",
    "execution_start": 1622126506032,
    "execution_millis": 56,
    "deepnote_cell_type": "code"
   },
   "source": "y_train = pd.DataFrame(y_train)\n\ny_train.alleged_threat_lvl.value_counts()\n",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 30,
     "data": {
      "text/plain": "1.0    2378\n0.0    1130\nName: alleged_threat_lvl, dtype: int64"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00023-ee3157ba-14d0-4f4c-add3-3525628778f2",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "71519740",
    "execution_start": 1622126506037,
    "execution_millis": 51,
    "deepnote_cell_type": "code"
   },
   "source": "baseline = 0\nbaseline_accuracy = round((y_train.alleged_threat_lvl == baseline).mean(),4)\nbaseline_accuracy\nprint(f'Baseline accuracy is {baseline_accuracy}')",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "Baseline accuracy is 0.3221\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "\n\n\nRandom Forest ",
   "metadata": {
    "tags": [],
    "cell_id": "00023-515ba470-8d61-4094-b604-b79976dbf9f0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00024-d3ef19db-34d5-418f-ada7-9aad1834afac",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5fe20fb4",
    "execution_start": 1622126506101,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\n# create the model \nrf = RandomForestClassifier(bootstrap=True, \n                            class_weight=None, \n                            criterion='gini',\n                            min_samples_leaf=3,\n                            n_estimators=100,\n                            max_depth=3, \n                            random_state=123)\n\n",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00025-f804edfc-1bef-44b2-bbcf-46ada16d5e0a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "35a7848c",
    "execution_start": 1622126506102,
    "execution_millis": 268,
    "deepnote_cell_type": "code"
   },
   "source": "# fit the model\nrf.fit(train2, y_train)\n\n\n\n",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py-core/lib/python3.7/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n  \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 33,
     "data": {
      "text/plain": "RandomForestClassifier(max_depth=3, min_samples_leaf=3, random_state=123)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Random Forest generated list of feature importances",
   "metadata": {
    "tags": [],
    "cell_id": "00031-3c145fb2-efd7-41f2-bda6-9dbe91c38e86",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00031-9166225f-f78f-41b3-85c5-f2309d845c2f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2d017813",
    "execution_start": 1622126506402,
    "execution_millis": 676,
    "deepnote_cell_type": "code"
   },
   "source": "# Find feature importance\nprint(rf.feature_importances_)\n\n\nfeature_names = list(train2.columns)\n\nplt.figure(figsize=(12, 11))\nplt.barh(feature_names, rf.feature_importances_)\n\n",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "text": "[0.050445   0.01960306 0.00967701 0.01014124 0.00338965 0.01179578\n 0.         0.3205173  0.11711505 0.02289323 0.01052646 0.01436981\n 0.00565214 0.00289052 0.04990279 0.00851644 0.00911022 0.03896344\n 0.00765382 0.00150679 0.01994885 0.00543419 0.03424818 0.00883928\n 0.02465709 0.01966089 0.00950413 0.00555056 0.10846197 0.00418416\n 0.         0.00383472 0.0061636  0.00351938 0.00665933 0.00326851\n 0.00672891 0.0146665 ]\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 34,
     "data": {
      "text/plain": "<BarContainer object of 38 artists>"
     },
     "metadata": {}
    },
    {
     "data": {
      "text/plain": "<Figure size 864x792 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 863,
       "height": 629
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Top Features according to Random Forest: (ordered greatest to least)\nwas_fleeing<br>\nwas_allegedly_armed<br>\nwas_violent_crime<br>\nwas_unarmed<br>\nage\n",
   "metadata": {
    "tags": [],
    "cell_id": "00033-cef110d8-e52d-4feb-9815-1809a71b4f18",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00026-ca4a9c6e-9836-498a-ae28-c6186e40a41f",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b18318e7",
    "execution_start": 1622126507080,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "train2.columns",
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 35,
     "data": {
      "text/plain": "Index(['age', 'body_camera', 'is_female', 'is_male', 'is_transgender',\n       'was_fleeing', 'was_not fleeing ', 'was_allegedly_armed', 'was_unarmed',\n       'was_vehicle', 'was_domestic_disturbance',\n       'was_mental_health_welfare_check', 'was_person_with_a_weapon',\n       'was_traffic_stop', 'was_violent_crime_part_1',\n       'is_asian/pacific islander', 'is_black', 'is_hispanic',\n       'is_native american', 'is_unknown race', 'is_white',\n       'mntlill_drug or alcohol use', 'mntlill_no', 'mntlill_unknown',\n       'mntlill_yes', 'rural', 'suburban', 'urban', 'cod_lethal', 'unknown',\n       'under 12', '12-17', '18-24', '25-34', '35-44', '45-54', '55-64',\n       '65+'],\n      dtype='object')"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00027-d3f95a7f-fd59-45c6-a522-728d8e97850e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9330a7f8",
    "execution_start": 1622126507135,
    "execution_millis": 121,
    "deepnote_cell_type": "code"
   },
   "source": "# make predictions\ny_pred = rf.predict(train2)\n\n# estimate probability\ny_pred_proba = rf.predict_proba(train2)\n\n\n#Compute accuracy\ntrain_accuracy = round(rf.score(train2, y_train),2)\nprint('Accuracy of random forest classifier on training set: {:.2f}'\n     .format(rf.score(train2, y_train)))\n",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of random forest classifier on training set: 0.69\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00028-55ef49e9-e134-4cba-b91b-a01bb25a1347",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "571ca5f9",
    "execution_start": 1622126507290,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "# run classification report\nprint(classification_report(y_train, y_pred))",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n         0.0       0.89      0.03      0.06      1130\n         1.0       0.68      1.00      0.81      2378\n\n    accuracy                           0.69      3508\n   macro avg       0.79      0.51      0.44      3508\nweighted avg       0.75      0.69      0.57      3508\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-8cf1818c-8672-4d06-a947-445812a92a61",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3a14f657",
    "execution_start": 1622126507291,
    "execution_millis": 321,
    "deepnote_cell_type": "code"
   },
   "source": "# fit the model on validate\nrf.fit(validate2, y_validate)\n\n# make predictions\ny_pred_val = rf.predict(validate2)\n\n# estimate probability\ny_pred_val_proba = rf.predict_proba(validate2)\n\n#Compute accuracy\nvalidate_accuracy = round(rf.score(validate2, y_validate),2)\nprint('Accuracy of random forest classifier on validate set: {:.2f}'\n     .format(rf.score(validate2, y_validate)))\n",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of random forest classifier on validate set: 0.68\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-af4eb133-581a-4f99-9bfc-ec69559453c0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bb080a19",
    "execution_start": 1622126507624,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "source": "# run classification report on validate\nprint(classification_report(y_validate, y_pred_val))",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n         0.0       0.91      0.06      0.11       500\n         1.0       0.68      1.00      0.81      1004\n\n    accuracy                           0.68      1504\n   macro avg       0.79      0.53      0.46      1504\nweighted avg       0.76      0.68      0.58      1504\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00034-3c2f89f9-ae98-4ab6-9f40-5f87b1e4df6b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a5201d0f",
    "execution_start": 1622126507678,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "def get_metrics_bin(clf, X, y):\n    '''\n    get_metrics_bin will take in a sklearn classifier model, an X and a y variable and utilize\n    the model to make a prediction and then gather accuracy, class report evaluations\n\n    return:  a classification report as a pandas DataFrame\n    '''\n    y_pred = clf.predict(X)\n    accuracy = clf.score(X, y)\n    conf = confusion_matrix(y, y_pred)\n    class_report = pd.DataFrame(classification_report(y, y_pred, output_dict=True)).T\n    tpr = conf[1][1] / conf[1].sum()\n    fpr = conf[0][1] / conf[0].sum()\n    tnr = conf[0][0] / conf[0].sum()\n    fnr = conf[1][0] / conf[1].sum()\n    print(f'''\n    The accuracy for our model is {accuracy:.4}\n    The True Positive Rate is {tpr:.3}, The False Positive Rate is {fpr:.3},\n    The True Negative Rate is {tnr:.3}, and the False Negative Rate is {fnr:.3}\n    ''')\n    return class_report",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00034-21f54af0-6d73-4293-bb45-c42cc0a79e49",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c1f85ee1",
    "execution_start": 1622126507679,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "# X = validate2\n# clf = RandomForestClassifier\n# print('Model #1: min samples 3, max depth 3')\n# class_report_val = get_metrics_bin(clf, validate2, y_validate)\n# # print('-------------------------------------------\\n Model #2: min samples 3, max_depth 3\\n')\n# # class_report_val1 = get_metrics_bin(clf1, X_val, y_val)",
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Takeaways on Random Forest Classifier Model (max depth 3):\n\nBaseline accuracy = 51% <br>\nAccuracy on Train = 70% <br>\nAccuracy on Validate = 72%",
   "metadata": {
    "tags": [],
    "cell_id": "00029-b74715f9-548b-430d-8ce6-cbba70590e45",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bb95de7",
    "execution_start": 1621894512751,
    "execution_millis": 11,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00032-2b00238d-061d-4bec-ae1a-bb5677d827a1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2e7e6100",
    "execution_start": 1622126507680,
    "execution_millis": 35,
    "deepnote_cell_type": "code"
   },
   "source": "\n#begin building a dataframe to record accuracy\nmetric_df = pd.DataFrame(data=[{\n    'model': 'random forest', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(train_accuracy, 2),\n    'validate_accuracy': round(validate_accuracy, 2)}])\nmetric_df",
   "execution_count": 42,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 42,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 1,
       "column_count": 4,
       "columns": [
        {
         "name": "model",
         "dtype": "object",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "categories": [
           {
            "name": "random forest",
            "count": 1
           }
          ]
         }
        },
        {
         "name": "baseline_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.32",
          "max": "0.32",
          "histogram": [
           {
            "bin_start": -0.18,
            "bin_end": -0.07999999999999999,
            "count": 0
           },
           {
            "bin_start": -0.07999999999999999,
            "bin_end": 0.020000000000000018,
            "count": 0
           },
           {
            "bin_start": 0.020000000000000018,
            "bin_end": 0.12000000000000005,
            "count": 0
           },
           {
            "bin_start": 0.12000000000000005,
            "bin_end": 0.22000000000000003,
            "count": 0
           },
           {
            "bin_start": 0.22000000000000003,
            "bin_end": 0.32,
            "count": 0
           },
           {
            "bin_start": 0.32,
            "bin_end": 0.4200000000000001,
            "count": 1
           },
           {
            "bin_start": 0.4200000000000001,
            "bin_end": 0.52,
            "count": 0
           },
           {
            "bin_start": 0.52,
            "bin_end": 0.6200000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6200000000000001,
            "bin_end": 0.72,
            "count": 0
           },
           {
            "bin_start": 0.72,
            "bin_end": 0.8200000000000001,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "train_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.69",
          "max": "0.69",
          "histogram": [
           {
            "bin_start": 0.18999999999999995,
            "bin_end": 0.2899999999999999,
            "count": 0
           },
           {
            "bin_start": 0.2899999999999999,
            "bin_end": 0.38999999999999996,
            "count": 0
           },
           {
            "bin_start": 0.38999999999999996,
            "bin_end": 0.49,
            "count": 0
           },
           {
            "bin_start": 0.49,
            "bin_end": 0.59,
            "count": 0
           },
           {
            "bin_start": 0.59,
            "bin_end": 0.69,
            "count": 0
           },
           {
            "bin_start": 0.69,
            "bin_end": 0.79,
            "count": 1
           },
           {
            "bin_start": 0.79,
            "bin_end": 0.89,
            "count": 0
           },
           {
            "bin_start": 0.89,
            "bin_end": 0.99,
            "count": 0
           },
           {
            "bin_start": 0.99,
            "bin_end": 1.0899999999999999,
            "count": 0
           },
           {
            "bin_start": 1.0899999999999999,
            "bin_end": 1.19,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "validate_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.68",
          "max": "0.68",
          "histogram": [
           {
            "bin_start": 0.18000000000000005,
            "bin_end": 0.28,
            "count": 0
           },
           {
            "bin_start": 0.28,
            "bin_end": 0.38000000000000006,
            "count": 0
           },
           {
            "bin_start": 0.38000000000000006,
            "bin_end": 0.4800000000000001,
            "count": 0
           },
           {
            "bin_start": 0.4800000000000001,
            "bin_end": 0.5800000000000001,
            "count": 0
           },
           {
            "bin_start": 0.5800000000000001,
            "bin_end": 0.68,
            "count": 0
           },
           {
            "bin_start": 0.68,
            "bin_end": 0.7800000000000001,
            "count": 1
           },
           {
            "bin_start": 0.7800000000000001,
            "bin_end": 0.8800000000000001,
            "count": 0
           },
           {
            "bin_start": 0.8800000000000001,
            "bin_end": 0.9800000000000001,
            "count": 0
           },
           {
            "bin_start": 0.9800000000000001,
            "bin_end": 1.08,
            "count": 0
           },
           {
            "bin_start": 1.08,
            "bin_end": 1.1800000000000002,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "model": "random forest",
         "baseline_accuracy": 0.32,
         "train_accuracy": 0.69,
         "validate_accuracy": 0.68,
         "_deepnote_index_column": 0
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "           model  baseline_accuracy  train_accuracy  validate_accuracy\n0  random forest               0.32            0.69               0.68",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>baseline_accuracy</th>\n      <th>train_accuracy</th>\n      <th>validate_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random forest</td>\n      <td>0.32</td>\n      <td>0.69</td>\n      <td>0.68</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "00037-c7741957-35d0-43c9-b5e6-fff0faebc2a6",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1622126507708,
    "execution_millis": 0,
    "deepnote_cell_type": "visualization"
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Naive Bayes\nNaïve Bayes Classifier is one of the simple and most effective Classification algorithms which helps in building fast machine learning models that can make quick predictions. It is a probabilistic classifier, which means it predicts on the basis of the probability of an object. It's biggest limitation is that it implicitly assumes that all the attributes are mutually independent. (In real life, it's almost impossible that we get a set of predictors that are completely independent or one another.)",
   "metadata": {
    "tags": [],
    "cell_id": "00036-bc2283cf-5389-4db5-b928-2d9743c2a13b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "99d3384f",
    "execution_start": 1621900322718,
    "execution_millis": 7,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00038-bf577518-5ce8-4a7c-b12c-ad63c5c4e317",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fe51bc76",
    "execution_start": 1622126507709,
    "execution_millis": 32,
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.naive_bayes import CategoricalNB\n\n# make the model\nclassifier = CategoricalNB()\n\n# fit the model\nclassifier.fit(train2, y_train)",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "text": "/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n  return f(*args, **kwargs)\n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 43,
     "data": {
      "text/plain": "CategoricalNB()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00039-f8de9f52-1243-4ab5-99f1-55dad9c3156b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "dad90cf1",
    "execution_start": 1622126507744,
    "execution_millis": 533,
    "deepnote_cell_type": "code"
   },
   "source": "# make predictions on train\nnb_y_pred  =  classifier.predict(train2)\n\n# make predictions on validate\nnb_y_val_pred  =  classifier.predict(validate2)",
   "execution_count": 44,
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b940bdeeea91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# make predictions on validate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnb_y_val_pred\u001b[0m  \u001b[0;34m=\u001b[0m  \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0mjll\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0mtotal_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjll\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_log_prior_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtotal_ll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00040-8012050f-8a4d-4414-b974-95543fe6cd30",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "20ca0f84",
    "execution_start": 1622080275975,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "# evaluate model on train\nfrom sklearn.metrics import confusion_matrix,accuracy_score\ncm_train = confusion_matrix(y_train, nb_y_pred)\nac_train = accuracy_score(y_train,nb_y_pred)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00041-00cf078f-1b1f-486a-84f1-724cb86ded7a",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "85adb028",
    "execution_start": 1622080275976,
    "execution_millis": 0,
    "deepnote_cell_type": "code"
   },
   "source": "# evaluate model on validate\ncm_validate = confusion_matrix(y_validate, nb_y_val_pred)\nac_validate = accuracy_score(y_validate,nb_y_val_pred)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00042-307e743c-b4e2-46dd-9a4e-be45fb381299",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "98109a86",
    "execution_start": 1622080275977,
    "execution_millis": 6,
    "deepnote_cell_type": "code"
   },
   "source": "print('Accuracy of Naive Bayes Gaussian Classifier on train set: {:.2f}'.format(ac_train))\nprint('Accuracy of Naive Bayes Gaussian Classifier on validate set: {:.2f}'.format(ac_validate))",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy of Naive Bayes Gaussian Classifier on train set: 0.70\nAccuracy of Naive Bayes Gaussian Classifier on validate set: 0.68\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Takeaways on Naive Bayes Model:\nBaseline accuracy = 51% <br>\nAccuracy on Train = 70% <br>\nAccuracy on Validate = 68%",
   "metadata": {
    "tags": [],
    "cell_id": "00045-9732d597-06db-4357-a678-493f3cbeec4c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "94e0f3ab",
    "execution_start": 1621902072354,
    "execution_millis": 7,
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Dataframe Summarizing Models",
   "metadata": {
    "tags": [],
    "cell_id": "00035-1f82fffe-df47-4cc4-a31c-a9432e509979",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00043-c8dcda21-b9ad-414d-b940-a027a05dced4",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "bce38aaf",
    "execution_start": 1622080275980,
    "execution_millis": 40,
    "deepnote_cell_type": "code"
   },
   "source": "# append dataframe to record accuracy on Naive Bayes\nmetric_df = metric_df.append({\n    'model': 'naive bayes', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(ac_train, 2),\n    'validate_accuracy':round(ac_validate,2)}, ignore_index=True)\n  \n\n\nmetric_df",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 46,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 2,
       "column_count": 4,
       "columns": [
        {
         "name": "model",
         "dtype": "object",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "categories": [
           {
            "name": "random forest",
            "count": 1
           },
           {
            "name": "naive bayes",
            "count": 1
           }
          ]
         }
        },
        {
         "name": "baseline_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.51",
          "max": "0.51",
          "histogram": [
           {
            "bin_start": 0.010000000000000009,
            "bin_end": 0.11000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.11000000000000001,
            "bin_end": 0.21000000000000002,
            "count": 0
           },
           {
            "bin_start": 0.21000000000000002,
            "bin_end": 0.31000000000000005,
            "count": 0
           },
           {
            "bin_start": 0.31000000000000005,
            "bin_end": 0.41000000000000003,
            "count": 0
           },
           {
            "bin_start": 0.41000000000000003,
            "bin_end": 0.51,
            "count": 0
           },
           {
            "bin_start": 0.51,
            "bin_end": 0.6100000000000001,
            "count": 2
           },
           {
            "bin_start": 0.6100000000000001,
            "bin_end": 0.7100000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7100000000000001,
            "bin_end": 0.81,
            "count": 0
           },
           {
            "bin_start": 0.81,
            "bin_end": 0.91,
            "count": 0
           },
           {
            "bin_start": 0.91,
            "bin_end": 1.01,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "train_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.7",
          "max": "0.7",
          "histogram": [
           {
            "bin_start": 0.19999999999999996,
            "bin_end": 0.29999999999999993,
            "count": 0
           },
           {
            "bin_start": 0.29999999999999993,
            "bin_end": 0.39999999999999997,
            "count": 0
           },
           {
            "bin_start": 0.39999999999999997,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6,
            "count": 0
           },
           {
            "bin_start": 0.6,
            "bin_end": 0.7,
            "count": 0
           },
           {
            "bin_start": 0.7,
            "bin_end": 0.8,
            "count": 2
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 0
           },
           {
            "bin_start": 1,
            "bin_end": 1.1,
            "count": 0
           },
           {
            "bin_start": 1.1,
            "bin_end": 1.2,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "validate_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0.68",
          "max": "0.72",
          "histogram": [
           {
            "bin_start": 0.68,
            "bin_end": 0.684,
            "count": 1
           },
           {
            "bin_start": 0.684,
            "bin_end": 0.6880000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6880000000000001,
            "bin_end": 0.6920000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6920000000000001,
            "bin_end": 0.6960000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6960000000000001,
            "bin_end": 0.7,
            "count": 0
           },
           {
            "bin_start": 0.7,
            "bin_end": 0.704,
            "count": 0
           },
           {
            "bin_start": 0.704,
            "bin_end": 0.708,
            "count": 0
           },
           {
            "bin_start": 0.708,
            "bin_end": 0.712,
            "count": 0
           },
           {
            "bin_start": 0.712,
            "bin_end": 0.716,
            "count": 0
           },
           {
            "bin_start": 0.716,
            "bin_end": 0.72,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "model": "random forest",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.72,
         "_deepnote_index_column": 0
        },
        {
         "model": "naive bayes",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.68,
         "_deepnote_index_column": 1
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "           model  baseline_accuracy  train_accuracy  validate_accuracy\n0  random forest               0.51             0.7               0.72\n1    naive bayes               0.51             0.7               0.68",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>baseline_accuracy</th>\n      <th>train_accuracy</th>\n      <th>validate_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random forest</td>\n      <td>0.51</td>\n      <td>0.7</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>naive bayes</td>\n      <td>0.51</td>\n      <td>0.7</td>\n      <td>0.68</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00046-8a5b83a8-30e3-483a-b5ca-c5cc36802154",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### GridSearchCV",
   "metadata": {
    "tags": [],
    "cell_id": "00046-217bb1dc-a743-42a8-ab02-21847598bdbc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00047-35748be9-71e7-4d9e-bddb-b1cf454b54f1",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "2264946b",
    "execution_start": 1622080275999,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom scipy.stats import uniform",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00048-22ef8f8c-abdc-423c-83c9-d63f8767c7d9",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "cd3ac985",
    "execution_start": 1622080276009,
    "execution_millis": 54650,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Create a parameter dictionary for the model, {'parameter': [list of settings]}\nparameters = [\n    {\n    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n    'shuffle': [True, False],\n    'verbose': [0, 1, 5, 10],\n    'class_weight': [None, 'balanced'],\n    },\n]\n# Created variable model which holds the KNN model\nmodel = SGDClassifier()\n# Create grid_search model, looking at recall\ngrid_search = GridSearchCV(model,\n                           param_grid=parameters,\n                           scoring='accuracy',\n                           )\n# Create variable r that hold the FIT grid_search\nr = grid_search.fit(X_train[f_feature], y_train)\nscores = r.cv_results_\nlm = r.best_estimator_",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Norm: 0.21, NNZs: 15, Bias: 0.828760, T: 27076, Avg. loss: 0.976934\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.826766, T: 30944, Avg. loss: 0.974783\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.315113, T: 3867, Avg. loss: 2.468035\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.302576, T: 7734, Avg. loss: 1.004415\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.296667, T: 11601, Avg. loss: 0.973992\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.292499, T: 15468, Avg. loss: 0.973255\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.289905, T: 19335, Avg. loss: 0.966912\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.287417, T: 23202, Avg. loss: 0.969365\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.285891, T: 27069, Avg. loss: 0.965391\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.284129, T: 30936, Avg. loss: 0.962874\nTotal training time: 0.00 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.282427, T: 34803, Avg. loss: 0.965441\nTotal training time: 0.00 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.281206, T: 38670, Avg. loss: 0.963520\nTotal training time: 0.00 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.280289, T: 42537, Avg. loss: 0.968434\nTotal training time: 0.00 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.279267, T: 46404, Avg. loss: 0.960523\nTotal training time: 0.00 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 15, Bias: 0.277867, T: 50271, Avg. loss: 0.956556\nTotal training time: 0.00 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 15, Bias: 0.277315, T: 54138, Avg. loss: 0.957893\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 15, Bias: 0.276562, T: 58005, Avg. loss: 0.964021\nTotal training time: 0.01 seconds.\n-- Epoch 16\nNorm: 0.22, NNZs: 15, Bias: 0.275999, T: 61872, Avg. loss: 0.962094\nTotal training time: 0.01 seconds.\n-- Epoch 17\nNorm: 0.22, NNZs: 15, Bias: 0.275075, T: 65739, Avg. loss: 0.960387\nTotal training time: 0.01 seconds.\n-- Epoch 18\nNorm: 0.22, NNZs: 15, Bias: 0.274290, T: 69606, Avg. loss: 0.952211\nTotal training time: 0.01 seconds.\n-- Epoch 19\nNorm: 0.22, NNZs: 15, Bias: 0.273962, T: 73473, Avg. loss: 0.958381\nTotal training time: 0.01 seconds.\n-- Epoch 20\nNorm: 0.22, NNZs: 15, Bias: 0.273418, T: 77340, Avg. loss: 0.955089\nTotal training time: 0.01 seconds.\n-- Epoch 21\nNorm: 0.22, NNZs: 15, Bias: 0.272777, T: 81207, Avg. loss: 0.962769\nTotal training time: 0.01 seconds.\n-- Epoch 22\nNorm: 0.22, NNZs: 15, Bias: 0.272205, T: 85074, Avg. loss: 0.958872\nTotal training time: 0.01 seconds.\n-- Epoch 23\nNorm: 0.22, NNZs: 15, Bias: 0.271632, T: 88941, Avg. loss: 0.958971\nTotal training time: 0.01 seconds.\nConvergence after 23 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.16, NNZs: 15, Bias: -0.814197, T: 3867, Avg. loss: 1.862996\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.810496, T: 7734, Avg. loss: 0.973274\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.809733, T: 11601, Avg. loss: 0.958107\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: -0.810169, T: 15468, Avg. loss: 0.967195\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.810700, T: 19335, Avg. loss: 0.951200\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.810509, T: 23202, Avg. loss: 0.945856\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: -0.810884, T: 27069, Avg. loss: 0.946740\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 15, Bias: -0.811744, T: 30936, Avg. loss: 0.953915\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.812661, T: 34803, Avg. loss: 0.953675\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 15, Bias: -0.812819, T: 38670, Avg. loss: 0.938997\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: -0.813155, T: 42537, Avg. loss: 0.950193\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: -0.813450, T: 46404, Avg. loss: 0.944039\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 15, Bias: -0.813870, T: 50271, Avg. loss: 0.944299\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 15, Bias: -0.814449, T: 54138, Avg. loss: 0.936509\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 15, Bias: -0.814643, T: 58005, Avg. loss: 0.945691\nTotal training time: 0.02 seconds.\n-- Epoch 16\nNorm: 0.21, NNZs: 15, Bias: -0.814531, T: 61872, Avg. loss: 0.933616\nTotal training time: 0.02 seconds.\n-- Epoch 17\nNorm: 0.21, NNZs: 15, Bias: -0.814874, T: 65739, Avg. loss: 0.939152\nTotal training time: 0.02 seconds.\n-- Epoch 18\nNorm: 0.21, NNZs: 15, Bias: -0.815034, T: 69606, Avg. loss: 0.938015\nTotal training time: 0.08 seconds.\n-- Epoch 19\nNorm: 0.21, NNZs: 15, Bias: -0.815410, T: 73473, Avg. loss: 0.943185\nTotal training time: 0.08 seconds.\n-- Epoch 20\nNorm: 0.21, NNZs: 15, Bias: -0.815747, T: 77340, Avg. loss: 0.939898\nTotal training time: 0.08 seconds.\n-- Epoch 21\nNorm: 0.21, NNZs: 15, Bias: -0.816228, T: 81207, Avg. loss: 0.940617\nTotal training time: 0.09 seconds.\nConvergence after 21 epochs took 0.09 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.813544, T: 3867, Avg. loss: 1.563121\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.796574, T: 7734, Avg. loss: 0.994202\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.788509, T: 11601, Avg. loss: 0.994897\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.783160, T: 15468, Avg. loss: 0.971883\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.779820, T: 19335, Avg. loss: 0.986341\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.777320, T: 23202, Avg. loss: 0.977290\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.774427, T: 27069, Avg. loss: 0.981034\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.772940, T: 30936, Avg. loss: 0.976681\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.771683, T: 34803, Avg. loss: 0.973345\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.447964, T: 3867, Avg. loss: 1.847895\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.436012, T: 7734, Avg. loss: 0.987081\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.430509, T: 11601, Avg. loss: 0.965860\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.427495, T: 15468, Avg. loss: 0.966101\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.424314, T: 19335, Avg. loss: 0.949107\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.423025, T: 23202, Avg. loss: 0.973044\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.422258, T: 27069, Avg. loss: 0.972485\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.420428, T: 30936, Avg. loss: 0.954773\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.419480, T: 34803, Avg. loss: 0.960126\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.418119, T: 38670, Avg. loss: 0.956003\nTotal training time: 0.01 seconds.\nConvergence after 10 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.16, NNZs: 15, Bias: -0.513442, T: 3868, Avg. loss: 1.806891\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: -0.514614, T: 7736, Avg. loss: 0.972542\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: -0.515605, T: 11604, Avg. loss: 0.968965\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: -0.518382, T: 15472, Avg. loss: 0.950837\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: -0.520269, T: 19340, Avg. loss: 0.946317\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.521391, T: 23208, Avg. loss: 0.941913\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: -0.522523, T: 27076, Avg. loss: 0.955137\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: -0.524050, T: 30944, Avg. loss: 0.953770\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: -0.524961, T: 34812, Avg. loss: 0.948126\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: -0.525830, T: 38680, Avg. loss: 0.941457\nTotal training time: 0.07 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: -0.526605, T: 42548, Avg. loss: 0.939959\nTotal training time: 0.07 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: -0.527700, T: 46416, Avg. loss: 0.938116\nTotal training time: 0.07 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 15, Bias: -0.528089, T: 50284, Avg. loss: 0.946558\nTotal training time: 0.07 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 15, Bias: -0.528955, T: 54152, Avg. loss: 0.937841\nTotal training time: 0.07 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: -0.529406, T: 58020, Avg. loss: 0.941723\nTotal training time: 0.08 seconds.\n-- Epoch 16\nNorm: 0.22, NNZs: 15, Bias: -0.529855, T: 61888, Avg. loss: 0.938606\nTotal training time: 0.08 seconds.\n-- Epoch 17\nNorm: 0.22, NNZs: 15, Bias: -0.530582, T: 65756, Avg. loss: 0.947922\nTotal training time: 0.08 seconds.\nConvergence after 17 epochs took 0.08 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 15, Bias: -0.905223, T: 3867, Avg. loss: 1.311422\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.899070, T: 7734, Avg. loss: 0.969841\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.896748, T: 11601, Avg. loss: 0.955577\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 15, Bias: -0.895927, T: 15468, Avg. loss: 0.951618\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.895591, T: 19335, Avg. loss: 0.951667\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.895173, T: 23202, Avg. loss: 0.953631\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.894876, T: 27069, Avg. loss: 0.952417\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 15, Bias: -0.894745, T: 30936, Avg. loss: 0.951819\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.894743, T: 34803, Avg. loss: 0.951205\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 15, Bias: 0.815444, T: 3867, Avg. loss: 1.914033\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.798935, T: 7734, Avg. loss: 0.988788\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.790798, T: 11601, Avg. loss: 0.981051\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.785476, T: 15468, Avg. loss: 0.979066\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.781827, T: 19335, Avg. loss: 0.979000\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.779156, T: 23202, Avg. loss: 0.977237\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.776993, T: 27069, Avg. loss: 0.975920\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.775123, T: 30936, Avg. loss: 0.974840\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.773477, T: 34803, Avg. loss: 0.974083\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.772039, T: 38670, Avg. loss: 0.973455\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.770766, T: 42537, Avg. loss: 0.972627\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.769606, T: 46404, Avg. loss: 0.972288\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.768561, T: 50271, Avg. loss: 0.971908\nTotal training time: 0.01 seconds.\nConvergence after 13 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.819444, T: 3867, Avg. loss: 1.904986\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: 0.802018, T: 7734, Avg. loss: 0.988963\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.793577, T: 11601, Avg. loss: 0.982172\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: 0.788233, T: 15468, Avg. loss: 0.980840\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.784628, T: 19335, Avg. loss: 0.978594\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.781852, T: 23202, Avg. loss: 0.977853\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: 0.779564, T: 27069, Avg. loss: 0.978034\nTotal training time: 0.07 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.777692, T: 30936, Avg. loss: 0.977911\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.776139, T: 34803, Avg. loss: 0.977588\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.774755, T: 38670, Avg. loss: 0.976957\nTotal training time: 0.07 seconds.\nConvergence after 10 epochs took 0.07 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.825833, T: 3867, Avg. loss: 1.906355\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.811119, T: 7734, Avg. loss: 0.987736\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.804096, T: 11601, Avg. loss: 0.979527\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.799536, T: 15468, Avg. loss: 0.977853\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.796495, T: 19335, Avg. loss: 0.976248\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.794229, T: 23202, Avg. loss: 0.976284\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.792378, T: 27069, Avg. loss: 0.976439\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.790919, T: 30936, Avg. loss: 0.976025\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.789638, T: 34803, Avg. loss: 0.974615\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.788497, T: 38670, Avg. loss: 0.974499\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.787519, T: 42537, Avg. loss: 0.973500\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.786606, T: 46404, Avg. loss: 0.972892\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.785811, T: 50271, Avg. loss: 0.972570\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.785076, T: 54138, Avg. loss: 0.971945\nTotal training time: 0.01 seconds.\nConvergence after 14 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.818384, T: 3868, Avg. loss: 1.920305\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: 0.801938, T: 7736, Avg. loss: 0.988807\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.794142, T: 11604, Avg. loss: 0.981883\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.21, NNZs: 15, Bias: 0.789297, T: 15472, Avg. loss: 0.980771\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.21, NNZs: 15, Bias: 0.785937, T: 19340, Avg. loss: 0.978860\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.783290, T: 23208, Avg. loss: 0.977811\nTotal training time: 0.05 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.781096, T: 27076, Avg. loss: 0.976609\nTotal training time: 0.06 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.779229, T: 30944, Avg. loss: 0.974711\nTotal training time: 0.06 seconds.\n-- Epoch 9\nNorm: 0.22, NNZs: 15, Bias: 0.777613, T: 34812, Avg. loss: 0.973673\nTotal training time: 0.06 seconds.\n-- Epoch 10\nNorm: 0.22, NNZs: 15, Bias: 0.776112, T: 38680, Avg. loss: 0.972546\nTotal training time: 0.06 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.774780, T: 42548, Avg. loss: 0.971769\nTotal training time: 0.06 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.773587, T: 46416, Avg. loss: 0.971313\nTotal training time: 0.06 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.772512, T: 50284, Avg. loss: 0.970911\nTotal training time: 0.06 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.771554, T: 54152, Avg. loss: 0.970199\nTotal training time: 0.06 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: 0.770644, T: 58020, Avg. loss: 0.969567\nTotal training time: 0.06 seconds.\nConvergence after 15 epochs took 0.06 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 15, Bias: -0.905223, T: 3867, Avg. loss: 1.311422\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.899070, T: 7734, Avg. loss: 0.969841\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.896748, T: 11601, Avg. loss: 0.955577\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 15, Bias: -0.895927, T: 15468, Avg. loss: 0.951618\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.895591, T: 19335, Avg. loss: 0.951667\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.895173, T: 23202, Avg. loss: 0.953631\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.894876, T: 27069, Avg. loss: 0.952417\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 15, Bias: -0.894745, T: 30936, Avg. loss: 0.951819\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.894743, T: 34803, Avg. loss: 0.951205\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 15, Bias: 0.815444, T: 3867, Avg. loss: 1.914033\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.798935, T: 7734, Avg. loss: 0.988788\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.790798, T: 11601, Avg. loss: 0.981051\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.785476, T: 15468, Avg. loss: 0.979066\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.781827, T: 19335, Avg. loss: 0.979000\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.779156, T: 23202, Avg. loss: 0.977237\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.776993, T: 27069, Avg. loss: 0.975920\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.775123, T: 30936, Avg. loss: 0.974840\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.773477, T: 34803, Avg. loss: 0.974083\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.772039, T: 38670, Avg. loss: 0.973455\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.770766, T: 42537, Avg. loss: 0.972627\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.769606, T: 46404, Avg. loss: 0.972288\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.768561, T: 50271, Avg. loss: 0.971908\nTotal training time: 0.01 seconds.\nConvergence after 13 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.819444, T: 3867, Avg. loss: 1.904986\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: 0.802018, T: 7734, Avg. loss: 0.988963\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.793577, T: 11601, Avg. loss: 0.982172\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: 0.788233, T: 15468, Avg. loss: 0.980840\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.784628, T: 19335, Avg. loss: 0.978594\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.781852, T: 23202, Avg. loss: 0.977853\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: 0.779564, T: 27069, Avg. loss: 0.978034\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.777692, T: 30936, Avg. loss: 0.977911\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.776139, T: 34803, Avg. loss: 0.977588\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.774755, T: 38670, Avg. loss: 0.976957\nTotal training time: 0.01 seconds.\nConvergence after 10 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.825833, T: 3867, Avg. loss: 1.906355\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.811119, T: 7734, Avg. loss: 0.987736\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.804096, T: 11601, Avg. loss: 0.979527\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.799536, T: 15468, Avg. loss: 0.977853\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.796495, T: 19335, Avg. loss: 0.976248\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.794229, T: 23202, Avg. loss: 0.976284\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.792378, T: 27069, Avg. loss: 0.976439\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.790919, T: 30936, Avg. loss: 0.976025\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.789638, T: 34803, Avg. loss: 0.974615\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.788497, T: 38670, Avg. loss: 0.974499\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.787519, T: 42537, Avg. loss: 0.973500\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.786606, T: 46404, Avg. loss: 0.972892\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.785811, T: 50271, Avg. loss: 0.972570\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.785076, T: 54138, Avg. loss: 0.971945\nTotal training time: 0.01 seconds.\nConvergence after 14 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.818384, T: 3868, Avg. loss: 1.920305\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: 0.801938, T: 7736, Avg. loss: 0.988807\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.794142, T: 11604, Avg. loss: 0.981883\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.21, NNZs: 15, Bias: 0.789297, T: 15472, Avg. loss: 0.980771\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.21, NNZs: 15, Bias: 0.785937, T: 19340, Avg. loss: 0.978860\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.783290, T: 23208, Avg. loss: 0.977811\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.781096, T: 27076, Avg. loss: 0.976609\nTotal training time: 0.07 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.779229, T: 30944, Avg. loss: 0.974711\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 0.22, NNZs: 15, Bias: 0.777613, T: 34812, Avg. loss: 0.973673\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 0.22, NNZs: 15, Bias: 0.776112, T: 38680, Avg. loss: 0.972546\nTotal training time: 0.07 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.774780, T: 42548, Avg. loss: 0.971769\nTotal training time: 0.07 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.773587, T: 46416, Avg. loss: 0.971313\nTotal training time: 0.07 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.772512, T: 50284, Avg. loss: 0.970911\nTotal training time: 0.07 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.771554, T: 54152, Avg. loss: 0.970199\nTotal training time: 0.08 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: 0.770644, T: 58020, Avg. loss: 0.969567\nTotal training time: 0.08 seconds.\nConvergence after 15 epochs took 0.08 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 15, Bias: -0.905223, T: 3867, Avg. loss: 1.311422\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 15, Bias: -0.899070, T: 7734, Avg. loss: 0.969841\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 15, Bias: -0.896748, T: 11601, Avg. loss: 0.955577\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 15, Bias: -0.895927, T: 15468, Avg. loss: 0.951618\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 15, Bias: -0.895591, T: 19335, Avg. loss: 0.951667\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 15, Bias: -0.895173, T: 23202, Avg. loss: 0.953631\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 15, Bias: -0.894876, T: 27069, Avg. loss: 0.952417\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 15, Bias: -0.894745, T: 30936, Avg. loss: 0.951819\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 15, Bias: -0.894743, T: 34803, Avg. loss: 0.951205\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 15, Bias: 0.815444, T: 3867, Avg. loss: 1.914033\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.798935, T: 7734, Avg. loss: 0.988788\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.790798, T: 11601, Avg. loss: 0.981051\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.785476, T: 15468, Avg. loss: 0.979066\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.781827, T: 19335, Avg. loss: 0.979000\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.779156, T: 23202, Avg. loss: 0.977237\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.776993, T: 27069, Avg. loss: 0.975920\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.775123, T: 30936, Avg. loss: 0.974840\nTotal training time: 0.00 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.773477, T: 34803, Avg. loss: 0.974083\nTotal training time: 0.00 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.772039, T: 38670, Avg. loss: 0.973455\nTotal training time: 0.00 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.770766, T: 42537, Avg. loss: 0.972627\nTotal training time: 0.00 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.769606, T: 46404, Avg. loss: 0.972288\nTotal training time: 0.00 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.768561, T: 50271, Avg. loss: 0.971908\nTotal training time: 0.00 seconds.\nConvergence after 13 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.819444, T: 3867, Avg. loss: 1.904986\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 15, Bias: 0.802018, T: 7734, Avg. loss: 0.988963\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.793577, T: 11601, Avg. loss: 0.982172\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 15, Bias: 0.788233, T: 15468, Avg. loss: 0.980840\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.784628, T: 19335, Avg. loss: 0.978594\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: 0.781852, T: 23202, Avg. loss: 0.977853\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 15, Bias: 0.779564, T: 27069, Avg. loss: 0.978034\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.777692, T: 30936, Avg. loss: 0.977911\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.776139, T: 34803, Avg. loss: 0.977588\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.774755, T: 38670, Avg. loss: 0.976957\nTotal training time: 0.01 seconds.\nConvergence after 10 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 15, Bias: 0.825833, T: 3867, Avg. loss: 1.906355\nTotal training time: 0.06 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 15, Bias: 0.811119, T: 7734, Avg. loss: 0.987736\nTotal training time: 0.07 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 15, Bias: 0.804096, T: 11601, Avg. loss: 0.979527\nTotal training time: 0.07 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: 0.799536, T: 15468, Avg. loss: 0.977853\nTotal training time: 0.07 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: 0.796495, T: 19335, Avg. loss: 0.976248\nTotal training time: 0.07 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.794229, T: 23202, Avg. loss: 0.976284\nTotal training time: 0.07 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.792378, T: 27069, Avg. loss: 0.976439\nTotal training time: 0.07 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.790919, T: 30936, Avg. loss: 0.976025\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 15, Bias: 0.789638, T: 34803, Avg. loss: 0.974615\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 15, Bias: 0.788497, T: 38670, Avg. loss: 0.974499\nTotal training time: 0.07 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 15, Bias: 0.787519, T: 42537, Avg. loss: 0.973500\nTotal training time: 0.07 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 15, Bias: 0.786606, T: 46404, Avg. loss: 0.972892\nTotal training time: 0.07 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.785811, T: 50271, Avg. loss: 0.972570\nTotal training time: 0.07 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.785076, T: 54138, Avg. loss: 0.971945\nTotal training time: 0.08 seconds.\nConvergence after 14 epochs took 0.08 seconds\n-- Epoch 1\nNorm: 0.19, NNZs: 15, Bias: 0.818384, T: 3868, Avg. loss: 1.920305\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: 0.801938, T: 7736, Avg. loss: 0.988807\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: 0.794142, T: 11604, Avg. loss: 0.981883\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.21, NNZs: 15, Bias: 0.789297, T: 15472, Avg. loss: 0.980771\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.21, NNZs: 15, Bias: 0.785937, T: 19340, Avg. loss: 0.978860\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.21, NNZs: 15, Bias: 0.783290, T: 23208, Avg. loss: 0.977811\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 15, Bias: 0.781096, T: 27076, Avg. loss: 0.976609\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 15, Bias: 0.779229, T: 30944, Avg. loss: 0.974711\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.22, NNZs: 15, Bias: 0.777613, T: 34812, Avg. loss: 0.973673\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.22, NNZs: 15, Bias: 0.776112, T: 38680, Avg. loss: 0.972546\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.22, NNZs: 15, Bias: 0.774780, T: 42548, Avg. loss: 0.971769\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.22, NNZs: 15, Bias: 0.773587, T: 46416, Avg. loss: 0.971313\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.22, NNZs: 15, Bias: 0.772512, T: 50284, Avg. loss: 0.970911\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.22, NNZs: 15, Bias: 0.771554, T: 54152, Avg. loss: 0.970199\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 0.22, NNZs: 15, Bias: 0.770644, T: 58020, Avg. loss: 0.969567\nTotal training time: 0.01 seconds.\nConvergence after 15 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 7.37, NNZs: 15, Bias: 1.406162, T: 4834, Avg. loss: 38.347686\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 6.28, NNZs: 15, Bias: 1.349998, T: 9668, Avg. loss: 5.306740\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 5.35, NNZs: 15, Bias: 1.305976, T: 14502, Avg. loss: 3.354388\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 4.80, NNZs: 15, Bias: 1.231279, T: 19336, Avg. loss: 2.485879\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 4.24, NNZs: 15, Bias: 1.201648, T: 24170, Avg. loss: 2.085090\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 3.97, NNZs: 15, Bias: 1.134589, T: 29004, Avg. loss: 1.798709\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 3.67, NNZs: 15, Bias: 1.105820, T: 33838, Avg. loss: 1.655288\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 3.50, NNZs: 15, Bias: 1.027808, T: 38672, Avg. loss: 1.492101\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 3.23, NNZs: 15, Bias: 0.971477, T: 43506, Avg. loss: 1.418440\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 3.07, NNZs: 15, Bias: 0.957097, T: 48340, Avg. loss: 1.376821\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 2.99, NNZs: 15, Bias: 0.930800, T: 53174, Avg. loss: 1.261254\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 2.86, NNZs: 15, Bias: 0.906851, T: 58008, Avg. loss: 1.230144\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 2.75, NNZs: 15, Bias: 0.896833, T: 62842, Avg. loss: 1.186108\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 2.67, NNZs: 15, Bias: 0.858023, T: 67676, Avg. loss: 1.156794\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 2.60, NNZs: 15, Bias: 0.840976, T: 72510, Avg. loss: 1.117554\nTotal training time: 0.02 seconds.\n-- Epoch 16\nNorm: 2.56, NNZs: 15, Bias: 0.817810, T: 77344, Avg. loss: 1.079536\nTotal training time: 0.02 seconds.\n-- Epoch 17\nNorm: 2.50, NNZs: 15, Bias: 0.797363, T: 82178, Avg. loss: 1.071443\nTotal training time: 0.02 seconds.\n-- Epoch 18\nNorm: 2.44, NNZs: 15, Bias: 0.776258, T: 87012, Avg. loss: 1.044934\nTotal training time: 0.02 seconds.\n-- Epoch 19\nNorm: 2.40, NNZs: 15, Bias: 0.768712, T: 91846, Avg. loss: 1.029003\nTotal training time: 0.09 seconds.\n-- Epoch 20\nNorm: 2.39, NNZs: 15, Bias: 0.770763, T: 96680, Avg. loss: 1.009274\nTotal training time: 0.09 seconds.\n-- Epoch 21\nNorm: 2.38, NNZs: 15, Bias: 0.754690, T: 101514, Avg. loss: 0.994236\nTotal training time: 0.09 seconds.\n-- Epoch 22\nNorm: 2.35, NNZs: 15, Bias: 0.736282, T: 106348, Avg. loss: 0.982415\nTotal training time: 0.09 seconds.\n-- Epoch 23\nNorm: 2.33, NNZs: 15, Bias: 0.744982, T: 111182, Avg. loss: 0.967655\nTotal training time: 0.09 seconds.\n-- Epoch 24\nNorm: 2.30, NNZs: 15, Bias: 0.730745, T: 116016, Avg. loss: 0.967726\nTotal training time: 0.09 seconds.\n-- Epoch 25\nNorm: 2.30, NNZs: 15, Bias: 0.714589, T: 120850, Avg. loss: 0.953087\nTotal training time: 0.09 seconds.\n-- Epoch 26\nNorm: 2.27, NNZs: 15, Bias: 0.702762, T: 125684, Avg. loss: 0.937898\nTotal training time: 0.09 seconds.\n-- Epoch 27\nNorm: 2.26, NNZs: 15, Bias: 0.699682, T: 130518, Avg. loss: 0.931483\nTotal training time: 0.09 seconds.\n-- Epoch 28\nNorm: 2.25, NNZs: 15, Bias: 0.700415, T: 135352, Avg. loss: 0.933362\nTotal training time: 0.09 seconds.\n-- Epoch 29\nNorm: 2.22, NNZs: 15, Bias: 0.692775, T: 140186, Avg. loss: 0.903729\nTotal training time: 0.10 seconds.\n-- Epoch 30\nNorm: 2.22, NNZs: 15, Bias: 0.672698, T: 145020, Avg. loss: 0.897064\nTotal training time: 0.10 seconds.\n-- Epoch 31\nNorm: 2.20, NNZs: 15, Bias: 0.677785, T: 149854, Avg. loss: 0.892656\nTotal training time: 0.10 seconds.\n-- Epoch 32\nNorm: 2.18, NNZs: 15, Bias: 0.672987, T: 154688, Avg. loss: 0.881189\nTotal training time: 0.10 seconds.\n-- Epoch 33\nNorm: 2.17, NNZs: 15, Bias: 0.663972, T: 159522, Avg. loss: 0.883303\nTotal training time: 0.10 seconds.\n-- Epoch 34\nNorm: 2.15, NNZs: 15, Bias: 0.650285, T: 164356, Avg. loss: 0.880543\nTotal training time: 0.10 seconds.\n-- Epoch 35\nNorm: 2.13, NNZs: 15, Bias: 0.659718, T: 169190, Avg. loss: 0.879327\nTotal training time: 0.10 seconds.\n-- Epoch 36\nNorm: 2.13, NNZs: 15, Bias: 0.665919, T: 174024, Avg. loss: 0.871793\nTotal training time: 0.10 seconds.\n-- Epoch 37\nNorm: 2.13, NNZs: 15, Bias: 0.663427, T: 178858, Avg. loss: 0.866347\nTotal training time: 0.10 seconds.\n-- Epoch 38\nNorm: 2.13, NNZs: 15, Bias: 0.662247, T: 183692, Avg. loss: 0.865674\nTotal training time: 0.10 seconds.\n-- Epoch 39\nNorm: 2.11, NNZs: 15, Bias: 0.658959, T: 188526, Avg. loss: 0.860187\nTotal training time: 0.10 seconds.\n-- Epoch 40\nNorm: 2.09, NNZs: 15, Bias: 0.655228, T: 193360, Avg. loss: 0.853340\nTotal training time: 0.10 seconds.\n-- Epoch 41\nNorm: 2.09, NNZs: 15, Bias: 0.657206, T: 198194, Avg. loss: 0.848103\nTotal training time: 0.10 seconds.\n-- Epoch 42\nNorm: 2.08, NNZs: 15, Bias: 0.657820, T: 203028, Avg. loss: 0.841349\nTotal training time: 0.10 seconds.\n-- Epoch 43\nNorm: 2.07, NNZs: 15, Bias: 0.646430, T: 207862, Avg. loss: 0.827202\nTotal training time: 0.10 seconds.\n-- Epoch 44\nNorm: 2.06, NNZs: 15, Bias: 0.640833, T: 212696, Avg. loss: 0.828538\nTotal training time: 0.10 seconds.\n-- Epoch 45\nNorm: 2.05, NNZs: 15, Bias: 0.643747, T: 217530, Avg. loss: 0.828789\nTotal training time: 0.10 seconds.\n-- Epoch 46\nNorm: 2.06, NNZs: 15, Bias: 0.642702, T: 222364, Avg. loss: 0.827391\nTotal training time: 0.10 seconds.\n-- Epoch 47\nNorm: 2.05, NNZs: 15, Bias: 0.633094, T: 227198, Avg. loss: 0.817204\nTotal training time: 0.11 seconds.\n-- Epoch 48\nNorm: 2.05, NNZs: 15, Bias: 0.629005, T: 232032, Avg. loss: 0.818878\nTotal training time: 0.11 seconds.\n-- Epoch 49\nNorm: 2.05, NNZs: 15, Bias: 0.626846, T: 236866, Avg. loss: 0.816777\nTotal training time: 0.11 seconds.\n-- Epoch 50\nNorm: 2.04, NNZs: 15, Bias: 0.626499, T: 241700, Avg. loss: 0.818115\nTotal training time: 0.11 seconds.\n-- Epoch 51\nNorm: 2.04, NNZs: 15, Bias: 0.624772, T: 246534, Avg. loss: 0.810805\nTotal training time: 0.11 seconds.\n-- Epoch 52\nNorm: 2.02, NNZs: 15, Bias: 0.632978, T: 251368, Avg. loss: 0.817934\nTotal training time: 0.11 seconds.\n-- Epoch 53\nNorm: 2.02, NNZs: 15, Bias: 0.631798, T: 256202, Avg. loss: 0.797964\nTotal training time: 0.11 seconds.\n-- Epoch 54\nNorm: 2.02, NNZs: 15, Bias: 0.631144, T: 261036, Avg. loss: 0.804053\nTotal training time: 0.11 seconds.\n-- Epoch 55\nNorm: 2.01, NNZs: 15, Bias: 0.629066, T: 265870, Avg. loss: 0.809159\nTotal training time: 0.11 seconds.\n-- Epoch 56\nNorm: 2.01, NNZs: 15, Bias: 0.623174, T: 270704, Avg. loss: 0.791859\nTotal training time: 0.11 seconds.\n-- Epoch 57\nNorm: 2.00, NNZs: 15, Bias: 0.624753, T: 275538, Avg. loss: 0.800885\nTotal training time: 0.11 seconds.\n-- Epoch 58\nNorm: 2.00, NNZs: 15, Bias: 0.615637, T: 280372, Avg. loss: 0.799807\nTotal training time: 0.11 seconds.\n-- Epoch 59\nNorm: 2.00, NNZs: 15, Bias: 0.610865, T: 285206, Avg. loss: 0.800382\nTotal training time: 0.11 seconds.\n-- Epoch 60\nNorm: 2.00, NNZs: 15, Bias: 0.611618, T: 290040, Avg. loss: 0.797639\nTotal training time: 0.11 seconds.\n-- Epoch 61\nNorm: 2.01, NNZs: 15, Bias: 0.612576, T: 294874, Avg. loss: 0.797422\nTotal training time: 0.11 seconds.\nConvergence after 61 epochs took 0.11 seconds\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00049-17ec2782-a3dc-4b89-a678-94576b39c441",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "32c9439c",
    "execution_start": 1622080330661,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "# Returns max value of the mean test score \nmax(scores['mean_test_score'])",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 49,
     "data": {
      "text/plain": "0.6812163721655201"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00050-9c7659bd-9c73-4b11-8197-2001238ca999",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "46f0d3fb",
    "execution_start": 1622080330667,
    "execution_millis": 20,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "source": "# loop that runs all of the possible parameter configurations from the parameter dictionary above\nfor mean_score, params in sorted(list(zip(scores[\"mean_test_score\"], scores[\"params\"])),key = lambda x: x[0]):\n     print(f'Best parameters for SGD Classifier are {params} with a score of {mean_score}')",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Best parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.502272936511505\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.513027848610781\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.520473556987203\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5208872074525597\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5239902282571227\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5250279942020422\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5262689455981124\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5275210304435609\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5335114685233835\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5434362963296014\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5436649602514446\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5442777281768334\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.5502636700559456\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5566731112210184\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5680825416808511\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5759292683396815\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.5796298556291363\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5850055988404085\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5864559447267059\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5922461948225178\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5930741380676186\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6005207028632233\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6021738059910804\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6061370998648998\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.607965126610871\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6143794921862454\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6143929807883766\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.617292602036993\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6201945784383625\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6239056568628081\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.628441038750827\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6300952124026626\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.641697765388247\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6526633566065246\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6588434915353669\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.661360293409212\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6615549146685337\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6630138247466605\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6646671419793132\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6671394100556458\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.669418555606227\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6696328745067561\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6719045263894866\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6723121819205629\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6725239315635431\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6748015783805542\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6766612926362938\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6772747028760697\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6787346834781752\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6812163721655201\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Best parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} using f_feature from Select K Best\n",
   "metadata": {
    "tags": [],
    "cell_id": "00051-c3636cb1-861e-4d20-ac55-4f50c27ad9cc",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00049-3e3bd1e4-f867-4c2a-aa7d-34e78b11a543",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "6f44e136",
    "is_output_hidden": true,
    "allow_embed": false,
    "execution_start": 1622080330683,
    "execution_millis": 32088,
    "deepnote_cell_type": "code"
   },
   "source": "# Create a parameter dictionary for the model, {'parameter': [list of settings]}\nparameters = [\n    {\n    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n    'shuffle': [True, False],\n    'verbose': [0, 1, 5, 10],\n    'class_weight': [None, 'balanced'],\n    },\n]\n# Created variable model which holds the KNN model\nmodel = SGDClassifier()\n# Create grid_search model, looking at recall\ngrid_search = GridSearchCV(model,\n                           param_grid=parameters,\n                           scoring='accuracy',\n                           )\n# Create variable r that hold the FIT grid_search\nr = grid_search.fit(X_train[rfe_list], y_train)\nscores = r.cv_results_\nlm = r.best_estimator_",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Total training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.013492, T: 7734, Avg. loss: 0.946165\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.004883, T: 11601, Avg. loss: 0.945848\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.001108, T: 15468, Avg. loss: 0.945670\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.005708, T: 19335, Avg. loss: 0.945547\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.009442, T: 23202, Avg. loss: 0.945453\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.012585, T: 27069, Avg. loss: 0.945377\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.24, NNZs: 15, Bias: 0.028819, T: 3868, Avg. loss: 0.948445\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.24, NNZs: 15, Bias: 0.013260, T: 7736, Avg. loss: 0.944546\nTotal training time: 0.01 seconds.\n-- Epoch 3\nNorm: 0.24, NNZs: 15, Bias: 0.004584, T: 11604, Avg. loss: 0.944139\nTotal training time: 0.01 seconds.\n-- Epoch 4\nNorm: 0.24, NNZs: 15, Bias: -0.001461, T: 15472, Avg. loss: 0.943921\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.24, NNZs: 15, Bias: -0.006104, T: 19340, Avg. loss: 0.943775\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.24, NNZs: 15, Bias: -0.009876, T: 23208, Avg. loss: 0.943666\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.24, NNZs: 15, Bias: -0.013052, T: 27076, Avg. loss: 0.943579\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.20, NNZs: 15, Bias: -0.759855, T: 3867, Avg. loss: 0.939707\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.20, NNZs: 15, Bias: -0.760235, T: 7734, Avg. loss: 0.939062\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 15, Bias: -0.760101, T: 11601, Avg. loss: 0.939003\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 15, Bias: -0.760030, T: 15468, Avg. loss: 0.938976\nTotal training time: 0.06 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 15, Bias: -0.759891, T: 19335, Avg. loss: 0.938968\nTotal training time: 0.07 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 15, Bias: -0.759812, T: 23202, Avg. loss: 0.938962\nTotal training time: 0.07 seconds.\nConvergence after 6 epochs took 0.07 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.027397, T: 3867, Avg. loss: 0.947323\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.24, NNZs: 15, Bias: 0.011667, T: 7734, Avg. loss: 0.944687\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.24, NNZs: 15, Bias: 0.002891, T: 11601, Avg. loss: 0.944488\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.24, NNZs: 15, Bias: -0.003225, T: 15468, Avg. loss: 0.944357\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.24, NNZs: 15, Bias: -0.007925, T: 19335, Avg. loss: 0.944257\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.24, NNZs: 15, Bias: -0.011743, T: 23202, Avg. loss: 0.944177\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.24, NNZs: 15, Bias: -0.014958, T: 27069, Avg. loss: 0.944110\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.029448, T: 3867, Avg. loss: 0.951113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.013861, T: 7734, Avg. loss: 0.948007\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.005133, T: 11601, Avg. loss: 0.947681\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.000960, T: 15468, Avg. loss: 0.947495\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.005646, T: 19335, Avg. loss: 0.947366\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.009455, T: 23202, Avg. loss: 0.947266\nTotal training time: 0.07 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.012663, T: 27069, Avg. loss: 0.947186\nTotal training time: 0.07 seconds.\nConvergence after 7 epochs took 0.07 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.028962, T: 3867, Avg. loss: 0.949495\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.013492, T: 7734, Avg. loss: 0.946165\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.004883, T: 11601, Avg. loss: 0.945848\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.001108, T: 15468, Avg. loss: 0.945670\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.005708, T: 19335, Avg. loss: 0.945547\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.009442, T: 23202, Avg. loss: 0.945453\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.012585, T: 27069, Avg. loss: 0.945377\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.24, NNZs: 15, Bias: 0.028819, T: 3868, Avg. loss: 0.948445\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.24, NNZs: 15, Bias: 0.013260, T: 7736, Avg. loss: 0.944546\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.24, NNZs: 15, Bias: 0.004584, T: 11604, Avg. loss: 0.944139\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.24, NNZs: 15, Bias: -0.001461, T: 15472, Avg. loss: 0.943921\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.24, NNZs: 15, Bias: -0.006104, T: 19340, Avg. loss: 0.943775\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.24, NNZs: 15, Bias: -0.009876, T: 23208, Avg. loss: 0.943666\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.24, NNZs: 15, Bias: -0.013052, T: 27076, Avg. loss: 0.943579\nTotal training time: 0.00 seconds.\nConvergence after 7 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.619750, T: 3867, Avg. loss: 0.940460\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.617975, T: 7734, Avg. loss: 0.938479\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.617109, T: 11601, Avg. loss: 0.937789\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.616675, T: 15468, Avg. loss: 0.937261\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.616804, T: 19335, Avg. loss: 0.937109\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.616832, T: 23202, Avg. loss: 0.936704\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.616802, T: 27069, Avg. loss: 0.936909\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.311553, T: 3867, Avg. loss: 0.943520\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.316552, T: 7734, Avg. loss: 0.939948\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.316507, T: 11601, Avg. loss: 0.940082\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.316214, T: 15468, Avg. loss: 0.940738\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.316324, T: 19335, Avg. loss: 0.940243\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.316172, T: 23202, Avg. loss: 0.940483\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.316124, T: 27069, Avg. loss: 0.940421\nTotal training time: 0.00 seconds.\nConvergence after 7 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.536113, T: 3867, Avg. loss: 0.968969\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.535845, T: 7734, Avg. loss: 0.960531\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.535715, T: 11601, Avg. loss: 0.960784\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.535200, T: 15468, Avg. loss: 0.960276\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.535084, T: 19335, Avg. loss: 0.960482\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.535426, T: 23202, Avg. loss: 0.960726\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.535414, T: 27069, Avg. loss: 0.960735\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.221276, T: 3867, Avg. loss: 0.957052\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.218259, T: 7734, Avg. loss: 0.953040\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.219092, T: 11601, Avg. loss: 0.952363\nTotal training time: 0.07 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.218916, T: 15468, Avg. loss: 0.952212\nTotal training time: 0.07 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.219088, T: 19335, Avg. loss: 0.952293\nTotal training time: 0.07 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.219061, T: 23202, Avg. loss: 0.952025\nTotal training time: 0.07 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.219176, T: 27069, Avg. loss: 0.952141\nTotal training time: 0.07 seconds.\nConvergence after 7 epochs took 0.07 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.271957, T: 3868, Avg. loss: 0.947998\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.270683, T: 7736, Avg. loss: 0.941480\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.272234, T: 11604, Avg. loss: 0.940099\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.271941, T: 15472, Avg. loss: 0.940774\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.271973, T: 19340, Avg. loss: 0.940714\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.271969, T: 23208, Avg. loss: 0.940699\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.272026, T: 27076, Avg. loss: 0.940295\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.23, NNZs: 15, Bias: -0.271998, T: 30944, Avg. loss: 0.940356\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.343078, T: 3867, Avg. loss: 0.946794\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.343102, T: 7734, Avg. loss: 0.942516\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.343505, T: 11601, Avg. loss: 0.942450\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.342876, T: 15468, Avg. loss: 0.942739\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.343030, T: 19335, Avg. loss: 0.942078\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.343168, T: 23202, Avg. loss: 0.941979\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.343194, T: 27069, Avg. loss: 0.942192\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.603735, T: 3867, Avg. loss: 0.937252\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.604655, T: 7734, Avg. loss: 0.935309\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.604576, T: 11601, Avg. loss: 0.934894\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.604290, T: 15468, Avg. loss: 0.935018\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.604464, T: 19335, Avg. loss: 0.934506\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.604446, T: 23202, Avg. loss: 0.934779\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.604526, T: 27069, Avg. loss: 0.934525\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.21, NNZs: 15, Bias: -0.723587, T: 3867, Avg. loss: 0.944294\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.722882, T: 7734, Avg. loss: 0.938146\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.721189, T: 11601, Avg. loss: 0.936693\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.720236, T: 15468, Avg. loss: 0.936902\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.719398, T: 19335, Avg. loss: 0.936744\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.718651, T: 23202, Avg. loss: 0.936568\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.718183, T: 27069, Avg. loss: 0.936578\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.22, NNZs: 15, Bias: -0.717704, T: 30936, Avg. loss: 0.936685\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.604139, T: 3867, Avg. loss: 0.964038\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.600960, T: 7734, Avg. loss: 0.959724\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.601088, T: 11601, Avg. loss: 0.959773\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.601504, T: 15468, Avg. loss: 0.959711\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.601747, T: 19335, Avg. loss: 0.959967\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.601681, T: 23202, Avg. loss: 0.959475\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.601937, T: 27069, Avg. loss: 0.959966\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.042386, T: 3868, Avg. loss: 0.950052\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.037987, T: 7736, Avg. loss: 0.947177\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.036727, T: 11604, Avg. loss: 0.945873\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.036481, T: 15472, Avg. loss: 0.945459\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.036218, T: 19340, Avg. loss: 0.945300\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.036038, T: 23208, Avg. loss: 0.945578\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.036102, T: 27076, Avg. loss: 0.945211\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.23, NNZs: 15, Bias: -0.036051, T: 30944, Avg. loss: 0.945259\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.692700, T: 3867, Avg. loss: 0.961889\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.692098, T: 7734, Avg. loss: 0.962840\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.692555, T: 11601, Avg. loss: 0.963274\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.691907, T: 15468, Avg. loss: 0.962922\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.691926, T: 19335, Avg. loss: 0.963246\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.691998, T: 23202, Avg. loss: 0.963278\nTotal training time: 0.01 seconds.\nConvergence after 6 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: -0.383248, T: 3867, Avg. loss: 0.944983\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: -0.379059, T: 7734, Avg. loss: 0.940591\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: -0.379192, T: 11601, Avg. loss: 0.939038\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: -0.378959, T: 15468, Avg. loss: 0.939087\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: -0.378775, T: 19335, Avg. loss: 0.939213\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: -0.378981, T: 23202, Avg. loss: 0.938968\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: -0.378936, T: 27069, Avg. loss: 0.939075\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.23, NNZs: 15, Bias: -0.378883, T: 30936, Avg. loss: 0.939062\nTotal training time: 0.01 seconds.\nConvergence after 8 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.490214, T: 3867, Avg. loss: 0.960429\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.491229, T: 7734, Avg. loss: 0.959923\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.491881, T: 11601, Avg. loss: 0.960133\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.492142, T: 15468, Avg. loss: 0.960021\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.492214, T: 19335, Avg. loss: 0.959639\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.492329, T: 23202, Avg. loss: 0.959898\nTotal training time: 0.00 seconds.\nConvergence after 6 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.356311, T: 3867, Avg. loss: 0.958604\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.353845, T: 7734, Avg. loss: 0.954415\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.353975, T: 11601, Avg. loss: 0.954836\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.354091, T: 15468, Avg. loss: 0.954843\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.354015, T: 19335, Avg. loss: 0.954701\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.353773, T: 23202, Avg. loss: 0.954691\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.353742, T: 27069, Avg. loss: 0.954705\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.078670, T: 3868, Avg. loss: 0.952683\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.075683, T: 7736, Avg. loss: 0.947273\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.075492, T: 11604, Avg. loss: 0.947516\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.076079, T: 15472, Avg. loss: 0.947788\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.075791, T: 19340, Avg. loss: 0.947498\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.075760, T: 23208, Avg. loss: 0.947489\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.075906, T: 27076, Avg. loss: 0.947737\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.686357, T: 3867, Avg. loss: 0.938113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.687095, T: 7734, Avg. loss: 0.935787\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.687238, T: 11601, Avg. loss: 0.935483\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.687264, T: 15468, Avg. loss: 0.935366\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.687202, T: 19335, Avg. loss: 0.935303\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.687182, T: 23202, Avg. loss: 0.935273\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.687155, T: 27069, Avg. loss: 0.935245\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.068531, T: 3867, Avg. loss: 0.948325\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066960, T: 7734, Avg. loss: 0.947785\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.066467, T: 11601, Avg. loss: 0.947867\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.066228, T: 15468, Avg. loss: 0.947903\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.066086, T: 19335, Avg. loss: 0.947923\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065993, T: 23202, Avg. loss: 0.947935\nTotal training time: 0.00 seconds.\nConvergence after 6 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.070583, T: 3867, Avg. loss: 0.952059\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.069155, T: 7734, Avg. loss: 0.951020\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.068710, T: 11601, Avg. loss: 0.950973\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.068494, T: 15468, Avg. loss: 0.950953\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.068366, T: 19335, Avg. loss: 0.950942\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.068282, T: 23202, Avg. loss: 0.950935\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.068222, T: 27069, Avg. loss: 0.950930\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.065962, T: 3867, Avg. loss: 0.950180\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.064292, T: 7734, Avg. loss: 0.948885\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.063756, T: 11601, Avg. loss: 0.948837\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.063493, T: 15468, Avg. loss: 0.948819\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.063336, T: 19335, Avg. loss: 0.948810\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.063233, T: 23202, Avg. loss: 0.948805\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.063159, T: 27069, Avg. loss: 0.948801\nTotal training time: 0.00 seconds.\nConvergence after 7 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.067849, T: 3868, Avg. loss: 0.949250\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066266, T: 7736, Avg. loss: 0.947401\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.065766, T: 11604, Avg. loss: 0.947267\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.065523, T: 15472, Avg. loss: 0.947213\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.065379, T: 19340, Avg. loss: 0.947183\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065283, T: 23208, Avg. loss: 0.947164\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.065216, T: 27076, Avg. loss: 0.947151\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.686357, T: 3867, Avg. loss: 0.938113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.687095, T: 7734, Avg. loss: 0.935787\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.687238, T: 11601, Avg. loss: 0.935483\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.687264, T: 15468, Avg. loss: 0.935366\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.687202, T: 19335, Avg. loss: 0.935303\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.687182, T: 23202, Avg. loss: 0.935273\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.687155, T: 27069, Avg. loss: 0.935245\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.068531, T: 3867, Avg. loss: 0.948325\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066960, T: 7734, Avg. loss: 0.947785\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.066467, T: 11601, Avg. loss: 0.947867\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.066228, T: 15468, Avg. loss: 0.947903\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.066086, T: 19335, Avg. loss: 0.947923\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065993, T: 23202, Avg. loss: 0.947935\nTotal training time: 0.01 seconds.\nConvergence after 6 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.070583, T: 3867, Avg. loss: 0.952059\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.069155, T: 7734, Avg. loss: 0.951020\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.068710, T: 11601, Avg. loss: 0.950973\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.068494, T: 15468, Avg. loss: 0.950953\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.068366, T: 19335, Avg. loss: 0.950942\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.068282, T: 23202, Avg. loss: 0.950935\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.068222, T: 27069, Avg. loss: 0.950930\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.065962, T: 3867, Avg. loss: 0.950180\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.064292, T: 7734, Avg. loss: 0.948885\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.063756, T: 11601, Avg. loss: 0.948837\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.063493, T: 15468, Avg. loss: 0.948819\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.063336, T: 19335, Avg. loss: 0.948810\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.063233, T: 23202, Avg. loss: 0.948805\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.063159, T: 27069, Avg. loss: 0.948801\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.067849, T: 3868, Avg. loss: 0.949250\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066266, T: 7736, Avg. loss: 0.947401\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.065766, T: 11604, Avg. loss: 0.947267\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.065523, T: 15472, Avg. loss: 0.947213\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.065379, T: 19340, Avg. loss: 0.947183\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065283, T: 23208, Avg. loss: 0.947164\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.065216, T: 27076, Avg. loss: 0.947151\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: -0.686357, T: 3867, Avg. loss: 0.938113\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: -0.687095, T: 7734, Avg. loss: 0.935787\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: -0.687238, T: 11601, Avg. loss: 0.935483\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: -0.687264, T: 15468, Avg. loss: 0.935366\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: -0.687202, T: 19335, Avg. loss: 0.935303\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: -0.687182, T: 23202, Avg. loss: 0.935273\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: -0.687155, T: 27069, Avg. loss: 0.935245\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.068531, T: 3867, Avg. loss: 0.948325\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066960, T: 7734, Avg. loss: 0.947785\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.066467, T: 11601, Avg. loss: 0.947867\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.066228, T: 15468, Avg. loss: 0.947903\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.066086, T: 19335, Avg. loss: 0.947923\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065993, T: 23202, Avg. loss: 0.947935\nTotal training time: 0.00 seconds.\nConvergence after 6 epochs took 0.00 seconds\n-- Epoch 1\nNorm: 0.22, NNZs: 15, Bias: 0.070583, T: 3867, Avg. loss: 0.952059\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.22, NNZs: 15, Bias: 0.069155, T: 7734, Avg. loss: 0.951020\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.22, NNZs: 15, Bias: 0.068710, T: 11601, Avg. loss: 0.950973\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.22, NNZs: 15, Bias: 0.068494, T: 15468, Avg. loss: 0.950953\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.22, NNZs: 15, Bias: 0.068366, T: 19335, Avg. loss: 0.950942\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.22, NNZs: 15, Bias: 0.068282, T: 23202, Avg. loss: 0.950935\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.22, NNZs: 15, Bias: 0.068222, T: 27069, Avg. loss: 0.950930\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.065962, T: 3867, Avg. loss: 0.950180\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.064292, T: 7734, Avg. loss: 0.948885\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.063756, T: 11601, Avg. loss: 0.948837\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.063493, T: 15468, Avg. loss: 0.948819\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.063336, T: 19335, Avg. loss: 0.948810\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.063233, T: 23202, Avg. loss: 0.948805\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.063159, T: 27069, Avg. loss: 0.948801\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.23, NNZs: 15, Bias: 0.067849, T: 3868, Avg. loss: 0.949250\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.23, NNZs: 15, Bias: 0.066266, T: 7736, Avg. loss: 0.947401\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.23, NNZs: 15, Bias: 0.065766, T: 11604, Avg. loss: 0.947267\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.23, NNZs: 15, Bias: 0.065523, T: 15472, Avg. loss: 0.947213\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.23, NNZs: 15, Bias: 0.065379, T: 19340, Avg. loss: 0.947183\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.23, NNZs: 15, Bias: 0.065283, T: 23208, Avg. loss: 0.947164\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.23, NNZs: 15, Bias: 0.065216, T: 27076, Avg. loss: 0.947151\nTotal training time: 0.01 seconds.\nConvergence after 7 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 16.48, NNZs: 15, Bias: -8.317042, T: 4834, Avg. loss: 5.496677\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 7.77, NNZs: 15, Bias: -3.785090, T: 9668, Avg. loss: 2.223314\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 8.33, NNZs: 15, Bias: -2.945375, T: 14502, Avg. loss: 1.630919\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 6.43, NNZs: 15, Bias: -3.647621, T: 19336, Avg. loss: 1.396846\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 6.24, NNZs: 15, Bias: -3.142039, T: 24170, Avg. loss: 1.237599\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 5.45, NNZs: 15, Bias: -2.361748, T: 29004, Avg. loss: 1.158754\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 5.08, NNZs: 15, Bias: -2.457931, T: 33838, Avg. loss: 1.076142\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 5.48, NNZs: 15, Bias: -1.410121, T: 38672, Avg. loss: 1.010721\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 5.62, NNZs: 15, Bias: -1.654239, T: 43506, Avg. loss: 0.977784\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 4.51, NNZs: 15, Bias: -2.888477, T: 48340, Avg. loss: 0.952283\nTotal training time: 0.07 seconds.\n-- Epoch 11\nNorm: 4.67, NNZs: 15, Bias: -2.066263, T: 53174, Avg. loss: 0.915564\nTotal training time: 0.07 seconds.\n-- Epoch 12\nNorm: 4.82, NNZs: 15, Bias: -2.327069, T: 58008, Avg. loss: 0.904253\nTotal training time: 0.08 seconds.\n-- Epoch 13\nNorm: 4.57, NNZs: 15, Bias: -1.810709, T: 62842, Avg. loss: 0.892929\nTotal training time: 0.08 seconds.\n-- Epoch 14\nNorm: 4.16, NNZs: 15, Bias: -1.840543, T: 67676, Avg. loss: 0.864060\nTotal training time: 0.08 seconds.\n-- Epoch 15\nNorm: 4.50, NNZs: 15, Bias: -1.484338, T: 72510, Avg. loss: 0.855568\nTotal training time: 0.08 seconds.\n-- Epoch 16\nNorm: 4.58, NNZs: 15, Bias: -1.654458, T: 77344, Avg. loss: 0.843029\nTotal training time: 0.08 seconds.\n-- Epoch 17\nNorm: 3.94, NNZs: 15, Bias: -2.126263, T: 82178, Avg. loss: 0.834411\nTotal training time: 0.08 seconds.\n-- Epoch 18\nNorm: 4.08, NNZs: 15, Bias: -1.758428, T: 87012, Avg. loss: 0.816972\nTotal training time: 0.08 seconds.\n-- Epoch 19\nNorm: 4.11, NNZs: 15, Bias: -1.505374, T: 91846, Avg. loss: 0.822138\nTotal training time: 0.08 seconds.\n-- Epoch 20\nNorm: 4.21, NNZs: 15, Bias: -1.755426, T: 96680, Avg. loss: 0.800411\nTotal training time: 0.08 seconds.\n-- Epoch 21\nNorm: 4.04, NNZs: 15, Bias: -1.486694, T: 101514, Avg. loss: 0.809004\nTotal training time: 0.08 seconds.\n-- Epoch 22\nNorm: 4.20, NNZs: 15, Bias: -1.337672, T: 106348, Avg. loss: 0.796404\nTotal training time: 0.08 seconds.\n-- Epoch 23\nNorm: 3.91, NNZs: 15, Bias: -1.930995, T: 111182, Avg. loss: 0.785684\nTotal training time: 0.08 seconds.\n-- Epoch 24\nNorm: 4.13, NNZs: 15, Bias: -1.802291, T: 116016, Avg. loss: 0.789173\nTotal training time: 0.09 seconds.\n-- Epoch 25\nNorm: 4.08, NNZs: 15, Bias: -1.857084, T: 120850, Avg. loss: 0.782514\nTotal training time: 0.09 seconds.\n-- Epoch 26\nNorm: 4.05, NNZs: 15, Bias: -1.791719, T: 125684, Avg. loss: 0.781822\nTotal training time: 0.09 seconds.\n-- Epoch 27\nNorm: 3.90, NNZs: 15, Bias: -1.625052, T: 130518, Avg. loss: 0.769952\nTotal training time: 0.09 seconds.\n-- Epoch 28\nNorm: 4.13, NNZs: 15, Bias: -1.281300, T: 135352, Avg. loss: 0.768055\nTotal training time: 0.09 seconds.\n-- Epoch 29\nNorm: 4.05, NNZs: 15, Bias: -1.237929, T: 140186, Avg. loss: 0.765366\nTotal training time: 0.09 seconds.\n-- Epoch 30\nNorm: 3.71, NNZs: 15, Bias: -1.837221, T: 145020, Avg. loss: 0.770257\nTotal training time: 0.09 seconds.\n-- Epoch 31\nNorm: 3.87, NNZs: 15, Bias: -1.597005, T: 149854, Avg. loss: 0.763421\nTotal training time: 0.09 seconds.\n-- Epoch 32\nNorm: 3.75, NNZs: 15, Bias: -1.809451, T: 154688, Avg. loss: 0.762691\nTotal training time: 0.09 seconds.\n-- Epoch 33\nNorm: 3.66, NNZs: 15, Bias: -1.707000, T: 159522, Avg. loss: 0.757380\nTotal training time: 0.09 seconds.\n-- Epoch 34\nNorm: 3.89, NNZs: 15, Bias: -1.583989, T: 164356, Avg. loss: 0.755022\nTotal training time: 0.09 seconds.\n-- Epoch 35\nNorm: 3.92, NNZs: 15, Bias: -1.334312, T: 169190, Avg. loss: 0.745812\nTotal training time: 0.09 seconds.\n-- Epoch 36\nNorm: 3.69, NNZs: 15, Bias: -1.392337, T: 174024, Avg. loss: 0.743401\nTotal training time: 0.09 seconds.\n-- Epoch 37\nNorm: 3.87, NNZs: 15, Bias: -1.403805, T: 178858, Avg. loss: 0.743713\nTotal training time: 0.09 seconds.\n-- Epoch 38\nNorm: 3.79, NNZs: 15, Bias: -1.307799, T: 183692, Avg. loss: 0.743782\nTotal training time: 0.10 seconds.\n-- Epoch 39\nNorm: 3.74, NNZs: 15, Bias: -1.419462, T: 188526, Avg. loss: 0.741167\nTotal training time: 0.10 seconds.\n-- Epoch 40\nNorm: 3.70, NNZs: 15, Bias: -1.506393, T: 193360, Avg. loss: 0.743336\nTotal training time: 0.10 seconds.\n-- Epoch 41\nNorm: 3.50, NNZs: 15, Bias: -1.465062, T: 198194, Avg. loss: 0.737274\nTotal training time: 0.10 seconds.\n-- Epoch 42\nNorm: 3.72, NNZs: 15, Bias: -1.152321, T: 203028, Avg. loss: 0.736892\nTotal training time: 0.10 seconds.\n-- Epoch 43\nNorm: 3.73, NNZs: 15, Bias: -1.333254, T: 207862, Avg. loss: 0.734872\nTotal training time: 0.10 seconds.\n-- Epoch 44\nNorm: 3.79, NNZs: 15, Bias: -1.167499, T: 212696, Avg. loss: 0.736135\nTotal training time: 0.10 seconds.\n-- Epoch 45\nNorm: 3.81, NNZs: 15, Bias: -1.295012, T: 217530, Avg. loss: 0.730074\nTotal training time: 0.10 seconds.\n-- Epoch 46\nNorm: 3.71, NNZs: 15, Bias: -1.192086, T: 222364, Avg. loss: 0.731670\nTotal training time: 0.10 seconds.\n-- Epoch 47\nNorm: 3.66, NNZs: 15, Bias: -1.183833, T: 227198, Avg. loss: 0.726848\nTotal training time: 0.10 seconds.\n-- Epoch 48\nNorm: 3.83, NNZs: 15, Bias: -1.196878, T: 232032, Avg. loss: 0.727172\nTotal training time: 0.10 seconds.\n-- Epoch 49\nNorm: 3.76, NNZs: 15, Bias: -1.107290, T: 236866, Avg. loss: 0.723305\nTotal training time: 0.10 seconds.\n-- Epoch 50\nNorm: 3.67, NNZs: 15, Bias: -1.386078, T: 241700, Avg. loss: 0.721445\nTotal training time: 0.10 seconds.\n-- Epoch 51\nNorm: 3.85, NNZs: 15, Bias: -1.139960, T: 246534, Avg. loss: 0.725520\nTotal training time: 0.10 seconds.\n-- Epoch 52\nNorm: 3.74, NNZs: 15, Bias: -1.362511, T: 251368, Avg. loss: 0.720732\nTotal training time: 0.10 seconds.\n-- Epoch 53\nNorm: 3.89, NNZs: 15, Bias: -1.207700, T: 256202, Avg. loss: 0.721879\nTotal training time: 0.10 seconds.\n-- Epoch 54\nNorm: 3.76, NNZs: 15, Bias: -1.334684, T: 261036, Avg. loss: 0.721365\nTotal training time: 0.10 seconds.\n-- Epoch 55\nNorm: 3.73, NNZs: 15, Bias: -1.244148, T: 265870, Avg. loss: 0.715844\nTotal training time: 0.10 seconds.\n-- Epoch 56\nNorm: 3.68, NNZs: 15, Bias: -1.233793, T: 270704, Avg. loss: 0.713126\nTotal training time: 0.11 seconds.\n-- Epoch 57\nNorm: 3.73, NNZs: 15, Bias: -1.351064, T: 275538, Avg. loss: 0.714431\nTotal training time: 0.11 seconds.\n-- Epoch 58\nNorm: 3.83, NNZs: 15, Bias: -1.349963, T: 280372, Avg. loss: 0.715667\nTotal training time: 0.11 seconds.\n-- Epoch 59\nNorm: 3.68, NNZs: 15, Bias: -1.383461, T: 285206, Avg. loss: 0.708160\nTotal training time: 0.11 seconds.\n-- Epoch 60\nNorm: 3.91, NNZs: 15, Bias: -1.338228, T: 290040, Avg. loss: 0.713309\nTotal training time: 0.11 seconds.\n-- Epoch 61\nNorm: 3.66, NNZs: 15, Bias: -1.366006, T: 294874, Avg. loss: 0.709675\nTotal training time: 0.11 seconds.\n-- Epoch 62\nNorm: 3.84, NNZs: 15, Bias: -1.290983, T: 299708, Avg. loss: 0.711337\nTotal training time: 0.11 seconds.\n-- Epoch 63\nNorm: 3.74, NNZs: 15, Bias: -1.272560, T: 304542, Avg. loss: 0.709144\nTotal training time: 0.11 seconds.\n-- Epoch 64\nNorm: 3.84, NNZs: 15, Bias: -1.172862, T: 309376, Avg. loss: 0.710285\nTotal training time: 0.11 seconds.\nConvergence after 64 epochs took 0.11 seconds\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00050-a8e1d628-6041-48d2-b19f-cd87e24f5871",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "32c9439c",
    "allow_embed": false,
    "execution_start": 1622080362774,
    "execution_millis": 7,
    "deepnote_cell_type": "code"
   },
   "source": "# Returns max value of the mean test score \nmax(scores['mean_test_score'])",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 52,
     "data": {
      "text/plain": "0.7041741870976168"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00051-fb51c8a0-61ba-4267-9fae-aad236819c5c",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "46f0d3fb",
    "allow_embed": false,
    "execution_start": 1622080362825,
    "execution_millis": 16,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "source": "# loop that runs all of the possible parameter configurations from the parameter dictionary above\nfor mean_score, params in sorted(list(zip(scores[\"mean_test_score\"], scores[\"params\"])),key = lambda x: x[0]):\n     print(f'Best parameters for SGD Classifier are {params} with a score of {mean_score}')",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Best parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5128253054740173\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5250279942020422\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5325013220971136\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5325094580793515\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.5535698763116594\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5550304992281522\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5769411276043173\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5775616033023524\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5881448033554504\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6642579877146668\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6708699720165032\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6710767972491816\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6719051687038738\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6737685227411409\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.675215228845911\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6754203412402234\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.675628665206472\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6760433861958074\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.676250853742873\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6766623631602725\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6770755854160377\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6779035286611385\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6781092833698382\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6791444800572088\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6791446941620045\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6818332080820279\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6828675483502156\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6828690470837857\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.683075872316464\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6832826975491424\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6834895227818208\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6836963480144992\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6839031732471776\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6863874311920712\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.688870832717782\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6892812716112029\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6911439833340827\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6911446256484699\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6927945172043909\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6927973005667354\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6985892635009132\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.699416350326831\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.7041741870976168\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Best parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} using rfe_list froms RFE\n",
   "metadata": {
    "tags": [],
    "cell_id": "00052-6260c188-07db-413d-b166-cdb4d0a8303e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00062-575c3364-08d8-4a10-971f-a1c39ab86df8",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "40a0c84e",
    "is_output_hidden": true,
    "allow_embed": false,
    "execution_start": 1622080362877,
    "execution_millis": 55985,
    "deepnote_cell_type": "code"
   },
   "source": "# Create a parameter dictionary for the model, {'parameter': [list of settings]}\nparameters = [\n    {\n    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],\n    'shuffle': [True, False],\n    'verbose': [0, 1, 5, 10],\n    'class_weight': [None, 'balanced'],\n    },\n]\n# Created variable model which holds the KNN model\nmodel = SGDClassifier()\n# Create grid_search model, looking at recall\ngrid_search = GridSearchCV(model,\n                           param_grid=parameters,\n                           scoring='accuracy',\n                           )\n# Create variable r that hold the FIT grid_search\nr = grid_search.fit(X_train[combo_feats], y_train)\nscores = r.cv_results_\nlm = r.best_estimator_",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Norm: 0.20, NNZs: 19, Bias: 0.391778, T: 11604, Avg. loss: 0.989658\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.387601, T: 15472, Avg. loss: 0.968038\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.384856, T: 19340, Avg. loss: 0.975484\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.382912, T: 23208, Avg. loss: 0.957200\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 19, Bias: 0.381053, T: 27076, Avg. loss: 0.953837\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.379342, T: 30944, Avg. loss: 0.962160\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.377931, T: 34812, Avg. loss: 0.967468\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.376607, T: 38680, Avg. loss: 0.964044\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.375845, T: 42548, Avg. loss: 0.959804\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.374332, T: 46416, Avg. loss: 0.957378\nTotal training time: 0.01 seconds.\nConvergence after 12 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 19, Bias: 0.593713, T: 3867, Avg. loss: 2.054757\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 19, Bias: 0.579684, T: 7734, Avg. loss: 1.014084\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.572189, T: 11601, Avg. loss: 0.972420\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.567756, T: 15468, Avg. loss: 0.985391\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.564839, T: 19335, Avg. loss: 0.972895\nTotal training time: 0.06 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.562254, T: 23202, Avg. loss: 0.967091\nTotal training time: 0.07 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.560051, T: 27069, Avg. loss: 0.967267\nTotal training time: 0.07 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.558200, T: 30936, Avg. loss: 0.976014\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 19, Bias: 0.556718, T: 34803, Avg. loss: 0.970882\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 19, Bias: 0.555140, T: 38670, Avg. loss: 0.965605\nTotal training time: 0.07 seconds.\n-- Epoch 11\nNorm: 0.20, NNZs: 19, Bias: 0.553756, T: 42537, Avg. loss: 0.978031\nTotal training time: 0.07 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.552319, T: 46404, Avg. loss: 0.969533\nTotal training time: 0.07 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.551713, T: 50271, Avg. loss: 0.972339\nTotal training time: 0.07 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.550625, T: 54138, Avg. loss: 0.971986\nTotal training time: 0.07 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 19, Bias: 0.549553, T: 58005, Avg. loss: 0.965307\nTotal training time: 0.07 seconds.\nConvergence after 15 epochs took 0.07 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 19, Bias: 0.737449, T: 3867, Avg. loss: 1.853211\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 19, Bias: 0.722024, T: 7734, Avg. loss: 0.993120\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.715175, T: 11601, Avg. loss: 0.977575\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.710277, T: 15468, Avg. loss: 0.975095\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.707373, T: 19335, Avg. loss: 0.973368\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.704626, T: 23202, Avg. loss: 0.976373\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.702635, T: 27069, Avg. loss: 0.974544\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.700930, T: 30936, Avg. loss: 0.979751\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.699368, T: 34803, Avg. loss: 0.968487\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.697698, T: 38670, Avg. loss: 0.957792\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.696549, T: 42537, Avg. loss: 0.961769\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.695123, T: 46404, Avg. loss: 0.967879\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.694140, T: 50271, Avg. loss: 0.969303\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.693196, T: 54138, Avg. loss: 0.969656\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 19, Bias: 0.692795, T: 58005, Avg. loss: 0.967320\nTotal training time: 0.02 seconds.\nConvergence after 15 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.16, NNZs: 19, Bias: -0.785323, T: 3867, Avg. loss: 2.336819\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 19, Bias: -0.783596, T: 7734, Avg. loss: 0.988406\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: -0.784424, T: 11601, Avg. loss: 0.969435\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 19, Bias: -0.784620, T: 15468, Avg. loss: 0.956225\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.18, NNZs: 19, Bias: -0.785639, T: 19335, Avg. loss: 0.945777\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 19, Bias: -0.786291, T: 23202, Avg. loss: 0.949639\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 19, Bias: -0.787393, T: 27069, Avg. loss: 0.954262\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: -0.787963, T: 30936, Avg. loss: 0.953750\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 19, Bias: -0.789056, T: 34803, Avg. loss: 0.956174\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 19, Bias: -0.789934, T: 38670, Avg. loss: 0.952599\nTotal training time: 0.01 seconds.\nConvergence after 10 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: -0.838455, T: 3867, Avg. loss: 1.505169\nTotal training time: 0.06 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 19, Bias: -0.833005, T: 7734, Avg. loss: 0.979815\nTotal training time: 0.06 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: -0.832019, T: 11601, Avg. loss: 0.968586\nTotal training time: 0.07 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: -0.832348, T: 15468, Avg. loss: 0.967998\nTotal training time: 0.07 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 19, Bias: -0.832236, T: 19335, Avg. loss: 0.957537\nTotal training time: 0.07 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 19, Bias: -0.832772, T: 23202, Avg. loss: 0.957598\nTotal training time: 0.07 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 19, Bias: -0.833061, T: 27069, Avg. loss: 0.938616\nTotal training time: 0.07 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: -0.832581, T: 30936, Avg. loss: 0.949567\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 19, Bias: -0.833446, T: 34803, Avg. loss: 0.958475\nTotal training time: 0.07 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 19, Bias: -0.833289, T: 38670, Avg. loss: 0.942098\nTotal training time: 0.07 seconds.\n-- Epoch 11\nNorm: 0.20, NNZs: 19, Bias: -0.833726, T: 42537, Avg. loss: 0.945789\nTotal training time: 0.08 seconds.\n-- Epoch 12\nNorm: 0.20, NNZs: 19, Bias: -0.834192, T: 46404, Avg. loss: 0.950489\nTotal training time: 0.08 seconds.\nConvergence after 12 epochs took 0.08 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: -0.470552, T: 3868, Avg. loss: 1.771790\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: -0.471986, T: 7736, Avg. loss: 0.992992\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: -0.473981, T: 11604, Avg. loss: 0.966420\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: -0.476446, T: 15472, Avg. loss: 0.964554\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: -0.479304, T: 19340, Avg. loss: 0.956063\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: -0.480690, T: 23208, Avg. loss: 0.948417\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: -0.481894, T: 27076, Avg. loss: 0.960348\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: -0.483428, T: 30944, Avg. loss: 0.955691\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: -0.484383, T: 34812, Avg. loss: 0.945757\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: -0.485575, T: 38680, Avg. loss: 0.949441\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: -0.486276, T: 42548, Avg. loss: 0.950577\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: -0.487116, T: 46416, Avg. loss: 0.954372\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: -0.488100, T: 50284, Avg. loss: 0.949426\nTotal training time: 0.07 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: -0.488403, T: 54152, Avg. loss: 0.930901\nTotal training time: 0.08 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 19, Bias: -0.489209, T: 58020, Avg. loss: 0.949846\nTotal training time: 0.08 seconds.\n-- Epoch 16\nNorm: 0.21, NNZs: 19, Bias: -0.489848, T: 61888, Avg. loss: 0.950569\nTotal training time: 0.08 seconds.\n-- Epoch 17\nNorm: 0.22, NNZs: 19, Bias: -0.490341, T: 65756, Avg. loss: 0.946533\nTotal training time: 0.08 seconds.\n-- Epoch 18\nNorm: 0.22, NNZs: 19, Bias: -0.490947, T: 69624, Avg. loss: 0.950153\nTotal training time: 0.08 seconds.\n-- Epoch 19\nNorm: 0.22, NNZs: 19, Bias: -0.491428, T: 73492, Avg. loss: 0.944491\nTotal training time: 0.08 seconds.\nConvergence after 19 epochs took 0.08 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 19, Bias: -0.929420, T: 3867, Avg. loss: 1.312011\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 19, Bias: -0.923305, T: 7734, Avg. loss: 0.967797\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: -0.921427, T: 11601, Avg. loss: 0.955692\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 19, Bias: -0.921042, T: 15468, Avg. loss: 0.952594\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.18, NNZs: 19, Bias: -0.921007, T: 19335, Avg. loss: 0.953460\nTotal training time: 0.06 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 19, Bias: -0.921053, T: 23202, Avg. loss: 0.954061\nTotal training time: 0.06 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 19, Bias: -0.921025, T: 27069, Avg. loss: 0.953204\nTotal training time: 0.06 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 19, Bias: -0.920955, T: 30936, Avg. loss: 0.952590\nTotal training time: 0.07 seconds.\n-- Epoch 9\nNorm: 0.19, NNZs: 19, Bias: -0.921011, T: 34803, Avg. loss: 0.952345\nTotal training time: 0.07 seconds.\nConvergence after 9 epochs took 0.07 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.804888, T: 3867, Avg. loss: 1.915816\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.788311, T: 7734, Avg. loss: 0.988405\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.780179, T: 11601, Avg. loss: 0.982532\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.774774, T: 15468, Avg. loss: 0.981114\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.771009, T: 19335, Avg. loss: 0.980726\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.768239, T: 23202, Avg. loss: 0.978934\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.766036, T: 27069, Avg. loss: 0.977364\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.764201, T: 30936, Avg. loss: 0.976386\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.762558, T: 34803, Avg. loss: 0.976559\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.761119, T: 38670, Avg. loss: 0.975555\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.759872, T: 42537, Avg. loss: 0.974593\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.758757, T: 46404, Avg. loss: 0.974110\nTotal training time: 0.01 seconds.\nConvergence after 12 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.804948, T: 3867, Avg. loss: 1.905376\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.788647, T: 7734, Avg. loss: 0.987544\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: 0.780365, T: 11601, Avg. loss: 0.983438\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: 0.774928, T: 15468, Avg. loss: 0.981551\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 19, Bias: 0.771325, T: 19335, Avg. loss: 0.981162\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.768596, T: 23202, Avg. loss: 0.979518\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.766351, T: 27069, Avg. loss: 0.980044\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.764553, T: 30936, Avg. loss: 0.980017\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 19, Bias: 0.762968, T: 34803, Avg. loss: 0.978461\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 19, Bias: 0.761584, T: 38670, Avg. loss: 0.979040\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.20, NNZs: 19, Bias: 0.760361, T: 42537, Avg. loss: 0.977992\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.759315, T: 46404, Avg. loss: 0.977565\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.758313, T: 50271, Avg. loss: 0.977205\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.757405, T: 54138, Avg. loss: 0.976294\nTotal training time: 0.02 seconds.\nConvergence after 14 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.803151, T: 3867, Avg. loss: 1.919080\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.789004, T: 7734, Avg. loss: 0.988320\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.782054, T: 11601, Avg. loss: 0.981400\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: 0.777724, T: 15468, Avg. loss: 0.980606\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.774744, T: 19335, Avg. loss: 0.979471\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.772429, T: 23202, Avg. loss: 0.978448\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.770656, T: 27069, Avg. loss: 0.978853\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.769195, T: 30936, Avg. loss: 0.977600\nTotal training time: 0.00 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.767944, T: 34803, Avg. loss: 0.976789\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.766803, T: 38670, Avg. loss: 0.976676\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.765825, T: 42537, Avg. loss: 0.975678\nTotal training time: 0.01 seconds.\nConvergence after 11 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 19, Bias: 0.807252, T: 3868, Avg. loss: 1.923714\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 19, Bias: 0.791740, T: 7736, Avg. loss: 0.989737\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 19, Bias: 0.784062, T: 11604, Avg. loss: 0.984799\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.779059, T: 15472, Avg. loss: 0.982862\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.775644, T: 19340, Avg. loss: 0.981845\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.772949, T: 23208, Avg. loss: 0.979709\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 19, Bias: 0.770755, T: 27076, Avg. loss: 0.979243\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.768886, T: 30944, Avg. loss: 0.977597\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.767239, T: 34812, Avg. loss: 0.976240\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.765737, T: 38680, Avg. loss: 0.975194\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.764427, T: 42548, Avg. loss: 0.974347\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.763256, T: 46416, Avg. loss: 0.974185\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.762180, T: 50284, Avg. loss: 0.973574\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.761202, T: 54152, Avg. loss: 0.972825\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 19, Bias: 0.760310, T: 58020, Avg. loss: 0.972213\nTotal training time: 0.02 seconds.\nConvergence after 15 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 19, Bias: -0.929420, T: 3867, Avg. loss: 1.312011\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 19, Bias: -0.923305, T: 7734, Avg. loss: 0.967797\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: -0.921427, T: 11601, Avg. loss: 0.955692\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 19, Bias: -0.921042, T: 15468, Avg. loss: 0.952594\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.18, NNZs: 19, Bias: -0.921007, T: 19335, Avg. loss: 0.953460\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 19, Bias: -0.921053, T: 23202, Avg. loss: 0.954061\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 19, Bias: -0.921025, T: 27069, Avg. loss: 0.953204\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 19, Bias: -0.920955, T: 30936, Avg. loss: 0.952590\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.19, NNZs: 19, Bias: -0.921011, T: 34803, Avg. loss: 0.952345\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.804888, T: 3867, Avg. loss: 1.915816\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.788311, T: 7734, Avg. loss: 0.988405\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.780179, T: 11601, Avg. loss: 0.982532\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.774774, T: 15468, Avg. loss: 0.981114\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.771009, T: 19335, Avg. loss: 0.980726\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.768239, T: 23202, Avg. loss: 0.978934\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.766036, T: 27069, Avg. loss: 0.977364\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.764201, T: 30936, Avg. loss: 0.976386\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.762558, T: 34803, Avg. loss: 0.976559\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.761119, T: 38670, Avg. loss: 0.975555\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.759872, T: 42537, Avg. loss: 0.974593\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.758757, T: 46404, Avg. loss: 0.974110\nTotal training time: 0.01 seconds.\nConvergence after 12 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.804948, T: 3867, Avg. loss: 1.905376\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.788647, T: 7734, Avg. loss: 0.987544\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: 0.780365, T: 11601, Avg. loss: 0.983438\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: 0.774928, T: 15468, Avg. loss: 0.981551\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 19, Bias: 0.771325, T: 19335, Avg. loss: 0.981162\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.768596, T: 23202, Avg. loss: 0.979518\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.766351, T: 27069, Avg. loss: 0.980044\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.764553, T: 30936, Avg. loss: 0.980017\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 19, Bias: 0.762968, T: 34803, Avg. loss: 0.978461\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 19, Bias: 0.761584, T: 38670, Avg. loss: 0.979040\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.20, NNZs: 19, Bias: 0.760361, T: 42537, Avg. loss: 0.977992\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.759315, T: 46404, Avg. loss: 0.977565\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.758313, T: 50271, Avg. loss: 0.977205\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.757405, T: 54138, Avg. loss: 0.976294\nTotal training time: 0.02 seconds.\nConvergence after 14 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.803151, T: 3867, Avg. loss: 1.919080\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.789004, T: 7734, Avg. loss: 0.988320\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.782054, T: 11601, Avg. loss: 0.981400\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: 0.777724, T: 15468, Avg. loss: 0.980606\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.774744, T: 19335, Avg. loss: 0.979471\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.772429, T: 23202, Avg. loss: 0.978448\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.770656, T: 27069, Avg. loss: 0.978853\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.769195, T: 30936, Avg. loss: 0.977600\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.767944, T: 34803, Avg. loss: 0.976789\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.766803, T: 38670, Avg. loss: 0.976676\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.765825, T: 42537, Avg. loss: 0.975678\nTotal training time: 0.01 seconds.\nConvergence after 11 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 19, Bias: 0.807252, T: 3868, Avg. loss: 1.923714\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 19, Bias: 0.791740, T: 7736, Avg. loss: 0.989737\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 19, Bias: 0.784062, T: 11604, Avg. loss: 0.984799\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.779059, T: 15472, Avg. loss: 0.982862\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.775644, T: 19340, Avg. loss: 0.981845\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.772949, T: 23208, Avg. loss: 0.979709\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 19, Bias: 0.770755, T: 27076, Avg. loss: 0.979243\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.768886, T: 30944, Avg. loss: 0.977597\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.767239, T: 34812, Avg. loss: 0.976240\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.765737, T: 38680, Avg. loss: 0.975194\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.764427, T: 42548, Avg. loss: 0.974347\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.763256, T: 46416, Avg. loss: 0.974185\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.762180, T: 50284, Avg. loss: 0.973574\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.761202, T: 54152, Avg. loss: 0.972825\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 19, Bias: 0.760310, T: 58020, Avg. loss: 0.972213\nTotal training time: 0.01 seconds.\nConvergence after 15 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.15, NNZs: 19, Bias: -0.929420, T: 3867, Avg. loss: 1.312011\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.17, NNZs: 19, Bias: -0.923305, T: 7734, Avg. loss: 0.967797\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: -0.921427, T: 11601, Avg. loss: 0.955692\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.18, NNZs: 19, Bias: -0.921042, T: 15468, Avg. loss: 0.952594\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.18, NNZs: 19, Bias: -0.921007, T: 19335, Avg. loss: 0.953460\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.19, NNZs: 19, Bias: -0.921053, T: 23202, Avg. loss: 0.954061\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.19, NNZs: 19, Bias: -0.921025, T: 27069, Avg. loss: 0.953204\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.19, NNZs: 19, Bias: -0.920955, T: 30936, Avg. loss: 0.952590\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.19, NNZs: 19, Bias: -0.921011, T: 34803, Avg. loss: 0.952345\nTotal training time: 0.01 seconds.\nConvergence after 9 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.804888, T: 3867, Avg. loss: 1.915816\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.788311, T: 7734, Avg. loss: 0.988405\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.780179, T: 11601, Avg. loss: 0.982532\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.774774, T: 15468, Avg. loss: 0.981114\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.771009, T: 19335, Avg. loss: 0.980726\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.768239, T: 23202, Avg. loss: 0.978934\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.766036, T: 27069, Avg. loss: 0.977364\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.764201, T: 30936, Avg. loss: 0.976386\nTotal training time: 0.00 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.762558, T: 34803, Avg. loss: 0.976559\nTotal training time: 0.00 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.761119, T: 38670, Avg. loss: 0.975555\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.759872, T: 42537, Avg. loss: 0.974593\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.758757, T: 46404, Avg. loss: 0.974110\nTotal training time: 0.01 seconds.\nConvergence after 12 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.804948, T: 3867, Avg. loss: 1.905376\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.788647, T: 7734, Avg. loss: 0.987544\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.18, NNZs: 19, Bias: 0.780365, T: 11601, Avg. loss: 0.983438\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: 0.774928, T: 15468, Avg. loss: 0.981551\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.19, NNZs: 19, Bias: 0.771325, T: 19335, Avg. loss: 0.981162\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.768596, T: 23202, Avg. loss: 0.979518\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.766351, T: 27069, Avg. loss: 0.980044\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.764553, T: 30936, Avg. loss: 0.980017\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.20, NNZs: 19, Bias: 0.762968, T: 34803, Avg. loss: 0.978461\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.20, NNZs: 19, Bias: 0.761584, T: 38670, Avg. loss: 0.979040\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.20, NNZs: 19, Bias: 0.760361, T: 42537, Avg. loss: 0.977992\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.759315, T: 46404, Avg. loss: 0.977565\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.758313, T: 50271, Avg. loss: 0.977205\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.757405, T: 54138, Avg. loss: 0.976294\nTotal training time: 0.02 seconds.\nConvergence after 14 epochs took 0.02 seconds\n-- Epoch 1\nNorm: 0.17, NNZs: 19, Bias: 0.803151, T: 3867, Avg. loss: 1.919080\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.18, NNZs: 19, Bias: 0.789004, T: 7734, Avg. loss: 0.988320\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.19, NNZs: 19, Bias: 0.782054, T: 11601, Avg. loss: 0.981400\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.19, NNZs: 19, Bias: 0.777724, T: 15468, Avg. loss: 0.980606\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.774744, T: 19335, Avg. loss: 0.979471\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.772429, T: 23202, Avg. loss: 0.978448\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.20, NNZs: 19, Bias: 0.770656, T: 27069, Avg. loss: 0.978853\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.20, NNZs: 19, Bias: 0.769195, T: 30936, Avg. loss: 0.977600\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.767944, T: 34803, Avg. loss: 0.976789\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.766803, T: 38670, Avg. loss: 0.976676\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.765825, T: 42537, Avg. loss: 0.975678\nTotal training time: 0.01 seconds.\nConvergence after 11 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 0.18, NNZs: 19, Bias: 0.807252, T: 3868, Avg. loss: 1.923714\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 0.19, NNZs: 19, Bias: 0.791740, T: 7736, Avg. loss: 0.989737\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 0.20, NNZs: 19, Bias: 0.784062, T: 11604, Avg. loss: 0.984799\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 0.20, NNZs: 19, Bias: 0.779059, T: 15472, Avg. loss: 0.982862\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 0.20, NNZs: 19, Bias: 0.775644, T: 19340, Avg. loss: 0.981845\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 0.20, NNZs: 19, Bias: 0.772949, T: 23208, Avg. loss: 0.979709\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 0.21, NNZs: 19, Bias: 0.770755, T: 27076, Avg. loss: 0.979243\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 0.21, NNZs: 19, Bias: 0.768886, T: 30944, Avg. loss: 0.977597\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 0.21, NNZs: 19, Bias: 0.767239, T: 34812, Avg. loss: 0.976240\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 0.21, NNZs: 19, Bias: 0.765737, T: 38680, Avg. loss: 0.975194\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 0.21, NNZs: 19, Bias: 0.764427, T: 42548, Avg. loss: 0.974347\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 0.21, NNZs: 19, Bias: 0.763256, T: 46416, Avg. loss: 0.974185\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 0.21, NNZs: 19, Bias: 0.762180, T: 50284, Avg. loss: 0.973574\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 0.21, NNZs: 19, Bias: 0.761202, T: 54152, Avg. loss: 0.972825\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 0.21, NNZs: 19, Bias: 0.760310, T: 58020, Avg. loss: 0.972213\nTotal training time: 0.01 seconds.\nConvergence after 15 epochs took 0.01 seconds\n-- Epoch 1\nNorm: 8.01, NNZs: 19, Bias: -0.919236, T: 4834, Avg. loss: 35.776144\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 6.37, NNZs: 19, Bias: -0.736666, T: 9668, Avg. loss: 5.271701\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 5.44, NNZs: 19, Bias: -0.668426, T: 14502, Avg. loss: 3.205339\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 4.90, NNZs: 19, Bias: -0.747657, T: 19336, Avg. loss: 2.449979\nTotal training time: 0.01 seconds.\n-- Epoch 5\nNorm: 4.38, NNZs: 19, Bias: -0.629652, T: 24170, Avg. loss: 2.035521\nTotal training time: 0.01 seconds.\n-- Epoch 6\nNorm: 4.03, NNZs: 19, Bias: -0.719994, T: 29004, Avg. loss: 1.802549\nTotal training time: 0.01 seconds.\n-- Epoch 7\nNorm: 3.76, NNZs: 19, Bias: -0.616038, T: 33838, Avg. loss: 1.652440\nTotal training time: 0.01 seconds.\n-- Epoch 8\nNorm: 3.57, NNZs: 19, Bias: -0.606599, T: 38672, Avg. loss: 1.473650\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 3.42, NNZs: 19, Bias: -0.601361, T: 43506, Avg. loss: 1.403720\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 3.28, NNZs: 19, Bias: -0.590367, T: 48340, Avg. loss: 1.339027\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 3.15, NNZs: 19, Bias: -0.563824, T: 53174, Avg. loss: 1.250119\nTotal training time: 0.02 seconds.\n-- Epoch 12\nNorm: 3.00, NNZs: 19, Bias: -0.576208, T: 58008, Avg. loss: 1.206968\nTotal training time: 0.02 seconds.\n-- Epoch 13\nNorm: 2.96, NNZs: 19, Bias: -0.559440, T: 62842, Avg. loss: 1.165696\nTotal training time: 0.02 seconds.\n-- Epoch 14\nNorm: 2.88, NNZs: 19, Bias: -0.515101, T: 67676, Avg. loss: 1.118374\nTotal training time: 0.02 seconds.\n-- Epoch 15\nNorm: 2.79, NNZs: 19, Bias: -0.540662, T: 72510, Avg. loss: 1.096303\nTotal training time: 0.02 seconds.\n-- Epoch 16\nNorm: 2.75, NNZs: 19, Bias: -0.505092, T: 77344, Avg. loss: 1.066580\nTotal training time: 0.02 seconds.\n-- Epoch 17\nNorm: 2.71, NNZs: 19, Bias: -0.500105, T: 82178, Avg. loss: 1.059752\nTotal training time: 0.02 seconds.\n-- Epoch 18\nNorm: 2.70, NNZs: 19, Bias: -0.502072, T: 87012, Avg. loss: 1.030561\nTotal training time: 0.02 seconds.\n-- Epoch 19\nNorm: 2.66, NNZs: 19, Bias: -0.492900, T: 91846, Avg. loss: 1.010994\nTotal training time: 0.02 seconds.\n-- Epoch 20\nNorm: 2.61, NNZs: 19, Bias: -0.475104, T: 96680, Avg. loss: 0.994655\nTotal training time: 0.02 seconds.\n-- Epoch 21\nNorm: 2.58, NNZs: 19, Bias: -0.472252, T: 101514, Avg. loss: 0.969271\nTotal training time: 0.02 seconds.\n-- Epoch 22\nNorm: 2.54, NNZs: 19, Bias: -0.474081, T: 106348, Avg. loss: 0.971167\nTotal training time: 0.02 seconds.\n-- Epoch 23\nNorm: 2.52, NNZs: 19, Bias: -0.462062, T: 111182, Avg. loss: 0.950741\nTotal training time: 0.08 seconds.\n-- Epoch 24\nNorm: 2.49, NNZs: 19, Bias: -0.464233, T: 116016, Avg. loss: 0.953989\nTotal training time: 0.09 seconds.\n-- Epoch 25\nNorm: 2.46, NNZs: 19, Bias: -0.456962, T: 120850, Avg. loss: 0.921304\nTotal training time: 0.09 seconds.\n-- Epoch 26\nNorm: 2.46, NNZs: 19, Bias: -0.455935, T: 125684, Avg. loss: 0.922268\nTotal training time: 0.09 seconds.\n-- Epoch 27\nNorm: 2.44, NNZs: 19, Bias: -0.435313, T: 130518, Avg. loss: 0.914264\nTotal training time: 0.09 seconds.\n-- Epoch 28\nNorm: 2.42, NNZs: 19, Bias: -0.445456, T: 135352, Avg. loss: 0.901576\nTotal training time: 0.09 seconds.\n-- Epoch 29\nNorm: 2.41, NNZs: 19, Bias: -0.444038, T: 140186, Avg. loss: 0.894479\nTotal training time: 0.09 seconds.\n-- Epoch 30\nNorm: 2.40, NNZs: 19, Bias: -0.432465, T: 145020, Avg. loss: 0.894918\nTotal training time: 0.09 seconds.\n-- Epoch 31\nNorm: 2.38, NNZs: 19, Bias: -0.429516, T: 149854, Avg. loss: 0.879469\nTotal training time: 0.09 seconds.\n-- Epoch 32\nNorm: 2.36, NNZs: 19, Bias: -0.416496, T: 154688, Avg. loss: 0.875309\nTotal training time: 0.10 seconds.\n-- Epoch 33\nNorm: 2.36, NNZs: 19, Bias: -0.402501, T: 159522, Avg. loss: 0.868168\nTotal training time: 0.10 seconds.\n-- Epoch 34\nNorm: 2.35, NNZs: 19, Bias: -0.395728, T: 164356, Avg. loss: 0.871130\nTotal training time: 0.10 seconds.\n-- Epoch 35\nNorm: 2.33, NNZs: 19, Bias: -0.385372, T: 169190, Avg. loss: 0.856722\nTotal training time: 0.10 seconds.\n-- Epoch 36\nNorm: 2.31, NNZs: 19, Bias: -0.387386, T: 174024, Avg. loss: 0.863063\nTotal training time: 0.10 seconds.\n-- Epoch 37\nNorm: 2.31, NNZs: 19, Bias: -0.385274, T: 178858, Avg. loss: 0.849733\nTotal training time: 0.10 seconds.\n-- Epoch 38\nNorm: 2.29, NNZs: 19, Bias: -0.376518, T: 183692, Avg. loss: 0.846778\nTotal training time: 0.10 seconds.\n-- Epoch 39\nNorm: 2.28, NNZs: 19, Bias: -0.376342, T: 188526, Avg. loss: 0.850381\nTotal training time: 0.10 seconds.\n-- Epoch 40\nNorm: 2.27, NNZs: 19, Bias: -0.375540, T: 193360, Avg. loss: 0.841316\nTotal training time: 0.10 seconds.\n-- Epoch 41\nNorm: 2.27, NNZs: 19, Bias: -0.367793, T: 198194, Avg. loss: 0.844210\nTotal training time: 0.10 seconds.\n-- Epoch 42\nNorm: 2.26, NNZs: 19, Bias: -0.363006, T: 203028, Avg. loss: 0.825978\nTotal training time: 0.10 seconds.\n-- Epoch 43\nNorm: 2.26, NNZs: 19, Bias: -0.356575, T: 207862, Avg. loss: 0.835346\nTotal training time: 0.10 seconds.\n-- Epoch 44\nNorm: 2.25, NNZs: 19, Bias: -0.355285, T: 212696, Avg. loss: 0.826438\nTotal training time: 0.10 seconds.\n-- Epoch 45\nNorm: 2.25, NNZs: 19, Bias: -0.352281, T: 217530, Avg. loss: 0.823362\nTotal training time: 0.10 seconds.\n-- Epoch 46\nNorm: 2.24, NNZs: 19, Bias: -0.343815, T: 222364, Avg. loss: 0.822189\nTotal training time: 0.10 seconds.\n-- Epoch 47\nNorm: 2.23, NNZs: 19, Bias: -0.340862, T: 227198, Avg. loss: 0.816651\nTotal training time: 0.10 seconds.\n-- Epoch 48\nNorm: 2.23, NNZs: 19, Bias: -0.339964, T: 232032, Avg. loss: 0.816117\nTotal training time: 0.10 seconds.\n-- Epoch 49\nNorm: 2.22, NNZs: 19, Bias: -0.338319, T: 236866, Avg. loss: 0.805042\nTotal training time: 0.10 seconds.\n-- Epoch 50\nNorm: 2.22, NNZs: 19, Bias: -0.331931, T: 241700, Avg. loss: 0.808064\nTotal training time: 0.11 seconds.\n-- Epoch 51\nNorm: 2.22, NNZs: 19, Bias: -0.326459, T: 246534, Avg. loss: 0.803896\nTotal training time: 0.11 seconds.\n-- Epoch 52\nNorm: 2.21, NNZs: 19, Bias: -0.326617, T: 251368, Avg. loss: 0.804277\nTotal training time: 0.11 seconds.\n-- Epoch 53\nNorm: 2.20, NNZs: 19, Bias: -0.319455, T: 256202, Avg. loss: 0.794552\nTotal training time: 0.11 seconds.\n-- Epoch 54\nNorm: 2.20, NNZs: 19, Bias: -0.318131, T: 261036, Avg. loss: 0.804563\nTotal training time: 0.11 seconds.\n-- Epoch 55\nNorm: 2.20, NNZs: 19, Bias: -0.314938, T: 265870, Avg. loss: 0.800389\nTotal training time: 0.11 seconds.\n-- Epoch 56\nNorm: 2.20, NNZs: 19, Bias: -0.312244, T: 270704, Avg. loss: 0.799095\nTotal training time: 0.11 seconds.\n-- Epoch 57\nNorm: 2.19, NNZs: 19, Bias: -0.311744, T: 275538, Avg. loss: 0.786804\nTotal training time: 0.11 seconds.\n-- Epoch 58\nNorm: 2.19, NNZs: 19, Bias: -0.310370, T: 280372, Avg. loss: 0.788858\nTotal training time: 0.11 seconds.\n-- Epoch 59\nNorm: 2.18, NNZs: 19, Bias: -0.309019, T: 285206, Avg. loss: 0.789256\nTotal training time: 0.11 seconds.\n-- Epoch 60\nNorm: 2.18, NNZs: 19, Bias: -0.311384, T: 290040, Avg. loss: 0.791667\nTotal training time: 0.11 seconds.\n-- Epoch 61\nNorm: 2.18, NNZs: 19, Bias: -0.305757, T: 294874, Avg. loss: 0.786576\nTotal training time: 0.11 seconds.\n-- Epoch 62\nNorm: 2.18, NNZs: 19, Bias: -0.298593, T: 299708, Avg. loss: 0.786676\nTotal training time: 0.11 seconds.\nConvergence after 62 epochs took 0.11 seconds\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00063-14c42876-8d61-4420-b9b7-09bf1e247d9c",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "32c9439c",
    "allow_embed": false,
    "execution_start": 1622080418863,
    "execution_millis": 9,
    "deepnote_cell_type": "code"
   },
   "source": "# Returns max value of the mean test score \nmax(scores['mean_test_score'])",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 55,
     "data": {
      "text/plain": "0.6998329982593281"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00064-ca01cd0e-8596-4f70-af95-dc73b4f98a07",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "46f0d3fb",
    "allow_embed": false,
    "is_output_hidden": false,
    "execution_start": 1622080418867,
    "execution_millis": 11,
    "deepnote_cell_type": "code"
   },
   "source": "# loop that runs all of the possible parameter configurations from the parameter dictionary above\nfor mean_score, params in sorted(list(zip(scores[\"mean_test_score\"], scores[\"params\"])),key = lambda x: x[0]):\n     print(f'Best parameters for SGD Classifier are {params} with a score of {mean_score}')",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "Best parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.5028934122095401\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.5028934122095401\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.5028934122095401\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.5028934122095401\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5134414990761378\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5134414990761378\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5134414990761378\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5134414990761378\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.5146871607777144\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.5146871607777144\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.5146871607777144\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.5146871607777144\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5157165766356001\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.5208917036532702\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.5208917036532702\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.5208917036532702\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.5208917036532702\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5281278034346693\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.5304197952729943\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5343351296725695\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.5370322077844222\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.5390921100241723\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5471698557575991\nBest parameters for SGD Classifier are {'alpha': 1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5521178175869961\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.5659798184819541\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.5668111874037867\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.5788406653520631\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.5887556443376775\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.5891440304371378\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6005224157015892\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6005224157015892\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6005224157015892\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6005224157015892\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6100385174527524\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6125394755717133\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6183093857119305\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6183093857119305\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6183093857119305\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6183093857119305\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.6189463474792372\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6210002547847069\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6237187433761328\nBest parameters for SGD Classifier are {'alpha': 0.0001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6241223309160903\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6249421381789532\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.627234344122074\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6332046563510976\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6371473961645268\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6408503386067345\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6408503386067345\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6408503386067345\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6408503386067345\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6479177238090956\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6487469516829707\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6513982113685365\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6513982113685365\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6513982113685365\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6513982113685365\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6563954173009521\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': None, 'shuffle': True, 'verbose': 1} with a score of 0.6572261439083974\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.6594980098959237\nBest parameters for SGD Classifier are {'alpha': 0.001, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.659708903119721\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6603131068532804\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 0} with a score of 0.6621820276152366\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6690121847039252\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6692213650893566\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 0} with a score of 0.6716944895848722\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 1} with a score of 0.6716944895848722\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 5} with a score of 0.6716944895848722\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': False, 'verbose': 10} with a score of 0.6716944895848722\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 10} with a score of 0.6720950796576892\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.676668358094553\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 0} with a score of 0.6776971316380516\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 1} with a score of 0.6776971316380516\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 5} with a score of 0.6776971316380516\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': False, 'verbose': 10} with a score of 0.6776971316380516\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 5} with a score of 0.6826665039470219\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': None, 'shuffle': True, 'verbose': 10} with a score of 0.687213019284419\nBest parameters for SGD Classifier are {'alpha': 0.1, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 0} with a score of 0.6923830077869915\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 1} with a score of 0.693421416046298\nBest parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': 'balanced', 'shuffle': True, 'verbose': 5} with a score of 0.6998329982593281\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Best parameters for SGD Classifier are {'alpha': 0.01, 'class_weight': None, 'shuffle': True, 'verbose': 0} using combo_feats\n",
   "metadata": {
    "tags": [],
    "cell_id": "00065-850cbacd-cffb-489c-896c-5844996d9cf7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00056-645ac43a-0c8d-47b9-9421-f62d19b649ad",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "2e1db916",
    "execution_start": 1622080418885,
    "execution_millis": 261,
    "is_output_hidden": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Build 3 models using Select K Best features, RFE feature, and a combination of the of the features minimizing multicolinearity\nsgd_skb = SGDClassifier(alpha=0.01, shuffle=True, verbose=5, class_weight=None)\nsgd_rfe = SGDClassifier(alpha=0.0001, class_weight='balanced', shuffle=True, verbose=1)\nsgd_cf = SGDClassifier(alpha=0.01, class_weight=None, shuffle=True, verbose=0)\n\n# fitting the SGD Classifiers with the X_train with the corresponding features\nsgd_skb.fit(X_train[f_feature], y_train)\nsgd_rfe.fit(X_train[rfe_list], y_train)\nsgd_cf.fit(X_train[combo_feats], y_train)\n\n# Model SKB predictions\ny_pred_sgd_skb = sgd_skb.predict(X_train[f_feature])\ny_pred_val_sgd_skb = sgd_skb.predict(X_validate[f_feature])\n\n# Model RFE predictions\ny_pred_sgd_rfe = sgd_rfe.predict(X_train[rfe_list])\ny_pred_val_sgd_rfe = sgd_rfe.predict(X_validate[rfe_list])\n\n# Model Combo Features\ny_pred_sgd_cf = sgd_cf.predict(X_train[combo_feats])\ny_pred_val_sgd_cf = sgd_cf.predict(X_validate[combo_feats])\n\n# Measure accuracy of the select k best feature model\naccuracy_train_sgd_skb = sgd_skb.score(X_train[f_feature], y_train)\naccuracy_val_sgd_skb = sgd_skb.score(X_validate[f_feature], y_validate)\n\n# Measure accuracy of the RFE feature model\naccuracy_train_sgd_rfe = sgd_rfe.score(X_train[rfe_list], y_train)\naccuracy_val_sgd_rfe = sgd_rfe.score(X_validate[rfe_list], y_validate)\n\n# Measure accuracy of the CF feature model\naccuracy_train_sgd_cf = sgd_cf.score(X_train[combo_feats], y_train)\naccuracy_val_sgd_cf = sgd_cf.score(X_validate[combo_feats], y_validate)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "-- Epoch 1\nNorm: 8.84, NNZs: 15, Bias: -0.577364, T: 4834, Avg. loss: 35.809312\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 6.75, NNZs: 15, Bias: -0.145173, T: 9668, Avg. loss: 5.214510\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 5.42, NNZs: 15, Bias: 0.002982, T: 14502, Avg. loss: 3.350249\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 4.78, NNZs: 15, Bias: 0.133721, T: 19336, Avg. loss: 2.469833\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 4.29, NNZs: 15, Bias: 0.237891, T: 24170, Avg. loss: 2.020873\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 3.85, NNZs: 15, Bias: 0.328668, T: 29004, Avg. loss: 1.802830\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 3.62, NNZs: 15, Bias: 0.306043, T: 33838, Avg. loss: 1.661731\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 3.38, NNZs: 15, Bias: 0.385129, T: 38672, Avg. loss: 1.525530\nTotal training time: 0.01 seconds.\n-- Epoch 9\nNorm: 3.16, NNZs: 15, Bias: 0.423758, T: 43506, Avg. loss: 1.453372\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 3.03, NNZs: 15, Bias: 0.425535, T: 48340, Avg. loss: 1.334086\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 2.89, NNZs: 15, Bias: 0.449965, T: 53174, Avg. loss: 1.281944\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 2.79, NNZs: 15, Bias: 0.437298, T: 58008, Avg. loss: 1.223690\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 2.73, NNZs: 15, Bias: 0.437191, T: 62842, Avg. loss: 1.180690\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 2.65, NNZs: 15, Bias: 0.441395, T: 67676, Avg. loss: 1.140883\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 2.57, NNZs: 15, Bias: 0.437776, T: 72510, Avg. loss: 1.113271\nTotal training time: 0.01 seconds.\n-- Epoch 16\nNorm: 2.51, NNZs: 15, Bias: 0.441835, T: 77344, Avg. loss: 1.067877\nTotal training time: 0.01 seconds.\n-- Epoch 17\nNorm: 2.48, NNZs: 15, Bias: 0.424364, T: 82178, Avg. loss: 1.074548\nTotal training time: 0.01 seconds.\n-- Epoch 18\nNorm: 2.43, NNZs: 15, Bias: 0.422558, T: 87012, Avg. loss: 1.052508\nTotal training time: 0.01 seconds.\n-- Epoch 19\nNorm: 2.38, NNZs: 15, Bias: 0.419472, T: 91846, Avg. loss: 1.039048\nTotal training time: 0.01 seconds.\n-- Epoch 20\nNorm: 2.37, NNZs: 15, Bias: 0.402562, T: 96680, Avg. loss: 0.993841\nTotal training time: 0.01 seconds.\n-- Epoch 21\nNorm: 2.34, NNZs: 15, Bias: 0.409522, T: 101514, Avg. loss: 0.999209\nTotal training time: 0.01 seconds.\n-- Epoch 22\nNorm: 2.31, NNZs: 15, Bias: 0.410433, T: 106348, Avg. loss: 0.985970\nTotal training time: 0.01 seconds.\n-- Epoch 23\nNorm: 2.28, NNZs: 15, Bias: 0.409649, T: 111182, Avg. loss: 0.964088\nTotal training time: 0.01 seconds.\n-- Epoch 24\nNorm: 2.24, NNZs: 15, Bias: 0.425492, T: 116016, Avg. loss: 0.965230\nTotal training time: 0.01 seconds.\n-- Epoch 25\nNorm: 2.24, NNZs: 15, Bias: 0.436490, T: 120850, Avg. loss: 0.924894\nTotal training time: 0.01 seconds.\n-- Epoch 26\nNorm: 2.24, NNZs: 15, Bias: 0.434987, T: 125684, Avg. loss: 0.939146\nTotal training time: 0.01 seconds.\n-- Epoch 27\nNorm: 2.20, NNZs: 15, Bias: 0.436551, T: 130518, Avg. loss: 0.932914\nTotal training time: 0.01 seconds.\n-- Epoch 28\nNorm: 2.19, NNZs: 15, Bias: 0.434224, T: 135352, Avg. loss: 0.909613\nTotal training time: 0.01 seconds.\n-- Epoch 29\nNorm: 2.18, NNZs: 15, Bias: 0.434034, T: 140186, Avg. loss: 0.891683\nTotal training time: 0.01 seconds.\n-- Epoch 30\nNorm: 2.17, NNZs: 15, Bias: 0.431870, T: 145020, Avg. loss: 0.900389\nTotal training time: 0.04 seconds.\n-- Epoch 31\nNorm: 2.15, NNZs: 15, Bias: 0.440539, T: 149854, Avg. loss: 0.891480\nTotal training time: 0.04 seconds.\n-- Epoch 32\nNorm: 2.14, NNZs: 15, Bias: 0.444385, T: 154688, Avg. loss: 0.894188\nTotal training time: 0.05 seconds.\n-- Epoch 33\nNorm: 2.13, NNZs: 15, Bias: 0.442511, T: 159522, Avg. loss: 0.884441\nTotal training time: 0.05 seconds.\n-- Epoch 34\nNorm: 2.11, NNZs: 15, Bias: 0.443774, T: 164356, Avg. loss: 0.866946\nTotal training time: 0.05 seconds.\n-- Epoch 35\nNorm: 2.10, NNZs: 15, Bias: 0.437310, T: 169190, Avg. loss: 0.879260\nTotal training time: 0.05 seconds.\n-- Epoch 36\nNorm: 2.09, NNZs: 15, Bias: 0.448390, T: 174024, Avg. loss: 0.876290\nTotal training time: 0.05 seconds.\n-- Epoch 37\nNorm: 2.08, NNZs: 15, Bias: 0.448933, T: 178858, Avg. loss: 0.861608\nTotal training time: 0.05 seconds.\n-- Epoch 38\nNorm: 2.08, NNZs: 15, Bias: 0.450161, T: 183692, Avg. loss: 0.850247\nTotal training time: 0.05 seconds.\n-- Epoch 39\nNorm: 2.08, NNZs: 15, Bias: 0.449086, T: 188526, Avg. loss: 0.861350\nTotal training time: 0.05 seconds.\n-- Epoch 40\nNorm: 2.06, NNZs: 15, Bias: 0.447958, T: 193360, Avg. loss: 0.838572\nTotal training time: 0.05 seconds.\n-- Epoch 41\nNorm: 2.06, NNZs: 15, Bias: 0.451624, T: 198194, Avg. loss: 0.843438\nTotal training time: 0.05 seconds.\n-- Epoch 42\nNorm: 2.07, NNZs: 15, Bias: 0.457006, T: 203028, Avg. loss: 0.841653\nTotal training time: 0.05 seconds.\n-- Epoch 43\nNorm: 2.06, NNZs: 15, Bias: 0.463743, T: 207862, Avg. loss: 0.847300\nTotal training time: 0.05 seconds.\n-- Epoch 44\nNorm: 2.06, NNZs: 15, Bias: 0.458021, T: 212696, Avg. loss: 0.837004\nTotal training time: 0.05 seconds.\n-- Epoch 45\nNorm: 2.06, NNZs: 15, Bias: 0.463908, T: 217530, Avg. loss: 0.824769\nTotal training time: 0.05 seconds.\n-- Epoch 46\nNorm: 2.06, NNZs: 15, Bias: 0.462020, T: 222364, Avg. loss: 0.834921\nTotal training time: 0.05 seconds.\n-- Epoch 47\nNorm: 2.05, NNZs: 15, Bias: 0.463317, T: 227198, Avg. loss: 0.815521\nTotal training time: 0.06 seconds.\n-- Epoch 48\nNorm: 2.05, NNZs: 15, Bias: 0.461085, T: 232032, Avg. loss: 0.820420\nTotal training time: 0.06 seconds.\n-- Epoch 49\nNorm: 2.04, NNZs: 15, Bias: 0.461504, T: 236866, Avg. loss: 0.814893\nTotal training time: 0.06 seconds.\n-- Epoch 50\nNorm: 2.04, NNZs: 15, Bias: 0.462328, T: 241700, Avg. loss: 0.815647\nTotal training time: 0.06 seconds.\n-- Epoch 51\nNorm: 2.04, NNZs: 15, Bias: 0.460813, T: 246534, Avg. loss: 0.816157\nTotal training time: 0.06 seconds.\n-- Epoch 52\nNorm: 2.04, NNZs: 15, Bias: 0.462800, T: 251368, Avg. loss: 0.818114\nTotal training time: 0.06 seconds.\nConvergence after 52 epochs took 0.06 seconds\n-- Epoch 1\nNorm: 16.18, NNZs: 14, Bias: -8.582179, T: 4834, Avg. loss: 5.494072\nTotal training time: 0.00 seconds.\n-- Epoch 2\nNorm: 11.82, NNZs: 15, Bias: -3.875576, T: 9668, Avg. loss: 2.308614\nTotal training time: 0.00 seconds.\n-- Epoch 3\nNorm: 9.47, NNZs: 15, Bias: -3.938957, T: 14502, Avg. loss: 1.641147\nTotal training time: 0.00 seconds.\n-- Epoch 4\nNorm: 6.28, NNZs: 15, Bias: -3.338135, T: 19336, Avg. loss: 1.373540\nTotal training time: 0.00 seconds.\n-- Epoch 5\nNorm: 7.07, NNZs: 15, Bias: -1.861946, T: 24170, Avg. loss: 1.245992\nTotal training time: 0.00 seconds.\n-- Epoch 6\nNorm: 6.10, NNZs: 15, Bias: -1.964754, T: 29004, Avg. loss: 1.136503\nTotal training time: 0.00 seconds.\n-- Epoch 7\nNorm: 5.43, NNZs: 15, Bias: -3.057719, T: 33838, Avg. loss: 1.067305\nTotal training time: 0.00 seconds.\n-- Epoch 8\nNorm: 5.72, NNZs: 15, Bias: -2.316894, T: 38672, Avg. loss: 1.025431\nTotal training time: 0.00 seconds.\n-- Epoch 9\nNorm: 5.15, NNZs: 15, Bias: -2.099499, T: 43506, Avg. loss: 0.974403\nTotal training time: 0.01 seconds.\n-- Epoch 10\nNorm: 4.80, NNZs: 15, Bias: -1.920260, T: 48340, Avg. loss: 0.930697\nTotal training time: 0.01 seconds.\n-- Epoch 11\nNorm: 5.15, NNZs: 15, Bias: -2.208550, T: 53174, Avg. loss: 0.917209\nTotal training time: 0.01 seconds.\n-- Epoch 12\nNorm: 4.48, NNZs: 15, Bias: -2.447835, T: 58008, Avg. loss: 0.909630\nTotal training time: 0.01 seconds.\n-- Epoch 13\nNorm: 4.94, NNZs: 15, Bias: -1.462777, T: 62842, Avg. loss: 0.889441\nTotal training time: 0.01 seconds.\n-- Epoch 14\nNorm: 4.79, NNZs: 15, Bias: -1.983558, T: 67676, Avg. loss: 0.874135\nTotal training time: 0.01 seconds.\n-- Epoch 15\nNorm: 3.93, NNZs: 15, Bias: -1.956891, T: 72510, Avg. loss: 0.852661\nTotal training time: 0.01 seconds.\n-- Epoch 16\nNorm: 4.44, NNZs: 15, Bias: -2.042087, T: 77344, Avg. loss: 0.844510\nTotal training time: 0.01 seconds.\n-- Epoch 17\nNorm: 3.97, NNZs: 15, Bias: -1.777267, T: 82178, Avg. loss: 0.833459\nTotal training time: 0.01 seconds.\n-- Epoch 18\nNorm: 4.11, NNZs: 15, Bias: -1.964700, T: 87012, Avg. loss: 0.819383\nTotal training time: 0.01 seconds.\n-- Epoch 19\nNorm: 4.07, NNZs: 15, Bias: -1.583874, T: 91846, Avg. loss: 0.824487\nTotal training time: 0.01 seconds.\n-- Epoch 20\nNorm: 3.67, NNZs: 15, Bias: -1.790653, T: 96680, Avg. loss: 0.810273\nTotal training time: 0.01 seconds.\n-- Epoch 21\nNorm: 4.24, NNZs: 15, Bias: -1.612514, T: 101514, Avg. loss: 0.803358\nTotal training time: 0.01 seconds.\n-- Epoch 22\nNorm: 4.45, NNZs: 15, Bias: -1.252715, T: 106348, Avg. loss: 0.798193\nTotal training time: 0.01 seconds.\n-- Epoch 23\nNorm: 3.86, NNZs: 15, Bias: -1.512146, T: 111182, Avg. loss: 0.788720\nTotal training time: 0.01 seconds.\n-- Epoch 24\nNorm: 4.20, NNZs: 15, Bias: -1.264246, T: 116016, Avg. loss: 0.795484\nTotal training time: 0.01 seconds.\n-- Epoch 25\nNorm: 3.90, NNZs: 15, Bias: -1.686413, T: 120850, Avg. loss: 0.779494\nTotal training time: 0.02 seconds.\n-- Epoch 26\nNorm: 4.16, NNZs: 15, Bias: -1.502994, T: 125684, Avg. loss: 0.773477\nTotal training time: 0.02 seconds.\n-- Epoch 27\nNorm: 3.86, NNZs: 15, Bias: -1.503968, T: 130518, Avg. loss: 0.769837\nTotal training time: 0.02 seconds.\n-- Epoch 28\nNorm: 3.88, NNZs: 15, Bias: -1.431469, T: 135352, Avg. loss: 0.773015\nTotal training time: 0.02 seconds.\n-- Epoch 29\nNorm: 3.87, NNZs: 15, Bias: -1.582249, T: 140186, Avg. loss: 0.766376\nTotal training time: 0.02 seconds.\n-- Epoch 30\nNorm: 3.71, NNZs: 15, Bias: -1.720301, T: 145020, Avg. loss: 0.762850\nTotal training time: 0.02 seconds.\n-- Epoch 31\nNorm: 3.84, NNZs: 15, Bias: -1.480149, T: 149854, Avg. loss: 0.764576\nTotal training time: 0.02 seconds.\n-- Epoch 32\nNorm: 3.63, NNZs: 15, Bias: -1.583434, T: 154688, Avg. loss: 0.761309\nTotal training time: 0.02 seconds.\n-- Epoch 33\nNorm: 3.74, NNZs: 15, Bias: -1.552752, T: 159522, Avg. loss: 0.755625\nTotal training time: 0.02 seconds.\n-- Epoch 34\nNorm: 3.74, NNZs: 15, Bias: -1.432704, T: 164356, Avg. loss: 0.746620\nTotal training time: 0.02 seconds.\n-- Epoch 35\nNorm: 3.82, NNZs: 15, Bias: -1.228497, T: 169190, Avg. loss: 0.749177\nTotal training time: 0.02 seconds.\n-- Epoch 36\nNorm: 3.58, NNZs: 15, Bias: -1.694363, T: 174024, Avg. loss: 0.751103\nTotal training time: 0.02 seconds.\n-- Epoch 37\nNorm: 3.81, NNZs: 15, Bias: -1.031218, T: 178858, Avg. loss: 0.746570\nTotal training time: 0.02 seconds.\n-- Epoch 38\nNorm: 3.46, NNZs: 15, Bias: -1.486277, T: 183692, Avg. loss: 0.744729\nTotal training time: 0.02 seconds.\n-- Epoch 39\nNorm: 3.78, NNZs: 15, Bias: -1.447654, T: 188526, Avg. loss: 0.745607\nTotal training time: 0.02 seconds.\n-- Epoch 40\nNorm: 3.86, NNZs: 15, Bias: -1.437902, T: 193360, Avg. loss: 0.739948\nTotal training time: 0.02 seconds.\n-- Epoch 41\nNorm: 3.82, NNZs: 15, Bias: -1.333885, T: 198194, Avg. loss: 0.739145\nTotal training time: 0.02 seconds.\n-- Epoch 42\nNorm: 3.72, NNZs: 15, Bias: -1.532695, T: 203028, Avg. loss: 0.734550\nTotal training time: 0.03 seconds.\n-- Epoch 43\nNorm: 3.71, NNZs: 15, Bias: -1.618117, T: 207862, Avg. loss: 0.733211\nTotal training time: 0.03 seconds.\n-- Epoch 44\nNorm: 3.81, NNZs: 15, Bias: -1.328242, T: 212696, Avg. loss: 0.730923\nTotal training time: 0.03 seconds.\n-- Epoch 45\nNorm: 3.75, NNZs: 15, Bias: -1.501379, T: 217530, Avg. loss: 0.730543\nTotal training time: 0.03 seconds.\n-- Epoch 46\nNorm: 3.78, NNZs: 15, Bias: -1.487391, T: 222364, Avg. loss: 0.728737\nTotal training time: 0.03 seconds.\n-- Epoch 47\nNorm: 3.62, NNZs: 15, Bias: -1.489789, T: 227198, Avg. loss: 0.724572\nTotal training time: 0.03 seconds.\n-- Epoch 48\nNorm: 3.80, NNZs: 15, Bias: -1.401000, T: 232032, Avg. loss: 0.730778\nTotal training time: 0.03 seconds.\n-- Epoch 49\nNorm: 3.49, NNZs: 15, Bias: -1.626442, T: 236866, Avg. loss: 0.719268\nTotal training time: 0.03 seconds.\n-- Epoch 50\nNorm: 3.70, NNZs: 15, Bias: -1.388782, T: 241700, Avg. loss: 0.723685\nTotal training time: 0.03 seconds.\n-- Epoch 51\nNorm: 3.71, NNZs: 15, Bias: -1.244658, T: 246534, Avg. loss: 0.723266\nTotal training time: 0.03 seconds.\n-- Epoch 52\nNorm: 3.85, NNZs: 15, Bias: -1.247069, T: 251368, Avg. loss: 0.722473\nTotal training time: 0.03 seconds.\n-- Epoch 53\nNorm: 3.68, NNZs: 15, Bias: -1.285706, T: 256202, Avg. loss: 0.716608\nTotal training time: 0.03 seconds.\n-- Epoch 54\nNorm: 3.70, NNZs: 15, Bias: -1.335680, T: 261036, Avg. loss: 0.718717\nTotal training time: 0.03 seconds.\n-- Epoch 55\nNorm: 3.53, NNZs: 15, Bias: -1.398931, T: 265870, Avg. loss: 0.716589\nTotal training time: 0.03 seconds.\n-- Epoch 56\nNorm: 3.84, NNZs: 15, Bias: -1.318287, T: 270704, Avg. loss: 0.715808\nTotal training time: 0.03 seconds.\n-- Epoch 57\nNorm: 3.60, NNZs: 15, Bias: -1.391909, T: 275538, Avg. loss: 0.710937\nTotal training time: 0.03 seconds.\n-- Epoch 58\nNorm: 3.61, NNZs: 15, Bias: -1.504343, T: 280372, Avg. loss: 0.713628\nTotal training time: 0.03 seconds.\n-- Epoch 59\nNorm: 3.78, NNZs: 15, Bias: -1.361453, T: 285206, Avg. loss: 0.714032\nTotal training time: 0.04 seconds.\n-- Epoch 60\nNorm: 3.84, NNZs: 15, Bias: -1.231089, T: 290040, Avg. loss: 0.711773\nTotal training time: 0.04 seconds.\n-- Epoch 61\nNorm: 3.97, NNZs: 15, Bias: -1.161600, T: 294874, Avg. loss: 0.711896\nTotal training time: 0.04 seconds.\n-- Epoch 62\nNorm: 3.86, NNZs: 15, Bias: -1.249798, T: 299708, Avg. loss: 0.707951\nTotal training time: 0.04 seconds.\n-- Epoch 63\nNorm: 3.74, NNZs: 15, Bias: -1.238075, T: 304542, Avg. loss: 0.707071\nTotal training time: 0.04 seconds.\n-- Epoch 64\nNorm: 3.65, NNZs: 15, Bias: -1.308904, T: 309376, Avg. loss: 0.709223\nTotal training time: 0.04 seconds.\n-- Epoch 65\nNorm: 3.79, NNZs: 15, Bias: -1.143918, T: 314210, Avg. loss: 0.708716\nTotal training time: 0.04 seconds.\n-- Epoch 66\nNorm: 3.78, NNZs: 15, Bias: -1.147954, T: 319044, Avg. loss: 0.706334\nTotal training time: 0.04 seconds.\n-- Epoch 67\nNorm: 3.93, NNZs: 15, Bias: -0.985342, T: 323878, Avg. loss: 0.707490\nTotal training time: 0.04 seconds.\nConvergence after 67 epochs took 0.04 seconds\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00060-7e5fbb44-a8a8-4de8-bc0f-d384b3ab3b75",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "962e44ec",
    "execution_start": 1622080419152,
    "execution_millis": 2,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# Add accuracy of the SKB model to the metric_df\nmetric_df = metric_df.append({\n    'model': 'SGD Classifier SKB Features', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(accuracy_train_sgd_skb, 2),\n    'validate_accuracy':round(accuracy_val_sgd_skb,2)}, ignore_index=True)\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00061-60b11f13-4225-4299-9769-853a128cda69",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "cb4e0fa5",
    "execution_start": 1622080419161,
    "execution_millis": 67,
    "deepnote_cell_type": "code"
   },
   "source": "# Add accuracy of the RFE model to the metric_df\nmetric_df = metric_df.append({\n    'model': 'SGD Classifier RFE Features', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(accuracy_train_sgd_rfe, 2),\n    'validate_accuracy':round(accuracy_val_sgd_rfe,2)}, ignore_index=True)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00073-51513955-2f8a-4c03-98a5-2b4f97233fb6",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "18ccc7a1",
    "execution_start": 1622080419231,
    "execution_millis": 8,
    "deepnote_cell_type": "code"
   },
   "source": "# Add accuracy of the CF model to the metric_df\nmetric_df = metric_df.append({\n    'model': 'SGD Classifier CF Features', \n    'baseline_accuracy': round(baseline_accuracy,2),\n    'train_accuracy': round(accuracy_train_sgd_cf, 2),\n    'validate_accuracy':round(accuracy_val_sgd_cf,2)}, ignore_index=True)",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00063-738a4a78-840c-49b6-9eea-091156bab26a",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "400c35cf",
    "execution_start": 1622080419245,
    "execution_millis": 36,
    "deepnote_cell_type": "code"
   },
   "source": "metric_df",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 61,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 5,
       "column_count": 4,
       "columns": [
        {
         "name": "model",
         "dtype": "object",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "categories": [
           {
            "name": "random forest",
            "count": 1
           },
           {
            "name": "naive bayes",
            "count": 1
           },
           {
            "name": "3 others",
            "count": 3
           }
          ]
         }
        },
        {
         "name": "baseline_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 1,
          "nan_count": 0,
          "min": "0.51",
          "max": "0.51",
          "histogram": [
           {
            "bin_start": 0.010000000000000009,
            "bin_end": 0.11000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.11000000000000001,
            "bin_end": 0.21000000000000002,
            "count": 0
           },
           {
            "bin_start": 0.21000000000000002,
            "bin_end": 0.31000000000000005,
            "count": 0
           },
           {
            "bin_start": 0.31000000000000005,
            "bin_end": 0.41000000000000003,
            "count": 0
           },
           {
            "bin_start": 0.41000000000000003,
            "bin_end": 0.51,
            "count": 0
           },
           {
            "bin_start": 0.51,
            "bin_end": 0.6100000000000001,
            "count": 5
           },
           {
            "bin_start": 0.6100000000000001,
            "bin_end": 0.7100000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7100000000000001,
            "bin_end": 0.81,
            "count": 0
           },
           {
            "bin_start": 0.81,
            "bin_end": 0.91,
            "count": 0
           },
           {
            "bin_start": 0.91,
            "bin_end": 1.01,
            "count": 0
           }
          ]
         }
        },
        {
         "name": "train_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 3,
          "nan_count": 0,
          "min": "0.66",
          "max": "0.7",
          "histogram": [
           {
            "bin_start": 0.66,
            "bin_end": 0.664,
            "count": 1
           },
           {
            "bin_start": 0.664,
            "bin_end": 0.668,
            "count": 0
           },
           {
            "bin_start": 0.668,
            "bin_end": 0.672,
            "count": 1
           },
           {
            "bin_start": 0.672,
            "bin_end": 0.676,
            "count": 0
           },
           {
            "bin_start": 0.676,
            "bin_end": 0.6799999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6799999999999999,
            "bin_end": 0.6839999999999999,
            "count": 0
           },
           {
            "bin_start": 0.6839999999999999,
            "bin_end": 0.688,
            "count": 0
           },
           {
            "bin_start": 0.688,
            "bin_end": 0.692,
            "count": 0
           },
           {
            "bin_start": 0.692,
            "bin_end": 0.696,
            "count": 0
           },
           {
            "bin_start": 0.696,
            "bin_end": 0.7,
            "count": 3
           }
          ]
         }
        },
        {
         "name": "validate_accuracy",
         "dtype": "float64",
         "stats": {
          "unique_count": 5,
          "nan_count": 0,
          "min": "0.65",
          "max": "0.72",
          "histogram": [
           {
            "bin_start": 0.65,
            "bin_end": 0.657,
            "count": 1
           },
           {
            "bin_start": 0.657,
            "bin_end": 0.664,
            "count": 0
           },
           {
            "bin_start": 0.664,
            "bin_end": 0.671,
            "count": 1
           },
           {
            "bin_start": 0.671,
            "bin_end": 0.678,
            "count": 0
           },
           {
            "bin_start": 0.678,
            "bin_end": 0.685,
            "count": 1
           },
           {
            "bin_start": 0.685,
            "bin_end": 0.692,
            "count": 0
           },
           {
            "bin_start": 0.692,
            "bin_end": 0.699,
            "count": 0
           },
           {
            "bin_start": 0.699,
            "bin_end": 0.706,
            "count": 1
           },
           {
            "bin_start": 0.706,
            "bin_end": 0.713,
            "count": 0
           },
           {
            "bin_start": 0.713,
            "bin_end": 0.72,
            "count": 1
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "model": "random forest",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.72,
         "_deepnote_index_column": 0
        },
        {
         "model": "naive bayes",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.68,
         "_deepnote_index_column": 1
        },
        {
         "model": "SGD Classifier SKB Features",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.67,
         "validate_accuracy": 0.67,
         "_deepnote_index_column": 2
        },
        {
         "model": "SGD Classifier RFE Features",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.7,
         "validate_accuracy": 0.7,
         "_deepnote_index_column": 3
        },
        {
         "model": "SGD Classifier CF Features",
         "baseline_accuracy": 0.51,
         "train_accuracy": 0.66,
         "validate_accuracy": 0.65,
         "_deepnote_index_column": 4
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "                         model  baseline_accuracy  train_accuracy  \\\n0                random forest               0.51            0.70   \n1                  naive bayes               0.51            0.70   \n2  SGD Classifier SKB Features               0.51            0.67   \n3  SGD Classifier RFE Features               0.51            0.70   \n4   SGD Classifier CF Features               0.51            0.66   \n\n   validate_accuracy  \n0               0.72  \n1               0.68  \n2               0.67  \n3               0.70  \n4               0.65  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>baseline_accuracy</th>\n      <th>train_accuracy</th>\n      <th>validate_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>random forest</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>naive bayes</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.68</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SGD Classifier SKB Features</td>\n      <td>0.51</td>\n      <td>0.67</td>\n      <td>0.67</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SGD Classifier RFE Features</td>\n      <td>0.51</td>\n      <td>0.70</td>\n      <td>0.70</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SGD Classifier CF Features</td>\n      <td>0.51</td>\n      <td>0.66</td>\n      <td>0.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00075-c41135db-9108-4f7d-861a-ead6033e108e",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "execution_start": 1622080419263,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "___\n# KNN \n## Train",
   "metadata": {
    "tags": [],
    "cell_id": "00066-5c562e23-abbc-415c-a7e1-f93c4e0f290b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00069-ccaeab24-85c5-4c80-be63-036ad728bd92",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "97f90de9",
    "execution_start": 1622080419269,
    "execution_millis": 3,
    "deepnote_cell_type": "code"
   },
   "source": "def get_metrics(mod, X, y):\n    \"\"\"\n    get_metrics returns the baseline accuracy score \n    along with the current model's accuracy score for comparison \n    along with a table of precision/recall/f1-score/support percentages of the model\n    \"\"\"\n    baseline_accuracy = (train.alleged_threat_lvl == 0).mean()\n    y_pred = mod.predict(X)\n    accuracy = mod.score(X, y)\n    conf = confusion_matrix(y, y_pred)\n    prfs = pd.DataFrame(precision_recall_fscore_support(y, y_pred), index=['precision', 'recall', 'f1-score', 'support'])\n    \n    print(f'''\n    BASELINE accuracy is: {baseline_accuracy:.2%}\n    The accuracy for our model is: {accuracy:.5%} \n    ''')\n    return conf, prfs",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Select K Best",
   "metadata": {
    "tags": [],
    "cell_id": "00072-bbb023ce-b81e-4c84-bb76-7f81cdb3f985",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00071-16dd3d22-80a0-4e0c-aa88-06c9b829ece7",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "1fd2a00e",
    "execution_start": 1622080419276,
    "execution_millis": 25,
    "deepnote_cell_type": "code"
   },
   "source": "# Create KNN object (thing)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n# fit the model (thing)\nknn.fit(train[f_feature], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 63,
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00072-d0c66d9b-66bd-4379-b697-322c7f2fa99a",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "c6cb09d",
    "execution_start": 1622080419295,
    "execution_millis": 400,
    "deepnote_cell_type": "code"
   },
   "source": "# Use the model (thing)\n# Select k Best features\nget_metrics(knn, train[f_feature], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n    BASELINE accuracy is: 51.01%\n    The accuracy for our model is: 74.18287% \n    \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 64,
     "data": {
      "text/plain": "(array([[1773,  693],\n        [ 555, 1813]]),\n                      0            1\n precision     0.761598     0.723464\n recall        0.718978     0.765625\n f1-score      0.739675     0.743947\n support    2466.000000  2368.000000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### RFE",
   "metadata": {
    "tags": [],
    "cell_id": "00075-dd3dafa5-b701-4f58-8846-354ac51d570b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00074-64bb6ddf-12c4-4a4d-ad53-afca2030a16e",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "963da197",
    "execution_start": 1622080419696,
    "execution_millis": 34,
    "deepnote_cell_type": "code"
   },
   "source": "# Create KNN object (thing)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n# fit the model (thing)\nknn.fit(train[rfe_list], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 65,
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00073-cc52a515-248f-47d1-b97d-58ac9d1f5815",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "15d2c431",
    "execution_start": 1622080419733,
    "execution_millis": 789,
    "deepnote_cell_type": "code"
   },
   "source": "# Use the model (thing)\n# RFE features\nget_metrics(knn, train[rfe_list], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n    BASELINE accuracy is: 51.01%\n    The accuracy for our model is: 68.61812% \n    \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 66,
     "data": {
      "text/plain": "(array([[1544,  922],\n        [ 595, 1773]]),\n                      0            1\n precision     0.721833     0.657885\n recall        0.626115     0.748733\n f1-score      0.670575     0.700375\n support    2466.000000  2368.000000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Combo",
   "metadata": {
    "tags": [],
    "cell_id": "00078-90a5b75f-62ea-4bac-b207-7b51211d56f7",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00075-ebf12e50-f8ee-471d-b3ab-a3e3508108b3",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "db6ff987",
    "execution_start": 1622080420519,
    "execution_millis": 14,
    "deepnote_cell_type": "code"
   },
   "source": "# Create KNN object (thing)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n# fit the model (thing)\nknn.fit(train[combo_feats], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 67,
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00077-6aa18c7b-affe-4d6d-9a4d-b669b29cb1c9",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "a535d258",
    "execution_start": 1622080420528,
    "execution_millis": 1374,
    "deepnote_cell_type": "code"
   },
   "source": "# Use the model (thing)\n# combo features\nget_metrics(knn, train[combo_feats], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n    BASELINE accuracy is: 51.01%\n    The accuracy for our model is: 75.69301% \n    \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 68,
     "data": {
      "text/plain": "(array([[1824,  642],\n        [ 533, 1835]]),\n                      0            1\n precision     0.773865     0.740816\n recall        0.739659     0.774916\n f1-score      0.756376     0.757482\n support    2466.000000  2368.000000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Validate",
   "metadata": {
    "tags": [],
    "cell_id": "00074-1b8d4992-af34-4e73-8ecc-ba6ed8d40a27",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Select K Best",
   "metadata": {
    "tags": [],
    "cell_id": "00088-1b3bba08-fe12-4aa5-beba-1a2a694741c8",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00088-a96610d4-38f4-4743-aae2-bf606be314e1",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "1fd2a00e",
    "execution_start": 1622080421897,
    "execution_millis": 19,
    "deepnote_cell_type": "code"
   },
   "source": "# Create KNN object (thing)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n# fit the model (thing)\nknn.fit(train[f_feature], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 69,
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00074-45cf7421-6669-4ed5-9fee-eccbc121696d",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "a576bb5c",
    "execution_start": 1622080421913,
    "execution_millis": 168,
    "deepnote_cell_type": "code"
   },
   "source": "# Use the model (thing)\n# Select k Best features\nget_metrics(knn, validate[f_feature], y_validate)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n    BASELINE accuracy is: 51.01%\n    The accuracy for our model is: 65.60540% \n    \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 70,
     "data": {
      "text/plain": "(array([[684, 369],\n        [344, 676]]),\n                      0            1\n precision     0.665370     0.646890\n recall        0.649573     0.662745\n f1-score      0.657376     0.654722\n support    1053.000000  1020.000000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### RFE",
   "metadata": {
    "tags": [],
    "cell_id": "00091-ae31fb63-8766-49ab-ade2-bd8ad964cb5c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00090-b716f319-6901-409d-8401-c207578bb537",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "963da197",
    "execution_start": 1622080422078,
    "execution_millis": 37,
    "deepnote_cell_type": "code"
   },
   "source": "# Create KNN object (thing)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n# fit the model (thing)\nknn.fit(train[rfe_list], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 71,
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00076-450d3381-593b-4304-acf5-8af16e153ad8",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "ef609b5",
    "execution_start": 1622080422157,
    "execution_millis": 307,
    "deepnote_cell_type": "code"
   },
   "source": "# Use the model (thing)\n# RFE features\nget_metrics(knn, validate[rfe_list], y_validate)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n    BASELINE accuracy is: 51.01%\n    The accuracy for our model is: 66.85962% \n    \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 72,
     "data": {
      "text/plain": "(array([[638, 415],\n        [272, 748]]),\n                      0            1\n precision     0.701099     0.643164\n recall        0.605888     0.733333\n f1-score      0.650025     0.685295\n support    1053.000000  1020.000000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Combo Features",
   "metadata": {
    "tags": [],
    "cell_id": "00094-2d4ba687-560a-4b7e-9939-a5e6e6db94af",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00092-90b11f93-5c05-43ac-8e09-981e68e99b64",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "db6ff987",
    "execution_start": 1622080422460,
    "execution_millis": 15,
    "deepnote_cell_type": "code"
   },
   "source": "# Create KNN object (thing)\nknn = KNeighborsClassifier(n_neighbors=5, weights='uniform')\n# fit the model (thing)\nknn.fit(train[combo_feats], y_train)",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 73,
     "data": {
      "text/plain": "KNeighborsClassifier()"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00092-3ca10d33-8dff-4ba0-a340-c34823ef9b06",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "62cc88b1",
    "execution_start": 1622080422472,
    "execution_millis": 668,
    "deepnote_cell_type": "code"
   },
   "source": "# Use the model (thing)\n# Combo features\nget_metrics(knn, validate[combo_feats], y_validate)",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\n    BASELINE accuracy is: 51.01%\n    The accuracy for our model is: 67.24554% \n    \n",
     "output_type": "stream"
    },
    {
     "output_type": "execute_result",
     "execution_count": 74,
     "data": {
      "text/plain": "(array([[698, 355],\n        [324, 696]]),\n                      0            1\n precision     0.682975     0.662226\n recall        0.662868     0.682353\n f1-score      0.672771     0.672139\n support    1053.000000  1020.000000)"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "**KNN using Combo feats is running best with Train=76% & Validate=67.24%**",
   "metadata": {
    "tags": [],
    "cell_id": "00078-b65913b2-3915-412e-b88c-516009f16f49",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00098-af4290be-3a3b-4a53-8a9b-4c149d24ad8f",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "f56e2dd3",
    "execution_start": 1622080511597,
    "execution_millis": 1139,
    "deepnote_cell_type": "code"
   },
   "source": "!pip install gra",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001b[31mERROR: Could not find a version that satisfies the requirement gra (from versions: none)\u001b[0m\n\u001b[31mERROR: No matching distribution found for gra\u001b[0m\n\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.1.2 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00099-6c61438a-9708-4401-aaf2-24b0edce1c5a",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "778f5ede",
    "execution_start": 1622080570144,
    "execution_millis": 1,
    "deepnote_cell_type": "code"
   },
   "source": "import graphviz as graph",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00100-732d4342-6341-4a40-a89b-3eb5a09095f8",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "120286ed",
    "deepnote_cell_type": "code"
   },
   "source": "graph.",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=258e71fc-cf2b-48c3-8461-70ecd9787aa1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "898de622-f47c-4fb6-afc3-512715d2b613",
  "deepnote_execution_queue": []
 }
}